# GPU åŠ é€Ÿè¨­ç½®æŒ‡å—

## ğŸ¯ ç•¶å‰ç‹€æ³

æ‚¨çš„ç³»çµ±é…å‚™ **NVIDIA GeForce RTX 3050 (4GB VRAM)**ï¼Œä½†ç›®å‰ PyTorch å®‰è£çš„æ˜¯ CPU ç‰ˆæœ¬ã€‚éœ€è¦é‡æ–°å®‰è£ GPU ç‰ˆæœ¬çš„ PyTorchã€‚

## ğŸ“¦ å®‰è£æ­¥é©Ÿ

### æ­¥é©Ÿ 1: å¸è¼‰ç•¶å‰ CPU ç‰ˆæœ¬çš„ PyTorch

```bash
pip uninstall torch torchvision torchaudio -y
```

### æ­¥é©Ÿ 2: å®‰è£ CUDA ç‰ˆæœ¬çš„ PyTorch

æ ¹æ“šæ‚¨çš„ NVIDIA-SMI é¡¯ç¤ºï¼Œæ‚¨æœ‰ CUDA 13.0ï¼Œä½† PyTorch ç›®å‰æœ€é«˜æ”¯æ´ CUDA 12.4ã€‚è«‹åŸ·è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# å®‰è£ CUDA 12.4 ç‰ˆæœ¬çš„ PyTorch (æœ€æ–°ç©©å®šç‰ˆ)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# æˆ–è€…å¦‚æœä¸Šé¢å¤±æ•—ï¼Œå˜—è©¦ CUDA 12.1 ç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
```

### æ­¥é©Ÿ 3: é©—è­‰å®‰è£

å‰µå»ºä¸¦é‹è¡Œä»¥ä¸‹æ¸¬è©¦è…³æœ¬ï¼š

```python
# test_gpu.py
import torch
print("PyTorch version:", torch.__version__)
print("CUDA available:", torch.cuda.is_available())
if torch.cuda.is_available():
    print("CUDA version:", torch.version.cuda)
    print("GPU Name:", torch.cuda.get_device_name(0))
    print("GPU Memory:", f"{torch.cuda.get_device_properties(0).total_memory/1024**3:.1f} GB")

    # æ¸¬è©¦ GPU é‹ç®—
    x = torch.randn(1000, 1000).cuda()
    y = torch.matmul(x, x)
    print("GPU computation test: PASSED")
else:
    print("GPU not detected!")
```

é‹è¡Œæ¸¬è©¦ï¼š
```bash
python test_gpu.py
```

## ğŸ”§ å¦‚æœä»ç„¶ç„¡æ³•åµæ¸¬ GPU

### é¸é … A: æª¢æŸ¥ CUDA å·¥å…·åŒ…

1. ä¸‹è¼‰ä¸¦å®‰è£ CUDA Toolkit 12.4ï¼š
   - å‰å¾€ï¼šhttps://developer.nvidia.com/cuda-12-4-0-download-archive
   - é¸æ“‡ï¼šWindows â†’ x86_64 â†’ 11 â†’ exe (local)
   - ä¸‹è¼‰ä¸¦å®‰è£ï¼ˆç´„ 3GBï¼‰

2. è¨­ç½®ç’°å¢ƒè®Šæ•¸ï¼ˆå®‰è£å¾Œè‡ªå‹•è¨­ç½®ï¼Œä½†å¯ä»¥æª¢æŸ¥ï¼‰ï¼š
   ```
   CUDA_PATH = C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
   PATH åŒ…å« %CUDA_PATH%\bin
   ```

3. é‡æ–°å•Ÿå‹•å‘½ä»¤æç¤ºå­—å…ƒæˆ– PowerShell

### é¸é … B: ä½¿ç”¨ Conda ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰

å¦‚æœ pip å®‰è£æœ‰å•é¡Œï¼Œä½¿ç”¨ Conda æ›´å®¹æ˜“ç®¡ç† CUDA ä¾è³´ï¼š

```bash
# å®‰è£ Miniconda (å¦‚æœæ²’æœ‰)
# ä¸‹è¼‰ï¼šhttps://docs.conda.io/en/latest/miniconda.html

# å‰µå»ºæ–°ç’°å¢ƒä¸¦å®‰è£ GPU ç‰ˆ PyTorch
conda create -n cyberpuppy python=3.11
conda activate cyberpuppy
conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia

# å®‰è£å…¶ä»–ä¾è³´
pip install -r requirements.txt
```

## ğŸ“Š GPU è³‡æºå„ªåŒ–å»ºè­°

æ‚¨çš„ RTX 3050 æœ‰ 4GB VRAMï¼Œè¨“ç·´æ™‚å»ºè­°ï¼š

1. **æ‰¹æ¬¡å¤§å°**ï¼šä½¿ç”¨è¼ƒå°çš„ batch_sizeï¼ˆå»ºè­° 8-16ï¼‰
2. **åºåˆ—é•·åº¦**ï¼šé™åˆ¶ max_length åœ¨ 128-256
3. **æ··åˆç²¾åº¦è¨“ç·´**ï¼šä½¿ç”¨ FP16 ç¯€çœè¨˜æ†¶é«”

```python
# æ··åˆç²¾åº¦è¨“ç·´ç¯„ä¾‹
from torch.cuda.amp import autocast, GradScaler

scaler = GradScaler()
for batch in dataloader:
    optimizer.zero_grad()
    with autocast():
        outputs = model(batch)
        loss = criterion(outputs, labels)
    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

## âœ… é æœŸçµæœ

å®‰è£æˆåŠŸå¾Œï¼Œæ‚¨æ‡‰è©²çœ‹åˆ°ï¼š
```
PyTorch version: 2.5.x+cu124
CUDA available: True
CUDA version: 12.4
GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU
GPU Memory: 4.0 GB
GPU computation test: PASSED
```

## ğŸš€ å®Œæˆå¾Œ

1. é‡æ–°é‹è¡Œ `python train_gpu.py` é€²è¡Œ GPU åŠ é€Ÿè¨“ç·´
2. API å°‡è‡ªå‹•ä½¿ç”¨ GPU é€²è¡Œæ¨ç†ï¼ˆå¦‚æœé…ç½®æ­£ç¢ºï¼‰
3. è¨“ç·´é€Ÿåº¦å°‡æå‡ 5-10 å€

## âš ï¸ æ³¨æ„äº‹é …

- ç¢ºä¿ NVIDIA é©…å‹•ç¨‹å¼æ˜¯æœ€æ–°çš„ï¼ˆæ‚¨çš„ 581.29 ç‰ˆæœ¬æ˜¯æœ€æ–°çš„ï¼‰
- å¦‚æœé‡åˆ° DLL éŒ¯èª¤ï¼Œå¯èƒ½éœ€è¦å®‰è£ Visual C++ Redistributable
- GPU è¨“ç·´æ™‚æœƒå¢åŠ ç³»çµ±åŠŸè€—å’Œæº«åº¦ï¼Œç¢ºä¿æ•£ç†±è‰¯å¥½