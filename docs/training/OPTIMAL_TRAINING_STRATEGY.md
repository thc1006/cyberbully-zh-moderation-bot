# ğŸ¯ æœ€ä½³æ•ˆèƒ½è¨“ç·´ç­–ç•¥ - éœ¸å‡Œåµæ¸¬ F1 â‰¥ 0.75

## ğŸ“‹ ç­–ç•¥ç¸½è¦½

**ç›®æ¨™**: é”æˆ F1 â‰¥ 0.75 çš„æœ€ä½³éœ¸å‡Œåµæ¸¬æ¨¡å‹
**æ–¹æ³•**: å¤šæ¨¡å‹è¨“ç·´ + é›†æˆå­¸ç¿’ + æ™ºèƒ½é¸æ“‡
**å¹³å°**: Google Colab (T4/V100/A100 GPU)
**Git LFS ç”¨é‡**: ~1.2-1.6 GB (å®Œå…¨åœ¨é™åˆ¶å…§)

---

## ğŸš€ ä¸‰éšæ®µè¨“ç·´è¨ˆåŠƒ

### Phase 1: åŸºç¤æ¨¡å‹è¨“ç·´ (3 å€‹æ¨¡å‹ä¸¦è¡Œ)

è¨“ç·´ä¸‰å€‹ä¸åŒé…ç½®çš„åŸºç¤æ¨¡å‹ï¼Œç¢ºä¿æ¢ç´¢æœ€ä½³è¶…åƒæ•¸ç©ºé–“ï¼š

#### Model A: ä¿å®ˆé…ç½® (ç©©å®šå„ªå…ˆ)
```yaml
åç¨±: macbert_conservative
åŸºç¤æ¨¡å‹: hfl/chinese-macbert-base
å­¸ç¿’ç‡: 1e-5 (è¼ƒä½ï¼Œé¿å…éæ“¬åˆ)
Batch size: 8
è¨“ç·´è¼ªæ•¸: 20 epochs
Early stopping: 5 epochs patience
ç„¦é»æå¤± alpha: 2.0, gamma: 2.5
è¨“ç·´è³‡æ–™: å®Œæ•´ 77,178 æ¨£æœ¬
é æœŸæ™‚é–“: 2-3 å°æ™‚ (Colab T4)
```

#### Model B: æ¿€é€²é…ç½® (æ•ˆèƒ½å„ªå…ˆ)
```yaml
åç¨±: macbert_aggressive
åŸºç¤æ¨¡å‹: hfl/chinese-macbert-base
å­¸ç¿’ç‡: 3e-5 (è¼ƒé«˜ï¼Œå¿«é€Ÿæ”¶æ–‚)
Batch size: 16 (æ¢¯åº¦ç´¯ç© x2)
è¨“ç·´è¼ªæ•¸: 15 epochs
Early stopping: 3 epochs patience
ç„¦é»æå¤± alpha: 2.5, gamma: 3.0
è³‡æ–™å¢å¼·: å•Ÿç”¨æ‰€æœ‰ç­–ç•¥
é æœŸæ™‚é–“: 2-3 å°æ™‚
```

#### Model C: RoBERTa è®Šé«” (æ¶æ§‹å¤šæ¨£æ€§)
```yaml
åç¨±: roberta_balanced
åŸºç¤æ¨¡å‹: hfl/chinese-roberta-wwm-ext
å­¸ç¿’ç‡: 2e-5 (ä¸­ç­‰)
Batch size: 12
è¨“ç·´è¼ªæ•¸: 18 epochs
Early stopping: 4 epochs patience
ç„¦é»æå¤± alpha: 2.2, gamma: 2.8
æ··åˆè¨“ç·´: 50% åŸå§‹ + 50% å¢å¼·
é æœŸæ™‚é–“: 2.5-3.5 å°æ™‚
```

**Git LFS ç”¨é‡**: 3 Ã— 390 MB = **1.17 GB**

---

### Phase 2: æœ€ä½³æ¨¡å‹ç²¾èª¿ (1-2 å€‹æ¨¡å‹)

å¾ Phase 1 é¸å‡º F1 æœ€é«˜çš„ 1-2 å€‹æ¨¡å‹ï¼Œé€²è¡Œç²¾èª¿ï¼š

```yaml
é…ç½®: åŸºæ–¼æœ€ä½³åŸºç¤æ¨¡å‹
å­¸ç¿’ç‡: é™ä½è‡³åŸä¾†çš„ 0.5x
è¨“ç·´è¼ªæ•¸: 10 epochs
Early stopping: 3 epochs patience
ç‰¹æ®ŠæŠ€å·§:
  - ä¸ç¢ºå®šæ€§åŠ æ¬Šæå¤±
  - å°æŠ—è¨“ç·´ (FGM)
  - å­¸ç¿’ç‡é¤˜å¼¦é€€ç«
  - æ¨™ç±¤å¹³æ»‘ (0.1)
é æœŸæ™‚é–“: 1-2 å°æ™‚
```

**é¡å¤– Git LFS ç”¨é‡**: 1-2 Ã— 390 MB = **390-780 MB**

---

### Phase 3: æ¨¡å‹é›†æˆ (å¯é¸ï¼Œå¦‚å–®æ¨¡å‹æœªé”æ¨™)

å¦‚æœå–®ä¸€æ¨¡å‹æœªé” F1 â‰¥ 0.75ï¼Œä½¿ç”¨é›†æˆç­–ç•¥ï¼š

#### ç­–ç•¥ A: Soft Voting Ensemble
```python
# åŠ æ¬Šå¹³å‡å¤šå€‹æ¨¡å‹çš„é æ¸¬æ¦‚ç‡
final_pred = (
    0.4 * model_best1.predict_proba(text) +
    0.35 * model_best2.predict_proba(text) +
    0.25 * model_best3.predict_proba(text)
)
```

#### ç­–ç•¥ B: Stacking Ensemble
```python
# ä½¿ç”¨ LightGBM ä½œç‚ºå…ƒå­¸ç¿’å™¨
meta_features = [model1_pred, model2_pred, model3_pred]
final_pred = lgbm_meta_model.predict(meta_features)
```

**å„ªé»**: é€šå¸¸å¯æå‡ 2-5% F1
**ç¼ºé»**: æ¨ç†æ™‚é–“å¢åŠ  2-3x
**Git LFS ç”¨é‡**: ç„¡é¡å¤–ç”¨é‡ï¼ˆé›†æˆé‚è¼¯åªæ˜¯ä»£ç¢¼ï¼‰

---

## ğŸ“Š Git LFS ç”¨é‡è¦åŠƒ

### æ¨é€ç­–ç•¥ï¼šæ™ºèƒ½åˆ†å±¤

#### å¿…é ˆæ¨é€ (é«˜å„ªå…ˆç´š)
```
models/bullying_improved/
â”œâ”€â”€ best_single_model/          # å–®ä¸€æœ€ä½³æ¨¡å‹
â”‚   â”œâ”€â”€ model.safetensors      (390 MB)
â”‚   â”œâ”€â”€ config.json            (<1 MB)
â”‚   â”œâ”€â”€ tokenizer_config.json  (<1 MB)
â”‚   â”œâ”€â”€ vocab.txt              (0.1 MB)
â”‚   â””â”€â”€ training_metrics.json  (<1 MB)
â””â”€â”€ ensemble_models/            # å¦‚æœéœ€è¦é›†æˆ
    â”œâ”€â”€ model_1.safetensors    (390 MB)
    â”œâ”€â”€ model_2.safetensors    (390 MB)
    â””â”€â”€ ensemble_config.json   (<1 MB)
```

**ç¸½ç”¨é‡**:
- å–®æ¨¡å‹æ–¹æ¡ˆ: **392 MB**
- é›†æˆæ–¹æ¡ˆ: **1.17 GB**

#### å¯é¸æ¨é€ (å¦‚ç©ºé–“å……è¶³)
```
models/experiments/             # å¯¦é©—æ¨¡å‹
â”œâ”€â”€ macbert_conservative/       (390 MB)
â”œâ”€â”€ macbert_aggressive/         (390 MB)
â””â”€â”€ roberta_balanced/           (390 MB)
```

**é¡å¤–ç”¨é‡**: **1.17 GB**

#### ä¸æ¨é€ (æœ¬åœ°ä¿ç•™)
```
- Optimizer states (.optimizer.pt)
- Training checkpoints (checkpoint-*.pt)
- TensorBoard logs
- ä¸­é–“è¨“ç·´è¼¸å‡º
```

---

## ğŸ¯ æ¨è–¦æ–¹æ¡ˆï¼šæ¼¸é€²å¼æ¨é€

### æ–¹æ¡ˆ 1ï¸âƒ£: ä¿å®ˆæ–¹æ¡ˆ (æ¨è–¦æ–°æ‰‹)
```
ç¬¬ä¸€æ¬¡æ¨é€: æœ€ä½³å–®æ¨¡å‹ (392 MB)
  â†’ å¦‚æœ F1 â‰¥ 0.75: å®Œæˆï¼
  â†’ å¦‚æœ F1 < 0.75: é€²å…¥æ–¹æ¡ˆ 2
```

### æ–¹æ¡ˆ 2ï¸âƒ£: å¹³è¡¡æ–¹æ¡ˆ (æ¨è–¦å¤§å¤šæ•¸æƒ…æ³)
```
ç¬¬ä¸€æ¬¡æ¨é€: æœ€ä½³å–®æ¨¡å‹ (392 MB)
ç¬¬äºŒæ¬¡æ¨é€: Top-3 æ¨¡å‹ç”¨æ–¼é›†æˆ (1.17 GB)
  â†’ å¦‚æœé›†æˆ F1 â‰¥ 0.75: å®Œæˆï¼
  â†’ å¦‚æœä»æœªé”æ¨™: é€²å…¥æ–¹æ¡ˆ 3
```

### æ–¹æ¡ˆ 3ï¸âƒ£: å…¨é¢æ–¹æ¡ˆ (è¿½æ±‚æ¥µè‡´æ•ˆèƒ½)
```
ç¬¬ä¸€æ¬¡æ¨é€: æ‰€æœ‰å¯¦é©—æ¨¡å‹ (1.17 GB)
ç¬¬äºŒæ¬¡æ¨é€: ç²¾èª¿æ¨¡å‹ (390-780 MB)
ç¬¬ä¸‰æ¬¡æ¨é€: æœ€çµ‚é›†æˆæ¨¡å‹ (1.17 GB)
ç¸½ç”¨é‡: ~2.7-3.1 GB (ä»åœ¨ 10 GB é™åˆ¶å…§)
```

---

## âš¡ Colab è¨“ç·´æµç¨‹å„ªåŒ–

### 1. Clone å„ªåŒ– (é¿å…ä¸‹è¼‰ç¾æœ‰å¤§æ¨¡å‹)
```bash
# æ–¹æ³• A: Shallow clone + LFS skip
GIT_LFS_SKIP_SMUDGE=1 git clone --depth 1 \
  https://github.com/yourusername/cyberbully-zh-moderation-bot.git

# æ–¹æ³• B: åªä¸‹è¼‰å¿…è¦çš„ LFS æª”æ¡ˆ
git lfs pull --include="data/processed/*" --exclude="models/*"
```

**ç¯€çœ**: ~2.4 GB ä¸‹è¼‰é‡

### 2. è¨“ç·´è³‡æ–™ä¸Šå‚³ç­–ç•¥
```python
# é¸é … A: å¾ repo è®€å– (å¦‚æœ data/ è¼ƒå°)
data_dir = "data/processed/training_dataset/"

# é¸é … B: å¾ Google Drive è®€å– (å¦‚æœ data/ è¼ƒå¤§)
from google.colab import drive
drive.mount('/content/drive')
data_dir = "/content/drive/MyDrive/cyberpuppy_data/"
```

### 3. æ¨¡å‹ä¸Šå‚³è‡ªå‹•åŒ–
```python
# è¨“ç·´å®Œæˆå¾Œè‡ªå‹•æ¨é€æœ€ä½³æ¨¡å‹
def push_best_model(model_path, f1_score):
    if f1_score >= 0.75:
        print(f"âœ… é”æ¨™ï¼F1 = {f1_score:.4f}")
        # åªæ¨é€æœ€ä½³æ¨¡å‹
        os.system(f"git lfs track '{model_path}/*.safetensors'")
        os.system(f"git add {model_path}")
        os.system(f"git commit -m 'feat: Add bullying model F1={f1_score:.4f}'")
        os.system("git push origin main")
    else:
        print(f"âš ï¸ æœªé”æ¨™ F1 = {f1_score:.4f}ï¼Œç¹¼çºŒè¨“ç·´...")
```

---

## ğŸ“ˆ é æœŸæ•ˆèƒ½èˆ‡æ™‚é–“

| éšæ®µ | æ¨¡å‹æ•¸ | è¨“ç·´æ™‚é–“ (T4) | è¨“ç·´æ™‚é–“ (V100) | Git LFS ç”¨é‡ | é æœŸ F1 |
|------|--------|---------------|-----------------|--------------|---------|
| Phase 1 | 3 | 6-9 å°æ™‚ | 3-5 å°æ™‚ | 1.17 GB | 0.65-0.75 |
| Phase 2 | 1-2 | 1-2 å°æ™‚ | 0.5-1 å°æ™‚ | +0.39-0.78 GB | 0.72-0.78 |
| Phase 3 | é›†æˆ | 0.5 å°æ™‚ | 0.2 å°æ™‚ | 0 GB | 0.75-0.82 |
| **ç¸½è¨ˆ** | - | **7-12 å°æ™‚** | **4-6 å°æ™‚** | **1.6-2.0 GB** | **â‰¥ 0.75** |

---

## ğŸ¯ æœ€çµ‚æ¨è–¦ï¼šæ™ºèƒ½æ¼¸é€²ç­–ç•¥

### ç¬¬ä¸€è¼ªï¼šå¿«é€Ÿé©—è­‰ (2-3 å°æ™‚)
1. è¨“ç·´ Model B (æ¿€é€²é…ç½®)
2. å¦‚æœ F1 â‰¥ 0.75 â†’ æ¨é€ï¼Œå®Œæˆï¼
3. å¦‚æœ F1 < 0.75 â†’ é€²å…¥ç¬¬äºŒè¼ª

### ç¬¬äºŒè¼ªï¼šå…¨é¢æ¢ç´¢ (6-9 å°æ™‚)
1. ä¸¦è¡Œè¨“ç·´ Model A + Model C
2. é¸å‡º Top-2 æ¨¡å‹
3. å¦‚æœä»»ä¸€ F1 â‰¥ 0.75 â†’ æ¨é€æœ€ä½³ï¼Œå®Œæˆï¼
4. å¦‚æœéƒ½ < 0.75 â†’ é€²å…¥ç¬¬ä¸‰è¼ª

### ç¬¬ä¸‰è¼ªï¼šç²¾èª¿èˆ‡é›†æˆ (2-3 å°æ™‚)
1. ç²¾èª¿ Top-2 æ¨¡å‹
2. å»ºç«‹ Soft Voting Ensemble
3. å¦‚æœé›†æˆ F1 â‰¥ 0.75 â†’ æ¨é€é›†æˆï¼Œå®Œæˆï¼
4. å¦‚æœä» < 0.75 â†’ åˆ†æå•é¡Œï¼Œèª¿æ•´ç­–ç•¥

---

## ğŸ’¾ Git LFS æœ€çµ‚ç”¨é‡é æ¸¬

| å ´æ™¯ | æ¨é€å…§å®¹ | LFS å­˜å„² | LFS é »å¯¬ | æˆåŠŸç‡ |
|------|---------|---------|---------|-------|
| æ¨‚è§€ | å–®ä¸€æœ€ä½³æ¨¡å‹ | +0.39 GB | +0.39 GB | 40% |
| æ¨™æº– | Top-2 ç²¾èª¿æ¨¡å‹ | +0.78 GB | +0.78 GB | 80% |
| ä¿å®ˆ | Top-3 + é›†æˆ | +1.17 GB | +1.17 GB | 95% |
| æ¥µé™ | æ‰€æœ‰å¯¦é©—æ¨¡å‹ | +2.34 GB | +2.34 GB | 99% |

**ä½ çš„å¯ç”¨ç©ºé–“**: 9.2 GB å­˜å„² + 9.8 GB é »å¯¬

âœ… **çµè«–**: å³ä½¿åœ¨æ¥µé™æƒ…æ³ä¸‹ï¼Œä¹Ÿåªç”¨ 25% çš„ç©ºé–“å’Œé »å¯¬ï¼

---

## ğŸš€ ç«‹å³åŸ·è¡Œ

æ¥ä¸‹ä¾†æˆ‘æœƒå»ºç«‹ï¼š
1. âœ… **Google Colab è¨“ç·´ç­†è¨˜æœ¬** (`notebooks/train_on_colab.ipynb`)
2. âœ… **æ™ºèƒ½æ¨é€è…³æœ¬** (`scripts/smart_push_model.py`)
3. âœ… **è¨“ç·´ç›£æ§å„€è¡¨æ¿** (TensorBoard + WandB)
4. âœ… **æ¨¡å‹é›†æˆå·¥å…·** (`src/cyberpuppy/ensemble/`)

æº–å‚™å¥½äº†å—ï¼Ÿæˆ‘ç¾åœ¨é–‹å§‹å»ºç«‹å®Œæ•´çš„ Colab è¨“ç·´ç³»çµ±ï¼