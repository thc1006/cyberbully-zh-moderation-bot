# CyberPuppy API éƒ¨ç½²èˆ‡é…ç½®æŒ‡å—
# Deployment & Configuration Guide

## éƒ¨ç½²æ¶æ§‹ (Deployment Architecture)

### ç”Ÿç”¢ç’°å¢ƒæ¶æ§‹åœ–
```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Load Balancer  â”‚
                    â”‚   (Nginx/AWS)   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  API Gateway    â”‚
                    â”‚  (Rate Limiting)â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   FastAPI App   â”‚
                    â”‚ (Multiple Pods) â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚ Model Service   â”‚ â”‚  Cache   â”‚ â”‚  Database  â”‚
    â”‚   (GPU Pod)     â”‚ â”‚ (Redis)  â”‚ â”‚ (MongoDB)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## éƒ¨ç½²é¸é … (Deployment Options)

### 1. Docker å®¹å™¨éƒ¨ç½²

#### Dockerfile
```dockerfile
# CyberPuppy API Dockerfile
FROM python:3.11-slim

# è¨­å®šå·¥ä½œç›®éŒ„
WORKDIR /app

# å®‰è£ç³»çµ±ä¾è³´
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# è¤‡è£½ä¾è³´æª”æ¡ˆ
COPY requirements.txt .

# å®‰è£ Python ä¾è³´
RUN pip install --no-cache-dir -r requirements.txt

# è¤‡è£½æ‡‰ç”¨ç¨‹å¼ç¢¼
COPY . .

# å»ºç«‹é root ç”¨æˆ¶
RUN useradd --create-home --shell /bin/bash cyberpuppy
RUN chown -R cyberpuppy:cyberpuppy /app
USER cyberpuppy

# æš´éœ²ç«¯å£
EXPOSE 8000

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
    CMD curl -f http://localhost:8000/healthz || exit 1

# å•Ÿå‹•å‘½ä»¤
CMD ["uvicorn", "api.app:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### docker-compose.yml
```yaml
version: '3.8'

services:
  cyberpuppy-api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - CYBERPUPPY_ENV=production
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=mongodb://mongo:27017/cyberpuppy
    depends_on:
      - redis
      - mongo
    volumes:
      - ./models:/app/models:ro
    networks:
      - cyberpuppy-net
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2'
        reservations:
          memory: 2G
          cpus: '1'

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - cyberpuppy-net
    restart: unless-stopped
    command: redis-server --appendonly yes

  mongo:
    image: mongo:6
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: cyberpuppy
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
      MONGO_INITDB_DATABASE: cyberpuppy
    volumes:
      - mongo_data:/data/db
      - ./scripts/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - cyberpuppy-net
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - cyberpuppy-api
    networks:
      - cyberpuppy-net
    restart: unless-stopped

volumes:
  redis_data:
  mongo_data:

networks:
  cyberpuppy-net:
    driver: bridge
```

#### å»ºç½®èˆ‡å•Ÿå‹•
```bash
# 1. æº–å‚™ç’°å¢ƒæª”æ¡ˆ
cp .env.example .env
# ç·¨è¼¯ .env è¨­å®šå¿…è¦çš„ç’°å¢ƒè®Šæ•¸

# 2. å»ºç½® Docker æ˜ åƒ
docker-compose build

# 3. å•Ÿå‹•æœå‹™
docker-compose up -d

# 4. æª¢æŸ¥æœå‹™ç‹€æ…‹
docker-compose ps

# 5. æŸ¥çœ‹æ—¥èªŒ
docker-compose logs -f cyberpuppy-api

# 6. å¥åº·æª¢æŸ¥
curl http://localhost:8000/healthz
```

### 2. Kubernetes éƒ¨ç½²

#### deployment.yaml
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cyberpuppy-api
  namespace: cyberpuppy
  labels:
    app: cyberpuppy-api
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  selector:
    matchLabels:
      app: cyberpuppy-api
  template:
    metadata:
      labels:
        app: cyberpuppy-api
    spec:
      containers:
      - name: cyberpuppy-api
        image: cyberpuppy/api:latest
        ports:
        - containerPort: 8000
        env:
        - name: CYBERPUPPY_ENV
          value: "production"
        - name: REDIS_URL
          valueFrom:
            secretKeyRef:
              name: cyberpuppy-secrets
              key: redis-url
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: cyberpuppy-secrets
              key: database-url
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 30
        readinessProbe:
          httpGet:
            path: /healthz
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
        volumeMounts:
        - name: model-storage
          mountPath: /app/models
          readOnly: true
      volumes:
      - name: model-storage
        persistentVolumeClaim:
          claimName: model-pvc
---
apiVersion: v1
kind: Service
metadata:
  name: cyberpuppy-api-service
  namespace: cyberpuppy
spec:
  selector:
    app: cyberpuppy-api
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8000
  type: ClusterIP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: cyberpuppy-api-ingress
  namespace: cyberpuppy
  annotations:
    nginx.ingress.kubernetes.io/rate-limit: "100"
    nginx.ingress.kubernetes.io/rate-limit-window: "1m"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - api.cyberpuppy.ai
    secretName: cyberpuppy-tls
  rules:
  - host: api.cyberpuppy.ai
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: cyberpuppy-api-service
            port:
              number: 80
```

#### éƒ¨ç½²æ­¥é©Ÿ
```bash
# 1. å»ºç«‹å‘½åç©ºé–“
kubectl create namespace cyberpuppy

# 2. å»ºç«‹ Secrets
kubectl create secret generic cyberpuppy-secrets \
  --from-literal=redis-url=redis://redis-service:6379/0 \
  --from-literal=database-url=mongodb://mongo-service:27017/cyberpuppy \
  -n cyberpuppy

# 3. éƒ¨ç½²æ‡‰ç”¨
kubectl apply -f deployment.yaml

# 4. æª¢æŸ¥éƒ¨ç½²ç‹€æ…‹
kubectl get pods -n cyberpuppy
kubectl get services -n cyberpuppy

# 5. æŸ¥çœ‹æ—¥èªŒ
kubectl logs -f deployment/cyberpuppy-api -n cyberpuppy
```

### 3. é›²ç«¯å¹³å°éƒ¨ç½²

#### AWS ECS éƒ¨ç½²
```json
{
  "family": "cyberpuppy-api",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "2048",
  "memory": "4096",
  "executionRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskExecutionRole",
  "taskRoleArn": "arn:aws:iam::ACCOUNT:role/ecsTaskRole",
  "containerDefinitions": [
    {
      "name": "cyberpuppy-api",
      "image": "cyberpuppy/api:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "CYBERPUPPY_ENV",
          "value": "production"
        }
      ],
      "secrets": [
        {
          "name": "API_KEY",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:cyberpuppy-api-key"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/cyberpuppy-api",
          "awslogs-region": "us-west-2",
          "awslogs-stream-prefix": "ecs"
        }
      },
      "healthCheck": {
        "command": [
          "CMD-SHELL",
          "curl -f http://localhost:8000/healthz || exit 1"
        ],
        "interval": 30,
        "timeout": 5,
        "retries": 3
      }
    }
  ]
}
```

#### Terraform é…ç½®
```hcl
# main.tf
provider "aws" {
  region = var.aws_region
}

# ECS Cluster
resource "aws_ecs_cluster" "cyberpuppy" {
  name = "cyberpuppy-cluster"

  setting {
    name  = "containerInsights"
    value = "enabled"
  }
}

# Application Load Balancer
resource "aws_lb" "cyberpuppy_alb" {
  name               = "cyberpuppy-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [aws_security_group.alb_sg.id]
  subnets           = var.public_subnet_ids

  enable_deletion_protection = true
}

# ECS Service
resource "aws_ecs_service" "cyberpuppy_api" {
  name            = "cyberpuppy-api"
  cluster         = aws_ecs_cluster.cyberpuppy.id
  task_definition = aws_ecs_task_definition.cyberpuppy_api.arn
  desired_count   = 3
  launch_type     = "FARGATE"

  network_configuration {
    security_groups  = [aws_security_group.api_sg.id]
    subnets         = var.private_subnet_ids
    assign_public_ip = false
  }

  load_balancer {
    target_group_arn = aws_lb_target_group.cyberpuppy_api.arn
    container_name   = "cyberpuppy-api"
    container_port   = 8000
  }

  depends_on = [aws_lb_listener.cyberpuppy_api]
}
```

## ç’°å¢ƒé…ç½® (Environment Configuration)

### 1. ç’°å¢ƒè®Šæ•¸è¨­å®š

#### .env æª”æ¡ˆç¯„ä¾‹
```bash
# æ‡‰ç”¨ç¨‹å¼é…ç½®
CYBERPUPPY_ENV=production
APP_NAME=CyberPuppy API
APP_VERSION=1.0.0
DEBUG=false

# API é…ç½®
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# è³‡æ–™åº«é…ç½®
DATABASE_URL=mongodb://username:password@localhost:27017/cyberpuppy
REDIS_URL=redis://localhost:6379/0

# æ¨¡å‹é…ç½®
MODEL_PATH=/app/models
MODEL_DEVICE=cuda:0
MODEL_BATCH_SIZE=32
MODEL_MAX_LENGTH=512

# å®‰å…¨é…ç½®
SECRET_KEY=your-super-secret-key-here
API_KEY_PREFIX=cp_
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=1440

# é™æµé…ç½®
RATE_LIMIT_PER_MINUTE=30
RATE_LIMIT_BURST=10
MAX_CONCURRENT_REQUESTS=100

# æ—¥èªŒé…ç½®
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE=/var/log/cyberpuppy/app.log

# ç›£æ§é…ç½®
METRICS_ENABLED=true
METRICS_PATH=/metrics
HEALTH_CHECK_PATH=/healthz

# LINE Bot é…ç½® (å¯é¸)
LINE_CHANNEL_ACCESS_TOKEN=your-line-channel-access-token
LINE_CHANNEL_SECRET=your-line-channel-secret

# å¤–éƒ¨æœå‹™é…ç½® (å¯é¸)
PERSPECTIVE_API_KEY=your-perspective-api-key
SENTRY_DSN=https://your-sentry-dsn

# å¿«å–é…ç½®
CACHE_TTL=3600
CACHE_MAX_SIZE=1000

# æª”æ¡ˆä¸Šå‚³é…ç½®
MAX_FILE_SIZE=10MB
ALLOWED_FILE_TYPES=txt,json
```

### 2. é…ç½®é©—è­‰è…³æœ¬

#### config_validator.py
```python
#!/usr/bin/env python3
"""
é…ç½®é©—è­‰è…³æœ¬
æª¢æŸ¥æ‰€æœ‰å¿…è¦çš„ç’°å¢ƒè®Šæ•¸æ˜¯å¦æ­£ç¢ºè¨­å®š
"""

import os
import sys
from typing import Dict, List, Optional

class ConfigValidator:
    """é…ç½®é©—è­‰å™¨"""

    REQUIRED_VARS = {
        'CYBERPUPPY_ENV': ['development', 'production', 'testing'],
        'DATABASE_URL': None,  # ä»»æ„å€¼
        'SECRET_KEY': None,
        'MODEL_PATH': None,
    }

    OPTIONAL_VARS = {
        'REDIS_URL': 'redis://localhost:6379/0',
        'API_HOST': '0.0.0.0',
        'API_PORT': '8000',
        'LOG_LEVEL': 'INFO',
        'RATE_LIMIT_PER_MINUTE': '30',
    }

    def __init__(self):
        self.errors: List[str] = []
        self.warnings: List[str] = []

    def validate_required_vars(self) -> bool:
        """é©—è­‰å¿…è¦ç’°å¢ƒè®Šæ•¸"""
        for var, valid_values in self.REQUIRED_VARS.items():
            value = os.getenv(var)

            if value is None:
                self.errors.append(f"Missing required environment variable: {var}")
                continue

            if valid_values and value not in valid_values:
                self.errors.append(
                    f"Invalid value for {var}: '{value}'. "
                    f"Valid values: {valid_values}"
                )

        return len(self.errors) == 0

    def validate_optional_vars(self):
        """é©—è­‰å¯é¸ç’°å¢ƒè®Šæ•¸ä¸¦è¨­å®šé è¨­å€¼"""
        for var, default_value in self.OPTIONAL_VARS.items():
            value = os.getenv(var)

            if value is None:
                self.warnings.append(
                    f"Optional variable {var} not set, using default: {default_value}"
                )
                os.environ[var] = default_value

    def validate_database_connection(self) -> bool:
        """é©—è­‰è³‡æ–™åº«é€£æ¥"""
        try:
            from pymongo import MongoClient

            db_url = os.getenv('DATABASE_URL')
            if not db_url:
                return True  # å·²åœ¨å¿…è¦è®Šæ•¸æª¢æŸ¥ä¸­è™•ç†

            client = MongoClient(db_url, serverSelectionTimeoutMS=5000)
            client.server_info()  # è§¸ç™¼é€£æ¥æ¸¬è©¦
            client.close()

            return True
        except Exception as e:
            self.errors.append(f"Database connection failed: {str(e)}")
            return False

    def validate_redis_connection(self) -> bool:
        """é©—è­‰ Redis é€£æ¥"""
        try:
            import redis

            redis_url = os.getenv('REDIS_URL')
            if not redis_url:
                return True

            r = redis.from_url(redis_url, socket_connect_timeout=5)
            r.ping()
            r.close()

            return True
        except Exception as e:
            self.warnings.append(f"Redis connection failed: {str(e)}")
            return True  # Redis æ˜¯å¯é¸çš„

    def validate_model_files(self) -> bool:
        """é©—è­‰æ¨¡å‹æª”æ¡ˆ"""
        model_path = os.getenv('MODEL_PATH', '/app/models')

        if not os.path.exists(model_path):
            self.errors.append(f"Model path does not exist: {model_path}")
            return False

        # æª¢æŸ¥åŸºæœ¬æ¨¡å‹æª”æ¡ˆ
        required_files = [
            'detector_model.bin',
            'tokenizer_vocab.txt',
            'config.json'
        ]

        for file_name in required_files:
            file_path = os.path.join(model_path, file_name)
            if not os.path.exists(file_path):
                self.warnings.append(f"Model file not found: {file_path}")

        return True

    def validate_all(self) -> bool:
        """åŸ·è¡Œæ‰€æœ‰é©—è­‰"""
        print("ğŸ” Validating configuration...")

        # å¿…è¦è®Šæ•¸é©—è­‰
        required_ok = self.validate_required_vars()

        # å¯é¸è®Šæ•¸é©—è­‰
        self.validate_optional_vars()

        # æœå‹™é€£æ¥é©—è­‰
        db_ok = self.validate_database_connection()
        redis_ok = self.validate_redis_connection()
        model_ok = self.validate_model_files()

        # é¡¯ç¤ºçµæœ
        if self.warnings:
            print("\nâš ï¸  Warnings:")
            for warning in self.warnings:
                print(f"   {warning}")

        if self.errors:
            print("\nâŒ Errors:")
            for error in self.errors:
                print(f"   {error}")
            return False

        print("\nâœ… Configuration validation passed!")
        return True

def main():
    """ä¸»å‡½æ•¸"""
    validator = ConfigValidator()

    if not validator.validate_all():
        print("\nğŸ’¡ Please fix the errors above and try again.")
        sys.exit(1)

    print("\nğŸš€ Ready to start CyberPuppy API!")

if __name__ == "__main__":
    main()
```

### 3. ç”Ÿç”¢ç’°å¢ƒæœ€ä½³åŒ–

#### uvicorn_config.py
```python
"""
Uvicorn ç”Ÿç”¢ç’°å¢ƒé…ç½®
"""

import multiprocessing
import os

# æœå‹™å™¨é…ç½®
bind = f"{os.getenv('API_HOST', '0.0.0.0')}:{os.getenv('API_PORT', '8000')}"
workers = int(os.getenv('API_WORKERS', multiprocessing.cpu_count() * 2))
worker_class = "uvicorn.workers.UvicornWorker"
worker_connections = 1000
max_requests = 10000
max_requests_jitter = 1000
preload_app = True
timeout = 300
keepalive = 5

# æ—¥èªŒé…ç½®
accesslog = "-"
errorlog = "-"
loglevel = os.getenv('LOG_LEVEL', 'info').lower()
access_log_format = '%(h)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

# å®‰å…¨é…ç½®
limit_request_line = 8190
limit_request_fields = 100
limit_request_field_size = 8190

# é€²ç¨‹é…ç½®
user = os.getenv('APP_USER', 'cyberpuppy')
group = os.getenv('APP_GROUP', 'cyberpuppy')
tmp_upload_dir = os.getenv('TMP_DIR', '/tmp')

# SSL é…ç½® (å¦‚æœéœ€è¦)
keyfile = os.getenv('SSL_KEYFILE')
certfile = os.getenv('SSL_CERTFILE')
ca_certs = os.getenv('SSL_CA_CERTS')

def when_ready(server):
    """æœå‹™å™¨å•Ÿå‹•å®Œæˆæ™‚çš„å›èª¿"""
    server.log.info("CyberPuppy API server is ready!")

def worker_int(worker):
    """Worker æ”¶åˆ° SIGINT æ™‚çš„è™•ç†"""
    worker.log.info("Worker received SIGINT, shutting down gracefully")

def on_exit(server):
    """æœå‹™å™¨é€€å‡ºæ™‚çš„æ¸…ç†å·¥ä½œ"""
    server.log.info("CyberPuppy API server shutting down")
```

## ç›£æ§èˆ‡æ—¥èªŒ (Monitoring & Logging)

### 1. æ—¥èªŒé…ç½®

#### logging_config.py
```python
"""
çµæ§‹åŒ–æ—¥èªŒé…ç½®
"""

import logging.config
import os
from pythonjsonlogger import jsonlogger

LOGGING_CONFIG = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'json': {
            '()': jsonlogger.JsonFormatter,
            'format': '%(asctime)s %(name)s %(levelname)s %(message)s'
        },
        'verbose': {
            'format': '%(asctime)s [%(levelname)s] %(name)s: %(message)s'
        }
    },
    'handlers': {
        'console': {
            'class': 'logging.StreamHandler',
            'formatter': 'json' if os.getenv('LOG_FORMAT') == 'json' else 'verbose',
            'stream': 'ext://sys.stdout'
        },
        'file': {
            'class': 'logging.handlers.RotatingFileHandler',
            'formatter': 'json',
            'filename': os.getenv('LOG_FILE', '/var/log/cyberpuppy/app.log'),
            'maxBytes': 50 * 1024 * 1024,  # 50MB
            'backupCount': 10
        }
    },
    'loggers': {
        'cyberpuppy': {
            'handlers': ['console', 'file'],
            'level': os.getenv('LOG_LEVEL', 'INFO'),
            'propagate': False
        },
        'uvicorn': {
            'handlers': ['console', 'file'],
            'level': 'INFO',
            'propagate': False
        }
    },
    'root': {
        'handlers': ['console'],
        'level': 'WARNING'
    }
}

def setup_logging():
    """è¨­å®šæ—¥èªŒé…ç½®"""
    # å»ºç«‹æ—¥èªŒç›®éŒ„
    log_file = os.getenv('LOG_FILE', '/var/log/cyberpuppy/app.log')
    log_dir = os.path.dirname(log_file)
    os.makedirs(log_dir, exist_ok=True)

    logging.config.dictConfig(LOGGING_CONFIG)
```

### 2. Prometheus ç›£æ§

#### metrics.py
```python
"""
Prometheus æŒ‡æ¨™æ”¶é›†
"""

from prometheus_client import Counter, Histogram, Gauge, generate_latest
import time
from functools import wraps

# å®šç¾©æŒ‡æ¨™
REQUEST_COUNT = Counter(
    'cyberpuppy_requests_total',
    'Total API requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'cyberpuppy_request_duration_seconds',
    'API request duration',
    ['method', 'endpoint']
)

PREDICTION_COUNT = Counter(
    'cyberpuppy_predictions_total',
    'Total predictions made',
    ['toxicity_level']
)

MODEL_LOAD_TIME = Gauge(
    'cyberpuppy_model_load_time_seconds',
    'Time taken to load models'
)

ACTIVE_CONNECTIONS = Gauge(
    'cyberpuppy_active_connections',
    'Number of active connections'
)

def metrics_middleware(app):
    """Prometheus æŒ‡æ¨™ä¸­ä»‹å±¤"""

    @wraps(app)
    async def wrapper(scope, receive, send):
        if scope["type"] != "http":
            await app(scope, receive, send)
            return

        start_time = time.time()
        method = scope["method"]
        path = scope["path"]

        # å¢åŠ æ´»èºé€£æ¥æ•¸
        ACTIVE_CONNECTIONS.inc()

        try:
            # åŒ…è£ send å‡½æ•¸ä»¥æ•æ‰ç‹€æ…‹ç¢¼
            status_code = 200

            async def wrapped_send(message):
                nonlocal status_code
                if message["type"] == "http.response.start":
                    status_code = message["status"]
                await send(message)

            await app(scope, receive, wrapped_send)

        finally:
            # è¨˜éŒ„æŒ‡æ¨™
            duration = time.time() - start_time

            REQUEST_COUNT.labels(
                method=method,
                endpoint=path,
                status=status_code
            ).inc()

            REQUEST_DURATION.labels(
                method=method,
                endpoint=path
            ).observe(duration)

            # æ¸›å°‘æ´»èºé€£æ¥æ•¸
            ACTIVE_CONNECTIONS.dec()

    return wrapper

def record_prediction(toxicity_level: str):
    """è¨˜éŒ„é æ¸¬çµæœ"""
    PREDICTION_COUNT.labels(toxicity_level=toxicity_level).inc()
```

### 3. å¥åº·æª¢æŸ¥ç«¯é»å¢å¼·

#### æ›´æ–° app.py ä¸­çš„å¥åº·æª¢æŸ¥
```python
from prometheus_client import generate_latest, CONTENT_TYPE_LATEST

@app.get("/metrics")
async def get_metrics():
    """Prometheus æŒ‡æ¨™ç«¯é»"""
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

@app.get("/healthz")
async def enhanced_health_check():
    """å¢å¼·ç‰ˆå¥åº·æª¢æŸ¥"""
    health_data = {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0",
        "uptime_seconds": time.time() - start_time,
        "checks": {}
    }

    # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
    try:
        if model_loader and model_loader.detector:
            health_data["checks"]["model"] = "healthy"
        else:
            health_data["checks"]["model"] = "unhealthy"
            health_data["status"] = "degraded"
    except Exception:
        health_data["checks"]["model"] = "error"
        health_data["status"] = "degraded"

    # æª¢æŸ¥è³‡æ–™åº«é€£æ¥
    try:
        # å‡è¨­æœ‰è³‡æ–™åº«é€£æ¥æª¢æŸ¥å‡½æ•¸
        # check_database_connection()
        health_data["checks"]["database"] = "healthy"
    except Exception:
        health_data["checks"]["database"] = "unhealthy"
        health_data["status"] = "degraded"

    # æª¢æŸ¥ Redis é€£æ¥
    try:
        # check_redis_connection()
        health_data["checks"]["cache"] = "healthy"
    except Exception:
        health_data["checks"]["cache"] = "degraded"
        # Redis å¤±æ•—ä¸å½±éŸ¿æ•´é«”ç‹€æ…‹

    # æ ¹æ“šæª¢æŸ¥çµæœæ±ºå®š HTTP ç‹€æ…‹ç¢¼
    status_code = 200 if health_data["status"] == "healthy" else 503

    return JSONResponse(health_data, status_code=status_code)
```

## å®‰å…¨å¼·åŒ– (Security Hardening)

### 1. Nginx åå‘ä»£ç†é…ç½®

#### nginx.conf
```nginx
events {
    worker_connections 1024;
}

http {
    # åŸºæœ¬è¨­å®š
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;
    server_tokens off;

    # å®‰å…¨æ¨™é ­
    add_header X-Frame-Options DENY always;
    add_header X-Content-Type-Options nosniff always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;

    # é™æµè¨­å®š
    limit_req_zone $binary_remote_addr zone=api:10m rate=30r/m;
    limit_conn_zone $binary_remote_addr zone=conn:10m;

    # ä¸Šæ¸¸æœå‹™å™¨
    upstream cyberpuppy_api {
        least_conn;
        server cyberpuppy-api:8000 max_fails=3 fail_timeout=30s;
        keepalive 32;
    }

    server {
        listen 80;
        server_name api.cyberpuppy.ai;
        return 301 https://$server_name$request_uri;
    }

    server {
        listen 443 ssl http2;
        server_name api.cyberpuppy.ai;

        # SSL é…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
        ssl_prefer_server_ciphers off;

        # é™åˆ¶è«‹æ±‚å¤§å°
        client_max_body_size 1M;

        # é™æµ
        limit_req zone=api burst=10 nodelay;
        limit_conn conn 10;

        # ä»£ç†è¨­å®š
        location / {
            proxy_pass http://cyberpuppy_api;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
            proxy_read_timeout 300s;
            proxy_connect_timeout 75s;
        }

        # å¥åº·æª¢æŸ¥ç«¯é»ä¸é™æµ
        location /healthz {
            proxy_pass http://cyberpuppy_api;
            access_log off;
        }

        # éœæ…‹æª”æ¡ˆï¼ˆå¦‚æœæœ‰ï¼‰
        location /static/ {
            alias /var/www/static/;
            expires 1y;
            add_header Cache-Control "public, immutable";
        }
    }
}
```

### 2. é˜²ç«ç‰†è¦å‰‡

#### iptables è¦å‰‡
```bash
#!/bin/bash
# firewall_rules.sh - è¨­å®šé˜²ç«ç‰†è¦å‰‡

# æ¸…ç©ºç¾æœ‰è¦å‰‡
iptables -F
iptables -X
iptables -t nat -F
iptables -t nat -X
iptables -t mangle -F
iptables -t mangle -X

# é è¨­æ”¿ç­–
iptables -P INPUT DROP
iptables -P FORWARD DROP
iptables -P OUTPUT ACCEPT

# å…è¨± loopback
iptables -A INPUT -i lo -j ACCEPT
iptables -A OUTPUT -o lo -j ACCEPT

# å…è¨±å·²å»ºç«‹çš„é€£æ¥
iptables -A INPUT -m conntrack --ctstate ESTABLISHED,RELATED -j ACCEPT

# å…è¨± SSH (é™åˆ¶ä¾†æº IP)
iptables -A INPUT -p tcp --dport 22 -s YOUR_ADMIN_IP -j ACCEPT

# å…è¨± HTTP/HTTPS
iptables -A INPUT -p tcp --dport 80 -j ACCEPT
iptables -A INPUT -p tcp --dport 443 -j ACCEPT

# å…è¨±å…§éƒ¨ç¶²è·¯é€£æ¥åˆ° API
iptables -A INPUT -p tcp --dport 8000 -s 172.17.0.0/16 -j ACCEPT

# DDoS ä¿è­·
iptables -A INPUT -p tcp --dport 80 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT
iptables -A INPUT -p tcp --dport 443 -m limit --limit 25/minute --limit-burst 100 -j ACCEPT

# è¨˜éŒ„ä¸¦ä¸Ÿæ£„å…¶ä»–æµé‡
iptables -A INPUT -j LOG --log-prefix "DROPPED: "
iptables -A INPUT -j DROP

# ä¿å­˜è¦å‰‡
iptables-save > /etc/iptables/rules.v4

echo "Firewall rules applied successfully!"
```

## æ•…éšœæ’é™¤ (Troubleshooting)

### 1. å¸¸è¦‹å•é¡Œè¨ºæ–·

#### è¨ºæ–·è…³æœ¬
```bash
#!/bin/bash
# diagnose.sh - ç³»çµ±è¨ºæ–·è…³æœ¬

echo "ğŸ” CyberPuppy API ç³»çµ±è¨ºæ–·"
echo "=========================="

# æª¢æŸ¥æœå‹™ç‹€æ…‹
echo -e "\nğŸ“Š æœå‹™ç‹€æ…‹:"
if command -v docker-compose &> /dev/null; then
    docker-compose ps
elif command -v kubectl &> /dev/null; then
    kubectl get pods -n cyberpuppy
fi

# æª¢æŸ¥ API å¥åº·ç‹€æ…‹
echo -e "\nğŸ¥ API å¥åº·æª¢æŸ¥:"
curl -s http://localhost:8000/healthz | jq '.' || echo "API ä¸å¯ç”¨æˆ– jq æœªå®‰è£"

# æª¢æŸ¥è³‡æºä½¿ç”¨
echo -e "\nğŸ’¾ è³‡æºä½¿ç”¨ç‹€æ³:"
echo "Memory:"
free -h
echo -e "\nDisk:"
df -h
echo -e "\nCPU:"
top -bn1 | head -5

# æª¢æŸ¥æ—¥èªŒéŒ¯èª¤
echo -e "\nğŸ“ æœ€è¿‘çš„éŒ¯èª¤æ—¥èªŒ:"
if [ -f "/var/log/cyberpuppy/app.log" ]; then
    tail -20 /var/log/cyberpuppy/app.log | grep -i error || echo "æ²’æœ‰ç™¼ç¾éŒ¯èª¤"
else
    echo "æ—¥èªŒæª”æ¡ˆä¸å­˜åœ¨"
fi

# æª¢æŸ¥ç¶²è·¯é€£æ¥
echo -e "\nğŸŒ ç¶²è·¯é€£æ¥æ¸¬è©¦:"
curl -s -o /dev/null -w "API Response Time: %{time_total}s\n" http://localhost:8000/healthz

# æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ
echo -e "\nğŸ¤– æ¨¡å‹æª”æ¡ˆæª¢æŸ¥:"
MODEL_PATH="/app/models"
if [ -d "$MODEL_PATH" ]; then
    ls -la "$MODEL_PATH"
else
    echo "æ¨¡å‹ç›®éŒ„ä¸å­˜åœ¨: $MODEL_PATH"
fi

echo -e "\nâœ… è¨ºæ–·å®Œæˆ"
```

### 2. æ•ˆèƒ½èª¿å„ª

#### æ•ˆèƒ½ç›£æ§è…³æœ¬
```python
#!/usr/bin/env python3
"""
performance_monitor.py - æ•ˆèƒ½ç›£æ§è…³æœ¬
"""

import time
import requests
import statistics
import concurrent.futures
from datetime import datetime

class PerformanceMonitor:
    def __init__(self, base_url="http://localhost:8000"):
        self.base_url = base_url
        self.results = []

    def single_request_test(self):
        """å–®ä¸€è«‹æ±‚æ¸¬è©¦"""
        start = time.time()
        try:
            response = requests.post(
                f"{self.base_url}/analyze",
                json={"text": "æ¸¬è©¦æ–‡æœ¬"},
                timeout=30
            )
            duration = time.time() - start
            return {
                'duration': duration,
                'status_code': response.status_code,
                'success': response.status_code == 200
            }
        except Exception as e:
            return {
                'duration': time.time() - start,
                'status_code': 0,
                'success': False,
                'error': str(e)
            }

    def concurrent_test(self, concurrent_users=10, requests_per_user=5):
        """ä¸¦è¡Œè² è¼‰æ¸¬è©¦"""
        print(f"ğŸš€ é–‹å§‹ä¸¦è¡Œæ¸¬è©¦: {concurrent_users} ç”¨æˆ¶, æ¯ç”¨æˆ¶ {requests_per_user} è«‹æ±‚")

        def user_test():
            user_results = []
            for _ in range(requests_per_user):
                result = self.single_request_test()
                user_results.append(result)
                time.sleep(0.1)  # é¿å…éæ–¼å¯†é›†çš„è«‹æ±‚
            return user_results

        start_time = time.time()

        with concurrent.futures.ThreadPoolExecutor(max_workers=concurrent_users) as executor:
            futures = [executor.submit(user_test) for _ in range(concurrent_users)]
            all_results = []

            for future in concurrent.futures.as_completed(futures):
                all_results.extend(future.result())

        total_time = time.time() - start_time

        # åˆ†æçµæœ
        successful_requests = [r for r in all_results if r['success']]
        failed_requests = [r for r in all_results if not r['success']]

        if successful_requests:
            durations = [r['duration'] for r in successful_requests]

            print(f"\nğŸ“Š æ¸¬è©¦çµæœ:")
            print(f"ç¸½è«‹æ±‚æ•¸: {len(all_results)}")
            print(f"æˆåŠŸè«‹æ±‚: {len(successful_requests)}")
            print(f"å¤±æ•—è«‹æ±‚: {len(failed_requests)}")
            print(f"æˆåŠŸç‡: {len(successful_requests)/len(all_results)*100:.2f}%")
            print(f"ç¸½æ¸¬è©¦æ™‚é–“: {total_time:.2f} ç§’")
            print(f"å¹³å‡å›æ‡‰æ™‚é–“: {statistics.mean(durations):.3f} ç§’")
            print(f"ä¸­ä½æ•¸å›æ‡‰æ™‚é–“: {statistics.median(durations):.3f} ç§’")
            print(f"95% å›æ‡‰æ™‚é–“: {statistics.quantiles(durations, n=20)[18]:.3f} ç§’")
            print(f"æœ€å¤§å›æ‡‰æ™‚é–“: {max(durations):.3f} ç§’")
            print(f"æœ€å°å›æ‡‰æ™‚é–“: {min(durations):.3f} ç§’")
            print(f"ååé‡: {len(successful_requests)/total_time:.2f} è«‹æ±‚/ç§’")

        if failed_requests:
            print(f"\nâŒ å¤±æ•—è«‹æ±‚è©³æƒ…:")
            for i, req in enumerate(failed_requests[:5]):  # åªé¡¯ç¤ºå‰5å€‹
                print(f"  {i+1}. ç‹€æ…‹ç¢¼: {req['status_code']}, éŒ¯èª¤: {req.get('error', 'Unknown')}")

    def health_check_test(self):
        """å¥åº·æª¢æŸ¥æ¸¬è©¦"""
        print("ğŸ¥ å¥åº·æª¢æŸ¥æ¸¬è©¦...")

        try:
            response = requests.get(f"{self.base_url}/healthz", timeout=10)
            if response.status_code == 200:
                health_data = response.json()
                print(f"âœ… API å¥åº·ç‹€æ…‹: {health_data.get('status', 'unknown')}")
                print(f"   é‹è¡Œæ™‚é–“: {health_data.get('uptime_seconds', 0):.2f} ç§’")

                if 'model_status' in health_data:
                    model_status = health_data['model_status']
                    print(f"   æ¨¡å‹å·²è¼‰å…¥: {model_status.get('models_loaded', False)}")
                    print(f"   è¨ˆç®—è¨­å‚™: {model_status.get('device', 'unknown')}")

            else:
                print(f"âŒ å¥åº·æª¢æŸ¥å¤±æ•—: HTTP {response.status_code}")

        except Exception as e:
            print(f"âŒ å¥åº·æª¢æŸ¥éŒ¯èª¤: {e}")

def main():
    monitor = PerformanceMonitor()

    print("CyberPuppy API æ•ˆèƒ½ç›£æ§")
    print("======================")

    # å¥åº·æª¢æŸ¥
    monitor.health_check_test()

    # å–®ä¸€è«‹æ±‚æ¸¬è©¦
    print(f"\nâš¡ å–®ä¸€è«‹æ±‚æ¸¬è©¦...")
    result = monitor.single_request_test()
    if result['success']:
        print(f"âœ… å–®ä¸€è«‹æ±‚æˆåŠŸ: {result['duration']:.3f} ç§’")
    else:
        print(f"âŒ å–®ä¸€è«‹æ±‚å¤±æ•—: {result.get('error', 'Unknown error')}")

    # ä¸¦è¡Œæ¸¬è©¦
    print(f"\n")
    monitor.concurrent_test(concurrent_users=5, requests_per_user=3)

if __name__ == "__main__":
    main()
```

## ç¶­è­·ä½œæ¥­ (Maintenance Tasks)

### 1. å®šæœŸç¶­è­·è…³æœ¬

#### maintenance.sh
```bash
#!/bin/bash
# maintenance.sh - å®šæœŸç¶­è­·è…³æœ¬

LOG_FILE="/var/log/cyberpuppy/maintenance.log"
MODEL_PATH="/app/models"
BACKUP_PATH="/backup/cyberpuppy"

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log "ğŸ”§ é–‹å§‹å®šæœŸç¶­è­·ä½œæ¥­"

# 1. æ¸…ç†èˆŠæ—¥èªŒ
log "ğŸ“ æ¸…ç†èˆŠæ—¥èªŒæª”æ¡ˆ..."
find /var/log/cyberpuppy/ -name "*.log" -mtime +30 -delete
find /var/log/cyberpuppy/ -name "*.log.*" -mtime +7 -delete

# 2. å‚™ä»½è³‡æ–™åº«
log "ğŸ’¾ å‚™ä»½è³‡æ–™åº«..."
if command -v mongodump &> /dev/null; then
    mkdir -p "$BACKUP_PATH/$(date +%Y%m%d)"
    mongodump --uri="$DATABASE_URL" --out="$BACKUP_PATH/$(date +%Y%m%d)/"

    # æ¸…ç†èˆŠå‚™ä»½
    find "$BACKUP_PATH" -type d -mtime +7 -exec rm -rf {} +
fi

# 3. æª¢æŸ¥ç£ç¢Ÿç©ºé–“
log "ğŸ’½ æª¢æŸ¥ç£ç¢Ÿç©ºé–“..."
DISK_USAGE=$(df /var/log | tail -1 | awk '{print $5}' | sed 's/%//')
if [ "$DISK_USAGE" -gt 80 ]; then
    log "âš ï¸  ç£ç¢Ÿä½¿ç”¨ç‡éé«˜: ${DISK_USAGE}%"
    # ç™¼é€å‘Šè­¦ï¼ˆéœ€è¦é…ç½®ï¼‰
    # send_alert "Disk usage high: ${DISK_USAGE}%"
fi

# 4. æ›´æ–°æ¨¡å‹ï¼ˆå¦‚æœæœ‰æ–°ç‰ˆæœ¬ï¼‰
log "ğŸ¤– æª¢æŸ¥æ¨¡å‹æ›´æ–°..."
# é€™è£¡å¯ä»¥åŠ å…¥æ¨¡å‹æ›´æ–°é‚è¼¯

# 5. ç³»çµ±å¥åº·æª¢æŸ¥
log "ğŸ¥ åŸ·è¡Œç³»çµ±å¥åº·æª¢æŸ¥..."
curl -s -f http://localhost:8000/healthz > /dev/null
if [ $? -eq 0 ]; then
    log "âœ… API å¥åº·æª¢æŸ¥é€šé"
else
    log "âŒ API å¥åº·æª¢æŸ¥å¤±æ•—"
    # é‡å•Ÿæœå‹™
    log "ğŸ”„ å˜—è©¦é‡å•Ÿæœå‹™..."
    docker-compose restart cyberpuppy-api
fi

# 6. è¨˜æ†¶é«”ä½¿ç”¨æª¢æŸ¥
log "ğŸ’¾ æª¢æŸ¥è¨˜æ†¶é«”ä½¿ç”¨..."
MEM_USAGE=$(free | grep '^Mem:' | awk '{printf "%.0f", $3/$2*100}')
if [ "$MEM_USAGE" -gt 85 ]; then
    log "âš ï¸  è¨˜æ†¶é«”ä½¿ç”¨ç‡éé«˜: ${MEM_USAGE}%"
fi

log "âœ… å®šæœŸç¶­è­·ä½œæ¥­å®Œæˆ"
```

### 2. æ¨¡å‹æ›´æ–°æµç¨‹

#### model_update.py
```python
#!/usr/bin/env python3
"""
model_update.py - æ¨¡å‹æ›´æ–°è…³æœ¬
"""

import os
import shutil
import hashlib
import requests
from pathlib import Path

class ModelUpdater:
    def __init__(self, model_path="/app/models"):
        self.model_path = Path(model_path)
        self.backup_path = Path("/backup/models")
        self.download_path = Path("/tmp/model_update")

    def check_for_updates(self, version_url="https://api.cyberpuppy.ai/model-version"):
        """æª¢æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æ›´æ–°"""
        try:
            response = requests.get(version_url, timeout=10)
            if response.status_code == 200:
                remote_version = response.json()
                current_version = self.get_current_version()

                return remote_version.get('version') != current_version
        except Exception as e:
            print(f"æª¢æŸ¥æ›´æ–°å¤±æ•—: {e}")
            return False

    def get_current_version(self):
        """å–å¾—ç›®å‰æ¨¡å‹ç‰ˆæœ¬"""
        version_file = self.model_path / "version.txt"
        if version_file.exists():
            return version_file.read_text().strip()
        return "unknown"

    def download_model(self, model_url):
        """ä¸‹è¼‰æ–°æ¨¡å‹"""
        self.download_path.mkdir(parents=True, exist_ok=True)

        try:
            response = requests.get(model_url, stream=True, timeout=300)
            response.raise_for_status()

            model_file = self.download_path / "model.tar.gz"
            with open(model_file, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)

            return model_file
        except Exception as e:
            print(f"æ¨¡å‹ä¸‹è¼‰å¤±æ•—: {e}")
            return None

    def verify_model(self, model_file, expected_hash):
        """é©—è­‰æ¨¡å‹æª”æ¡ˆå®Œæ•´æ€§"""
        sha256_hash = hashlib.sha256()
        with open(model_file, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                sha256_hash.update(chunk)

        return sha256_hash.hexdigest() == expected_hash

    def backup_current_model(self):
        """å‚™ä»½ç›®å‰çš„æ¨¡å‹"""
        if not self.model_path.exists():
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_dir = self.backup_path / f"model_{timestamp}"
        backup_dir.parent.mkdir(parents=True, exist_ok=True)

        shutil.copytree(self.model_path, backup_dir)
        print(f"æ¨¡å‹å·²å‚™ä»½è‡³: {backup_dir}")

    def install_new_model(self, model_file):
        """å®‰è£æ–°æ¨¡å‹"""
        # è§£å£“ç¸®æ¨¡å‹
        import tarfile
        with tarfile.open(model_file, 'r:gz') as tar:
            tar.extractall(self.download_path)

        # ç§»å‹•åˆ°ç›®æ¨™ç›®éŒ„
        extracted_dir = self.download_path / "model"
        if extracted_dir.exists():
            shutil.rmtree(self.model_path)
            shutil.move(extracted_dir, self.model_path)
            print("æ–°æ¨¡å‹å®‰è£å®Œæˆ")
            return True

        return False

    def update_model(self):
        """å®Œæ•´çš„æ¨¡å‹æ›´æ–°æµç¨‹"""
        print("ğŸ¤– é–‹å§‹æ¨¡å‹æ›´æ–°æª¢æŸ¥...")

        if not self.check_for_updates():
            print("âœ… æ¨¡å‹å·²æ˜¯æœ€æ–°ç‰ˆæœ¬")
            return True

        print("ğŸ“¥ ç™¼ç¾æ–°ç‰ˆæœ¬ï¼Œé–‹å§‹ä¸‹è¼‰...")

        # é€™è£¡æ‡‰è©²å¾ API å–å¾—å¯¦éš›çš„ä¸‹è¼‰ URL å’Œé›œæ¹Šå€¼
        model_url = "https://models.cyberpuppy.ai/latest/model.tar.gz"
        expected_hash = "actual_hash_from_api"

        model_file = self.download_model(model_url)
        if not model_file:
            return False

        print("ğŸ” é©—è­‰æ¨¡å‹æª”æ¡ˆ...")
        if not self.verify_model(model_file, expected_hash):
            print("âŒ æ¨¡å‹æª”æ¡ˆé©—è­‰å¤±æ•—")
            return False

        print("ğŸ’¾ å‚™ä»½ç›®å‰æ¨¡å‹...")
        self.backup_current_model()

        print("ğŸ”„ å®‰è£æ–°æ¨¡å‹...")
        if self.install_new_model(model_file):
            print("âœ… æ¨¡å‹æ›´æ–°å®Œæˆï¼Œè«‹é‡å•Ÿæœå‹™")
            return True
        else:
            print("âŒ æ¨¡å‹å®‰è£å¤±æ•—")
            return False

if __name__ == "__main__":
    updater = ModelUpdater()
    updater.update_model()
```

---

**æœ¬æ–‡ä»¶æ¶µè“‹äº† CyberPuppy API çš„å®Œæ•´éƒ¨ç½²æµç¨‹ï¼Œå¾å®¹å™¨åŒ–åˆ°ç”Ÿç”¢ç’°å¢ƒé…ç½®ï¼ŒåŒ…å«ç›£æ§ã€å®‰å…¨ã€ç¶­è­·ç­‰å„å€‹é¢å‘ã€‚è«‹æ ¹æ“šå¯¦éš›éœ€æ±‚é¸æ“‡åˆé©çš„éƒ¨ç½²æ–¹å¼ã€‚**

*æœ€å¾Œæ›´æ–°: 2024-12-30*