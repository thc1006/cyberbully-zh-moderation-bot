# ğŸ¯ éœ¸å‡Œåµæ¸¬æ¨¡å‹æ”¹é€²æŒ‡å—

**ç•¶å‰ç‹€æ…‹**: F1 Score = 0.55 (ç›®æ¨™: 0.75)
**æ’°å¯«æ—¥æœŸ**: 2025-09-25
**ä½œè€…**: CyberPuppy é–‹ç™¼åœ˜éšŠ

---

## ğŸ” å•é¡Œæ ¹æœ¬åŸå› åˆ†æ

### 1. **è³‡æ–™é›†å•é¡Œ (æœ€é—œéµ)**
- **100% åˆæˆæ¨™ç±¤**: ç›®å‰çš„éœ¸å‡Œæ¨™ç±¤å®Œå…¨æ˜¯å¾æ¯’æ€§æ¨™ç±¤è‡ªå‹•ç”Ÿæˆ
- **ç¼ºä¹çœŸå¯¦æ¨™è¨»**: æ²’æœ‰äººå·¥æ¨™è¨»çš„éœ¸å‡Œè¡Œç‚ºè³‡æ–™
- **è³‡æ–™é›†ç¼ºå¤±**: SCCD å’Œ CHNCI ç­‰å°ˆé–€çš„éœ¸å‡Œè³‡æ–™é›†å°šæœªå–å¾—
- **æ¨™ç±¤æ±¡æŸ“**: éœ¸å‡Œèˆ‡æ¯’æ€§æ¨™ç±¤æœ‰å®Œç¾ç›¸é—œæ€§ï¼Œå°è‡´æ¨¡å‹ç„¡æ³•å­¸ç¿’å€åˆ¥

### 2. **æ¨¡å‹æ¶æ§‹é™åˆ¶**
- **å…±äº«è¡¨ç¤ºå•é¡Œ**: éœ¸å‡Œæª¢æ¸¬é ­èˆ‡æ¯’æ€§æª¢æ¸¬å…±ç”¨åº•å±¤ç‰¹å¾µ
- **ç¼ºä¹å°è©±ä¸Šä¸‹æ–‡**: æœªè€ƒæ…®å°è©±åºåˆ—å’Œç¤¾äº¤å‹•æ…‹
- **æ–‡åŒ–ç‰¹å¾µç¼ºå¤±**: æœªé‡å°ä¸­æ–‡ç¶²è·¯éœ¸å‡Œçš„ç‰¹æ®Šæ¨¡å¼å„ªåŒ–

### 3. **è¨“ç·´ä¸è¶³**
- **è¨“ç·´è¼ªæ•¸éå°‘**: åƒ…è¨“ç·´ 2 å€‹ epochs
- **æ¨£æœ¬é‡ä¸è¶³**: åƒ…ä½¿ç”¨ 800 å€‹è¨“ç·´æ¨£æœ¬
- **é¡åˆ¥ä¸å¹³è¡¡**: éœ¸å‡Œé¡åˆ¥åˆ†å¸ƒæ¥µåº¦ä¸å‡

---

## ğŸ“š å­¸è¡“ç´šæ”¹é€²å»ºè­°

### éšæ®µä¸€ï¼šè³‡æ–™é›†æ”¹é€² (é æœŸæå‡ F1: 0.55 â†’ 0.70)

#### 1.1 ç²å–çœŸå¯¦éœ¸å‡Œè³‡æ–™é›†
```python
# å„ªå…ˆç²å–ä»¥ä¸‹è³‡æ–™é›†ï¼š
datasets_needed = {
    "SCCD": "https://arxiv.org/abs/2506.04975",  # æœƒè©±ç´šéœ¸å‡Œ
    "CHNCI": "https://arxiv.org/abs/2506.05380",  # äº‹ä»¶ç´šéœ¸å‡Œ
    "å¾®åšéœ¸å‡Œèªæ–™": "è¯ç¹«ä¸­ç ”é™¢æˆ–æ¸…å¤§ NLP å¯¦é©—å®¤"
}
```

#### 1.2 äººå·¥æ¨™è¨»ç­–ç•¥
```python
# æ¨™è¨»æŒ‡å—
annotation_guidelines = {
    "éœ¸å‡Œå®šç¾©": {
        "ç›´æ¥æ”»æ“Š": "é‡å°å€‹äººçš„ä¾®è¾±ã€å¨è„…",
        "é–“æ¥éœ¸å‡Œ": "æ’æ“ ã€æ•£å¸ƒè¬ è¨€ã€ç¤¾äº¤å­¤ç«‹",
        "ç¶²è·¯ç‰¹æœ‰": "äººè‚‰æœç´¢ã€æƒ¡æ„æ¨™è¨˜ã€ç¾¤é«”æ”»æ“Š"
    },
    "æ¨™è¨»å±¤ç´š": ["ç„¡éœ¸å‡Œ", "è¼•å¾®", "ä¸­åº¦", "åš´é‡"],
    "å¿…è¦ä¸Šä¸‹æ–‡": "è‡³å°‘ 3 è¼ªå°è©±æ­·å²"
}

# å»ºè­°æ¨™è¨» 5000+ ç­†è³‡æ–™
# ä½¿ç”¨ 3 ä½æ¨™è¨»å“¡ï¼Œè¨ˆç®— Kappa ä¸€è‡´æ€§ > 0.7
```

### éšæ®µäºŒï¼šæ¨¡å‹æ¶æ§‹å„ªåŒ– (é æœŸæå‡ F1: 0.70 â†’ 0.80)

#### 2.1 éšå±¤å¼å°è©±å»ºæ¨¡
```python
class HierarchicalBullyingDetector(nn.Module):
    def __init__(self):
        super().__init__()
        # è¨Šæ¯ç´šç·¨ç¢¼å™¨
        self.message_encoder = AutoModel.from_pretrained("hfl/chinese-macbert-base")

        # å°è©±ç´šç·¨ç¢¼å™¨ (ä½¿ç”¨ LSTM æˆ– Transformer)
        self.conversation_encoder = nn.LSTM(
            input_size=768,
            hidden_size=384,
            num_layers=2,
            bidirectional=True,
            batch_first=True
        )

        # ç¤¾äº¤åœ–ç¥ç¶“ç¶²è·¯ (GNN)
        self.social_gnn = GraphAttentionNetwork(
            in_features=768,
            out_features=256,
            n_heads=4
        )

        # éœ¸å‡Œåˆ†é¡é ­ (ç¨ç«‹æ–¼æ¯’æ€§æª¢æ¸¬)
        self.bullying_classifier = nn.Sequential(
            nn.Linear(768 + 768 + 256, 512),  # è¨Šæ¯+å°è©±+ç¤¾äº¤ç‰¹å¾µ
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 4)  # å››ç´šåˆ†é¡
        )
```

#### 2.2 å°æ¯”å­¸ç¿’æ¡†æ¶
```python
# ä½¿ç”¨å°æ¯”å­¸ç¿’å€åˆ†æ¯’æ€§èˆ‡éœ¸å‡Œ
class ContrastiveBullyingLoss(nn.Module):
    def __init__(self, temperature=0.07):
        super().__init__()
        self.temperature = temperature

    def forward(self, toxic_embeddings, bullying_embeddings, labels):
        # å­¸ç¿’æ¯’æ€§ä½†ééœ¸å‡Œ vs éœ¸å‡Œçš„å€åˆ¥
        # ä½¿ç”¨ SimCLR æˆ– SupCon æ¡†æ¶
        pass
```

### éšæ®µä¸‰ï¼šé€²éšæŠ€è¡“ (é æœŸæå‡ F1: 0.80 â†’ 0.90+)

#### 3.1 æ–‡åŒ–æ„ŸçŸ¥å¢å¼·
```python
cultural_augmentation = {
    "è«§éŸ³æ”»æ“Š": "æ™ºéšœ->ã„“ã„“, è…¦æ®˜->NC",
    "è¡¨æƒ…ç¬¦è™Ÿéœ¸å‡Œ": "ğŸ¤¡ğŸ¤®ğŸ’© çµ„åˆä½¿ç”¨",
    "æµè¡Œèªéœ¸å‡Œ": "å°ä¸‘ã€ç ´é˜²ã€æ€¥äº†",
    "ç¾¤é«”æ¨™è¨˜": "@å…¨é«”æˆå“¡ åœæ”»æ¨¡å¼"
}
```

#### 3.2 å¤šæ¨¡æ…‹æ•´åˆ
- æ•´åˆç”¨æˆ¶æ­·å²è¡Œç‚ºæ¨¡å¼
- åˆ†æç™¼æ–‡é »ç‡å’Œæ™‚é–“æ¨¡å¼
- åµæ¸¬å”åŒæ”»æ“Šè¡Œç‚º

#### 3.3 ä¸»å‹•å­¸ç¿’ç­–ç•¥
```python
# å„ªå…ˆæ¨™è¨»æœ€ä¸ç¢ºå®šçš„æ¨£æœ¬
def active_learning_selection(model, unlabeled_data, k=100):
    uncertainties = model.predict_proba(unlabeled_data)
    entropy = -np.sum(uncertainties * np.log(uncertainties), axis=1)
    top_k_indices = np.argsort(entropy)[-k:]
    return unlabeled_data[top_k_indices]
```

---

## ğŸ”¬ å¯¦é©—è¨­è¨ˆå»ºè­°

### 1. åŸºæº–æ¸¬è©¦è¨­ç½®
```python
experiments = {
    "baseline": {
        "data": "COLD + åˆæˆæ¨™ç±¤",
        "model": "MacBERT + ç°¡å–®åˆ†é¡é ­",
        "expected_f1": 0.55
    },
    "phase1": {
        "data": "COLD + SCCD + äººå·¥æ¨™è¨»",
        "model": "MacBERT + ç¨ç«‹éœ¸å‡Œé ­",
        "expected_f1": 0.70
    },
    "phase2": {
        "data": "å…¨é‡è³‡æ–™",
        "model": "éšå±¤å¼å°è©±æ¨¡å‹",
        "expected_f1": 0.80
    },
    "phase3": {
        "data": "å¢å¼·è³‡æ–™é›†",
        "model": "å¤šæ¨¡æ…‹ + GNN",
        "expected_f1": 0.90
    }
}
```

### 2. è©•ä¼°æŒ‡æ¨™
- **ä¸»è¦æŒ‡æ¨™**: Macro F1 (å¹³è¡¡å„é¡åˆ¥)
- **æ¬¡è¦æŒ‡æ¨™**:
  - Precision@é«˜é¢¨éšªé–¾å€¼ (æ¸›å°‘èª¤åˆ¤)
  - Recall@ä½é¢¨éšªé–¾å€¼ (ä¸æ¼æª¢åš´é‡éœ¸å‡Œ)
  - AUC-ROC æ›²ç·š
- **äººå·¥è©•ä¼°**: éš¨æ©ŸæŠ½æ¨£ 100 å€‹æ¡ˆä¾‹äººå·¥å¯©æ ¸

### 3. è¨“ç·´é…ç½®å„ªåŒ–
```python
training_config = {
    "epochs": 20,  # å¢åŠ åˆ° 20 è¼ª
    "batch_size": 16,  # è€ƒæ…® GPU è¨˜æ†¶é«”
    "learning_rate": 2e-5,
    "warmup_steps": 500,
    "weight_decay": 0.01,

    # é¡åˆ¥æ¬Šé‡ (è™•ç†ä¸å¹³è¡¡)
    "class_weights": [1.0, 2.0, 5.0, 10.0],  # ç„¡ã€è¼•ã€ä¸­ã€é‡

    # ç„¦é»æå¤±
    "focal_loss_gamma": 2.0,
    "focal_loss_alpha": 0.25,

    # æ—©åœç­–ç•¥
    "early_stopping_patience": 5,
    "early_stopping_delta": 0.001
}
```

---

## ğŸ“Š é æœŸæ™‚ç¨‹èˆ‡è³‡æº

| éšæ®µ | æ™‚é–“ | äººåŠ› | é æœŸæˆæœ |
|-----|------|------|----------|
| è³‡æ–™æ”¶é›†èˆ‡æ¨™è¨» | 2-3 é€± | 3 äºº | 5000+ æ¨™è¨»æ¨£æœ¬ |
| æ¨¡å‹æ¶æ§‹æ”¹é€² | 1-2 é€± | 2 äºº | F1 æå‡è‡³ 0.70 |
| é€²éšæŠ€è¡“å¯¦ä½œ | 2-3 é€± | 2 äºº | F1 æå‡è‡³ 0.80 |
| å„ªåŒ–èˆ‡èª¿åƒ | 1 é€± | 1 äºº | F1 ç©©å®šåœ¨ 0.85+ |

---

## ğŸš€ å¿«é€Ÿæ”¹é€²æ¸…å–® (1 é€±å…§å¯å®Œæˆ)

1. **ç«‹å³è¡Œå‹•**:
   - [ ] è¯ç¹« SCCD/CHNCI ä½œè€…ç²å–è³‡æ–™é›†
   - [ ] å¾ç¾æœ‰ COLD è³‡æ–™æ‰‹å‹•æ¨™è¨» 1000 ç­†éœ¸å‡Œæ¨£æœ¬
   - [ ] åˆ†é›¢éœ¸å‡Œæª¢æ¸¬é ­ï¼Œé¿å…èˆ‡æ¯’æ€§å…±äº«

2. **è¨“ç·´æ”¹é€²**:
   - [ ] å¢åŠ  epochs è‡³ 10-15
   - [ ] ä½¿ç”¨ focal loss è™•ç†é¡åˆ¥ä¸å¹³è¡¡
   - [ ] å¯¦æ–½è³‡æ–™å¢å¼· (åŒç¾©è©æ›¿æ›ã€åå‘ç¿»è­¯)

3. **è©•ä¼°å„ªåŒ–**:
   - [ ] å»ºç«‹ç¨ç«‹çš„éœ¸å‡Œæ¸¬è©¦é›†
   - [ ] å¯¦æ–½äº¤å‰é©—è­‰
   - [ ] è¨˜éŒ„æ··æ·†çŸ©é™£åˆ†æéŒ¯èª¤æ¨¡å¼

---

## ğŸ“š åƒè€ƒæ–‡ç»

1. **Qian et al. (2024)** - "SCCD: Session-level Chinese Cyberbullying Detection Dataset"
2. **Wang et al. (2023)** - "Hierarchical Attention Networks for Cyberbullying Detection"
3. **Liu et al. (2023)** - "Cultural-Aware Neural Models for Chinese Social Media"
4. **Zhang et al. (2022)** - "Graph Neural Networks for Social Media Abuse Detection"
5. **Chen et al. (2022)** - "Contrastive Learning for Fine-grained Text Classification"

---

## ğŸ’¡ çµè«–

éœ¸å‡Œåµæ¸¬ F1 score å¾ 0.55 æå‡è‡³ 0.75+ æ˜¯å®Œå…¨å¯è¡Œçš„ï¼Œé—œéµåœ¨æ–¼ï¼š
1. **ç²å–çœŸå¯¦æ¨™è¨»è³‡æ–™** (æœ€é‡è¦)
2. **æ”¹é€²æ¨¡å‹æ¶æ§‹**ä»¥æ•æ‰å°è©±ä¸Šä¸‹æ–‡
3. **é‡å°ä¸­æ–‡ç¶²è·¯æ–‡åŒ–**é€²è¡Œå„ªåŒ–

é è¨ˆæŠ•å…¥ 3-4 äººæœˆçš„å·¥ä½œé‡ï¼Œå³å¯é”æˆç›®æ¨™ã€‚å»ºè­°å„ªå…ˆè™•ç†è³‡æ–™å•é¡Œï¼Œé€™å°‡å¸¶ä¾†æœ€å¤§çš„æ”¹é€²æ•ˆæœã€‚

---

**è¯çµ¡äºº**: hctsai@linux.com
**æœ€å¾Œæ›´æ–°**: 2025-09-25