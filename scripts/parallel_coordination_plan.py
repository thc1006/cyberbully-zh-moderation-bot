#!/usr/bin/env python3
"""
CyberPuppy ä¸¦è¡Œå”èª¿åŸ·è¡Œè¨ˆç•«
æˆ°ç•¥è¦åŠƒ Agent çš„æ ¸å¿ƒå”èª¿è…³æœ¬
ç›®æ¨™: F1 å¾ 0.55 æå‡è‡³ 0.75+
"""

import os
import sys
import json
import time
import logging
import subprocess
from pathlib import Path
from typing import Dict, List, Any
from datetime import datetime, timedelta

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - [COORDINATOR] - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('coordination.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)

class StrategicCoordinator:
    """æˆ°ç•¥å”èª¿å™¨ - ç®¡ç†æ‰€æœ‰ agents çš„ä¸¦è¡ŒåŸ·è¡Œ"""

    def __init__(self):
        self.start_time = datetime.now()
        self.target_f1 = 0.75
        self.current_f1 = 0.55
        self.improvement_needed = self.target_f1 - self.current_f1

        self.tasks = {
            "data_augmentation": {
                "status": "pending",
                "agent": "data_augmentation_specialist",
                "priority": "high",
                "estimated_time": "1-2 hours",
                "expected_improvement": 0.03,
                "script": "scripts/run_data_augmentation.py"
            },
            "label_mapping_fix": {
                "status": "pending",
                "agent": "label_mapping_engineer",
                "priority": "critical",
                "estimated_time": "2-3 hours",
                "expected_improvement": 0.05,
                "script": "scripts/fix_label_mapping.py"
            },
            "improved_model_training": {
                "status": "pending",
                "agent": "training_coordinator",
                "priority": "high",
                "estimated_time": "3-6 hours",
                "expected_improvement": 0.15,
                "script": "scripts/train_improved_model.py"
            },
            "performance_monitoring": {
                "status": "pending",
                "agent": "performance_monitor",
                "priority": "medium",
                "estimated_time": "continuous",
                "expected_improvement": 0.0,
                "script": "scripts/monitor_training.py"
            },
            "final_evaluation": {
                "status": "pending",
                "agent": "evaluation_specialist",
                "priority": "medium",
                "estimated_time": "30 minutes",
                "expected_improvement": 0.0,
                "script": "scripts/final_evaluation.py"
            }
        }

        self.risk_factors = {
            "gpu_memory_oom": {"probability": 0.3, "impact": "high", "mitigation": "dynamic_batch_sizing"},
            "training_non_convergence": {"probability": 0.2, "impact": "critical", "mitigation": "early_stopping + lr_scheduling"},
            "data_quality_issues": {"probability": 0.15, "impact": "medium", "mitigation": "multi_layer_validation"},
            "time_overrun": {"probability": 0.25, "impact": "medium", "mitigation": "parallel_execution"}
        }

    def log_status(self, message: str, level: str = "info"):
        """çµ±ä¸€æ—¥èªŒè¨˜éŒ„"""
        elapsed = datetime.now() - self.start_time
        status_msg = f"[{elapsed}] {message}"

        if level == "info":
            logger.info(status_msg)
        elif level == "warning":
            logger.warning(status_msg)
        elif level == "error":
            logger.error(status_msg)
        elif level == "critical":
            logger.critical(status_msg)

    def check_prerequisites(self) -> bool:
        """æª¢æŸ¥åŸ·è¡Œå‰ææ¢ä»¶"""
        self.log_status("æª¢æŸ¥åŸ·è¡Œå‰ææ¢ä»¶...")

        checks = {
            "gpu_available": False,
            "datasets_ready": False,
            "model_architecture_ready": False,
            "training_pipeline_ready": False
        }

        # GPU æª¢æŸ¥
        try:
            import torch
            checks["gpu_available"] = torch.cuda.is_available()
            if checks["gpu_available"]:
                gpu_name = torch.cuda.get_device_name(0)
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                self.log_status(f"GPU æª¢æŸ¥é€šé: {gpu_name} ({gpu_memory:.1f}GB)")
        except Exception as e:
            self.log_status(f"GPU æª¢æŸ¥å¤±æ•—: {e}", "error")

        # è³‡æ–™é›†æª¢æŸ¥
        dataset_files = [
            "data/raw/cold/COLDataset/train.csv",
            "data/raw/chnsenticorp/train.arrow",
            "data/raw/dmsc/DMSC.csv",
            "data/raw/ntusd/data/æ­£é¢è©ç„¡é‡è¤‡_9365è©.txt"
        ]

        missing_files = []
        for file_path in dataset_files:
            if not Path(file_path).exists():
                missing_files.append(file_path)

        checks["datasets_ready"] = len(missing_files) == 0
        if not checks["datasets_ready"]:
            self.log_status(f"ç¼ºå°‘è³‡æ–™é›†æª”æ¡ˆ: {missing_files}", "warning")
        else:
            self.log_status("è³‡æ–™é›†æª¢æŸ¥é€šé: 4/4 å®Œæ•´")

        # æ¨¡å‹æ¶æ§‹æª¢æŸ¥
        model_files = [
            "src/cyberpuppy/models/improved_detector.py",
            "src/cyberpuppy/training/trainer.py"
        ]

        for file_path in model_files:
            if Path(file_path).exists():
                checks["model_architecture_ready"] = True
                break

        if checks["model_architecture_ready"]:
            self.log_status("æ¨¡å‹æ¶æ§‹æª¢æŸ¥é€šé")
        else:
            self.log_status("æ¨¡å‹æ¶æ§‹æª”æ¡ˆç¼ºå¤±", "error")

        # è¨“ç·´ pipeline æª¢æŸ¥
        pipeline_files = [
            "scripts/train_improved_model.py"
        ]

        checks["training_pipeline_ready"] = all(Path(f).exists() for f in pipeline_files)
        if checks["training_pipeline_ready"]:
            self.log_status("è¨“ç·´ pipeline æª¢æŸ¥é€šé")
        else:
            self.log_status("è¨“ç·´ pipeline æª”æ¡ˆç¼ºå¤±", "error")

        # ç¸½çµ
        all_ready = all(checks.values())
        if all_ready:
            self.log_status("âœ… æ‰€æœ‰å‰ææ¢ä»¶æª¢æŸ¥é€šéï¼Œæº–å‚™é–‹å§‹åŸ·è¡Œ")
        else:
            failed_checks = [k for k, v in checks.items() if not v]
            self.log_status(f"âŒ å‰ææ¢ä»¶æª¢æŸ¥å¤±æ•—: {failed_checks}", "error")

        return all_ready

    def estimate_timeline(self) -> Dict[str, Any]:
        """ä¼°ç®—åŸ·è¡Œæ™‚é–“ç·š"""
        timeline = {
            "total_estimated_time": "5-9 hours",
            "critical_path": ["label_mapping_fix", "improved_model_training", "final_evaluation"],
            "parallel_tasks": ["data_augmentation", "performance_monitoring"],
            "milestones": {
                "data_preparation_complete": "2-3 hours",
                "training_started": "3-4 hours",
                "first_evaluation": "6-8 hours",
                "target_achieved": "5-9 hours"
            }
        }

        self.log_status(f"æ™‚é–“ç·šä¼°ç®—: {timeline['total_estimated_time']}")
        self.log_status(f"é—œéµè·¯å¾‘: {' -> '.join(timeline['critical_path'])}")

        return timeline

    def calculate_success_probability(self) -> float:
        """è¨ˆç®—æˆåŠŸæ©Ÿç‡"""
        base_probability = 0.75  # åŸºæ–¼ç¾æœ‰åŸºç¤è¨­æ–½çš„åŸºæœ¬æˆåŠŸç‡

        # é¢¨éšªèª¿æ•´
        risk_impact = sum(
            rf["probability"] * (0.2 if rf["impact"] == "medium" else 0.4 if rf["impact"] == "high" else 0.6)
            for rf in self.risk_factors.values()
        )

        # æ”¹é€²ç­–ç•¥åŠ æˆ
        strategy_bonus = 0.15  # åŸºæ–¼å·²å¯¦ä½œçš„æ”¹é€²ç­–ç•¥

        final_probability = max(0.1, min(0.95, base_probability - risk_impact + strategy_bonus))

        self.log_status(f"æˆåŠŸæ©Ÿç‡ä¼°ç®—: {final_probability:.1%}")
        return final_probability

    def generate_execution_report(self) -> Dict[str, Any]:
        """ç”ŸæˆåŸ·è¡Œå ±å‘Š"""
        report = {
            "coordination_summary": {
                "start_time": self.start_time.isoformat(),
                "target_f1": self.target_f1,
                "current_f1": self.current_f1,
                "improvement_needed": self.improvement_needed,
                "success_probability": self.calculate_success_probability()
            },
            "task_allocation": self.tasks,
            "risk_assessment": self.risk_factors,
            "timeline": self.estimate_timeline(),
            "resource_allocation": {
                "gpu_memory": "3.5GB (RTX 3050)",
                "batch_size_range": "4-8 (å‹•æ…‹)",
                "fp16_enabled": True,
                "gradient_accumulation": "4-8 steps"
            },
            "success_criteria": {
                "primary": "éœ¸å‡Œåµæ¸¬ F1 â‰¥ 0.75",
                "secondary": [
                    "æ¯’æ€§åµæ¸¬ F1 â‰¥ 0.77",
                    "è¨“ç·´æ™‚é–“ â‰¤ 9 å°æ™‚",
                    "GPU è¨˜æ†¶é«”ç©©å®šä½¿ç”¨"
                ]
            }
        }

        return report

def main():
    """ä¸»å”èª¿å‡½æ•¸"""
    coordinator = StrategicCoordinator()

    print("=" * 80)
    print("ğŸ¯ CyberPuppy æˆ°ç•¥å”èª¿åŸ·è¡Œé–‹å§‹")
    print("=" * 80)

    # æª¢æŸ¥å‰ææ¢ä»¶
    if not coordinator.check_prerequisites():
        print("âŒ å‰ææ¢ä»¶æª¢æŸ¥å¤±æ•—ï¼Œè«‹å…ˆè§£æ±ºå•é¡Œå¾Œå†åŸ·è¡Œ")
        sys.exit(1)

    # ç”ŸæˆåŸ·è¡Œå ±å‘Š
    report = coordinator.generate_execution_report()

    # ä¿å­˜å ±å‘Š
    report_path = Path("coordination_execution_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    coordinator.log_status(f"åŸ·è¡Œå ±å‘Šå·²ä¿å­˜: {report_path}")

    # é¡¯ç¤ºé—œéµè³‡è¨Š
    print(f"\nğŸ“Š åŸ·è¡Œæ‘˜è¦:")
    print(f"  ç›®æ¨™: F1 {coordinator.current_f1} â†’ {coordinator.target_f1}")
    print(f"  æ”¹é€²å¹…åº¦: +{coordinator.improvement_needed:.2f}")
    print(f"  é ä¼°æ™‚é–“: {report['timeline']['total_estimated_time']}")
    print(f"  æˆåŠŸæ©Ÿç‡: {report['coordination_summary']['success_probability']:.1%}")

    print(f"\nğŸ”„ ä»»å‹™åˆ†é…:")
    for task_name, task_info in coordinator.tasks.items():
        print(f"  {task_name}: {task_info['agent']} ({task_info['priority']} å„ªå…ˆç´š)")

    print(f"\nâš ï¸  é¢¨éšªç®¡æ§:")
    for risk_name, risk_info in coordinator.risk_factors.items():
        print(f"  {risk_name}: {risk_info['probability']:.0%} æ©Ÿç‡, {risk_info['impact']} å½±éŸ¿")

    print(f"\nâœ… æˆ°ç•¥å”èª¿å®Œæˆï¼Œæº–å‚™é–‹å§‹ä¸¦è¡ŒåŸ·è¡Œ")
    print("=" * 80)

if __name__ == "__main__":
    main()