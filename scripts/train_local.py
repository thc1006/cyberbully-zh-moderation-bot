#!/usr/bin/env python3
"""
CyberPuppy æœ¬åœ°è¨“ç·´å•Ÿå‹•å™¨
é‡å° Windows RTX 3050 å„ªåŒ–çš„ç”¨æˆ¶å‹å¥½è¨“ç·´ç•Œé¢

Features:
- è‡ªå‹•æª¢æ¸¬ GPU (RTX 3050 å„ªåŒ–)
- äº’å‹•å¼ CLI é…ç½®é¸æ“‡
- å½©è‰²çµ‚ç«¯è¼¸å‡º (Windows ç›¸å®¹)
- è¨“ç·´é€²åº¦è¿½è¹¤èˆ‡ ETA
- OOM éŒ¯èª¤è‡ªå‹•æ¢å¾©
- è‡ªå‹•æª¢æŸ¥é»ä¿å­˜
- å®Œæ•´è©•ä¼°å ±å‘Šç”Ÿæˆ
"""

import os
import sys
import json
import time
import logging
import warnings
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime, timedelta

# ç¢ºä¿ colorama åœ¨ Windows ä¸Šæ­£å¸¸å·¥ä½œ
try:
    import colorama
    from colorama import Fore, Back, Style, init
    init(autoreset=True)  # Windows è‡ªå‹•é‡ç½®é¡è‰²
    COLORS_AVAILABLE = True
except ImportError:
    # Fallback ç„¡é¡è‰²æ¨¡å¼
    class DummyColor:
        def __getattr__(self, name): return ""
    Fore = Back = Style = DummyColor()
    COLORS_AVAILABLE = False

import torch
import numpy as np
from tqdm.auto import tqdm

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

try:
    from src.cyberpuppy.config import settings
    from src.cyberpuppy.training.config import (
        TrainingPipelineConfig, ConfigManager,
        OptimizerConfig, DataConfig, ModelConfig,
        TrainingConfig, ResourceConfig, ExperimentConfig
    )
    from src.cyberpuppy.training.trainer import MultitaskTrainer, create_trainer
    from src.cyberpuppy.models.multitask import MultiTaskBullyingDetector
except ImportError as e:
    print(f"âŒ ç„¡æ³•å°å…¥ CyberPuppy æ¨¡çµ„: {e}")
    print("è«‹ç¢ºä¿åœ¨å°ˆæ¡ˆæ ¹ç›®éŒ„åŸ·è¡Œæ­¤è…³æœ¬")
    sys.exit(1)

# æŠ‘åˆ¶è­¦å‘Šä»¥ä¿æŒè¼¸å‡ºæ¸…æ½”
warnings.filterwarnings("ignore", category=UserWarning)
os.environ["TOKENIZERS_PARALLELISM"] = "false"

class WindowsTrainingLauncher:
    """Windows å„ªåŒ–çš„è¨“ç·´å•Ÿå‹•å™¨"""

    def __init__(self):
        self.config_manager = ConfigManager()
        self.device_info = self._detect_system()
        self.training_config = None
        self.start_time = None

        # è¨­ç½®æ—¥èªŒ
        self._setup_logging()

        # é å®šç¾©é…ç½®æ¨¡æ¿
        self.config_templates = {
            "conservative": "è¨˜æ†¶é«”ä¿å®ˆå‹ (RTX 3050 å®‰å…¨)",
            "aggressive": "æ€§èƒ½æ¿€é€²å‹ (éœ€è¦è‰¯å¥½æ•£ç†±)",
            "roberta": "RoBERTa æ¨¡å‹ (æ›´å¤§ä½†æ›´æº–ç¢º)",
            "custom": "è‡ªå®šç¾©é…ç½®"
        }

    def _setup_logging(self):
        """è¨­ç½®æ—¥èªŒè¼¸å‡º"""
        log_dir = PROJECT_ROOT / "logs"
        log_dir.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = log_dir / f"training_local_{timestamp}.log"

        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )

    def _detect_system(self) -> Dict[str, Any]:
        """æª¢æ¸¬ç³»çµ±è³‡æº (å°ˆç‚º RTX 3050 å„ªåŒ–)"""
        info = {
            "platform": sys.platform,
            "cuda_available": torch.cuda.is_available(),
            "gpu_count": 0,
            "gpu_name": "Unknown",
            "gpu_memory_gb": 0,
            "cpu_count": os.cpu_count(),
            "recommended_config": "conservative"
        }

        if torch.cuda.is_available():
            info["gpu_count"] = torch.cuda.device_count()

            for i in range(info["gpu_count"]):
                props = torch.cuda.get_device_properties(i)
                info["gpu_name"] = props.name
                info["gpu_memory_gb"] = props.total_memory / (1024 ** 3)

                # RTX 3050 ç‰¹å®šå„ªåŒ–æª¢æ¸¬
                if "3050" in props.name or info["gpu_memory_gb"] <= 4.5:
                    info["is_rtx_3050"] = True
                    info["recommended_config"] = "conservative"
                elif info["gpu_memory_gb"] >= 6:
                    info["recommended_config"] = "aggressive"

        return info

    def _print_header(self):
        """é¡¯ç¤ºæ­¡è¿æ¨™é¡Œ"""
        print(f"{Fore.CYAN}{Style.BRIGHT}")
        print("=" * 70)
        print("ğŸ• CyberPuppy æœ¬åœ°è¨“ç·´å•Ÿå‹•å™¨")
        print("   ä¸­æ–‡ç¶²è·¯éœ¸å‡Œæª¢æ¸¬æ¨¡å‹è¨“ç·´ç³»çµ±")
        print("=" * 70)
        print(f"{Style.RESET_ALL}")

    def _print_system_info(self):
        """é¡¯ç¤ºç³»çµ±è³‡è¨Š"""
        print(f"{Fore.YELLOW}{Style.BRIGHT}ğŸ–¥ï¸  ç³»çµ±è³‡è¨Š{Style.RESET_ALL}")
        print(f"   ä½œæ¥­ç³»çµ±: {self.device_info['platform']}")
        print(f"   CPU æ ¸å¿ƒ: {self.device_info['cpu_count']}")

        if self.device_info["cuda_available"]:
            gpu_name = self.device_info["gpu_name"]
            gpu_memory = self.device_info["gpu_memory_gb"]

            # RTX 3050 ç‰¹åˆ¥æ¨™ç¤º
            if "3050" in gpu_name:
                status_icon = "âœ…"
                status_color = Fore.GREEN
                status_text = "(å·²å„ªåŒ–)"
            elif gpu_memory <= 4.5:
                status_icon = "âš ï¸"
                status_color = Fore.YELLOW
                status_text = "(ä½è¨˜æ†¶é«”)"
            else:
                status_icon = "ğŸš€"
                status_color = Fore.GREEN
                status_text = "(é«˜æ€§èƒ½)"

            print(f"   GPU: {status_color}{gpu_name} ({gpu_memory:.1f}GB) {status_icon} {status_text}{Style.RESET_ALL}")
            print(f"   æ¨è–¦é…ç½®: {Fore.CYAN}{self.device_info['recommended_config']}{Style.RESET_ALL}")
        else:
            print(f"   {Fore.RED}âŒ GPU ä¸å¯ç”¨ï¼Œå°‡ä½¿ç”¨ CPU è¨“ç·´{Style.RESET_ALL}")

        print()

    def _select_config_template(self) -> str:
        """é¸æ“‡é…ç½®æ¨¡æ¿"""
        print(f"{Fore.YELLOW}{Style.BRIGHT}âš™ï¸  é¸æ“‡è¨“ç·´é…ç½®{Style.RESET_ALL}")

        # æ ¹æ“šç¡¬é«”æ¨è–¦é…ç½®
        recommended = self.device_info["recommended_config"]

        for i, (key, desc) in enumerate(self.config_templates.items(), 1):
            marker = f"{Fore.GREEN}[æ¨è–¦]" if key == recommended else "     "
            print(f"   {i}. {marker} {Fore.CYAN}{key.upper():<12}{Style.RESET_ALL} - {desc}")

        print()

        while True:
            try:
                choice = input(f"è«‹é¸æ“‡é…ç½® (1-{len(self.config_templates)}) [{list(self.config_templates.keys()).index(recommended) + 1}]: ").strip()

                if not choice:  # ä½¿ç”¨é è¨­æ¨è–¦
                    return recommended

                choice_idx = int(choice) - 1
                if 0 <= choice_idx < len(self.config_templates):
                    return list(self.config_templates.keys())[choice_idx]
                else:
                    print(f"{Fore.RED}âŒ è«‹è¼¸å…¥ 1-{len(self.config_templates)} ä¹‹é–“çš„æ•¸å­—{Style.RESET_ALL}")

            except ValueError:
                print(f"{Fore.RED}âŒ è«‹è¼¸å…¥æœ‰æ•ˆæ•¸å­—{Style.RESET_ALL}")

    def _get_training_params(self) -> Dict[str, Any]:
        """ç²å–è¨“ç·´åƒæ•¸"""
        params = {}

        print(f"{Fore.YELLOW}{Style.BRIGHT}ğŸ“Š è¨“ç·´åƒæ•¸è¨­å®š{Style.RESET_ALL}")

        # è¨“ç·´è¼ªæ•¸
        while True:
            try:
                epochs = input("è¨“ç·´è¼ªæ•¸ (epochs) [10]: ").strip()
                epochs = int(epochs) if epochs else 10
                if 1 <= epochs <= 100:
                    params["epochs"] = epochs
                    break
                else:
                    print(f"{Fore.RED}âŒ è¨“ç·´è¼ªæ•¸æ‡‰åœ¨ 1-100 ä¹‹é–“{Style.RESET_ALL}")
            except ValueError:
                print(f"{Fore.RED}âŒ è«‹è¼¸å…¥æœ‰æ•ˆæ•¸å­—{Style.RESET_ALL}")

        # è³‡æ–™å¢å¼·
        augment = input("å•Ÿç”¨è³‡æ–™å¢å¼·? (y/N) [N]: ").strip().lower()
        params["data_augmentation"] = augment in ('y', 'yes', '1', 'true')

        # æ—©åœè€å¿ƒ
        while True:
            try:
                patience = input("æ—©åœè€å¿ƒå€¼ (æ²’æ”¹å–„å°±åœæ­¢) [3]: ").strip()
                patience = int(patience) if patience else 3
                if 1 <= patience <= 10:
                    params["early_stopping_patience"] = patience
                    break
                else:
                    print(f"{Fore.RED}âŒ è€å¿ƒå€¼æ‡‰åœ¨ 1-10 ä¹‹é–“{Style.RESET_ALL}")
            except ValueError:
                print(f"{Fore.RED}âŒ è«‹è¼¸å…¥æœ‰æ•ˆæ•¸å­—{Style.RESET_ALL}")

        print()
        return params

    def _create_training_config(self, template: str, params: Dict[str, Any]) -> TrainingPipelineConfig:
        """å‰µå»ºè¨“ç·´é…ç½®"""
        # æ ¹æ“šæ¨¡æ¿é¸æ“‡åŸºç¤é…ç½®
        if template == "conservative":
            config = self.config_manager.get_template("memory_efficient")
            config.model.model_name = "hfl/chinese-macbert-base"
            config.data.batch_size = 4
            config.data.gradient_accumulation_steps = 4
            config.training.fp16 = True
            config.optimizer.lr = 2e-5

        elif template == "aggressive":
            config = self.config_manager.get_template("production")
            config.model.model_name = "hfl/chinese-macbert-base"
            config.data.batch_size = 8
            config.data.gradient_accumulation_steps = 2
            config.training.fp16 = True
            config.optimizer.lr = 3e-5

        elif template == "roberta":
            config = self.config_manager.get_template("production")
            config.model.model_name = "hfl/chinese-roberta-wwm-ext"
            config.data.batch_size = 4  # RoBERTa æ›´å¤§ï¼Œé™ä½ batch size
            config.data.gradient_accumulation_steps = 4
            config.training.fp16 = True
            config.optimizer.lr = 1e-5

        else:  # custom
            config = self.config_manager.get_template("default")

        # æ‡‰ç”¨ç”¨æˆ¶åƒæ•¸
        config.training.num_epochs = params["epochs"]
        config.data.data_augmentation = params["data_augmentation"]
        config.training.early_stopping_patience = params["early_stopping_patience"]

        # RTX 3050 ç‰¹å®šå„ªåŒ–
        if self.device_info.get("is_rtx_3050", False) or self.device_info["gpu_memory_gb"] <= 4.5:
            config.data.batch_size = min(config.data.batch_size, 4)
            config.data.gradient_accumulation_steps = max(config.data.gradient_accumulation_steps, 4)
            config.resources.dataloader_pin_memory = False
            config.resources.empty_cache_steps = 50
            config.model.gradient_checkpointing = True

        # è¨­ç½®å¯¦é©—åç¨±
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        config.experiment.name = f"local_training_{template}_{timestamp}"
        config.experiment.description = f"æœ¬åœ°è¨“ç·´ - {template} é…ç½®"

        return config

    def _show_config_summary(self, config: TrainingPipelineConfig):
        """é¡¯ç¤ºé…ç½®æ‘˜è¦"""
        print(f"{Fore.YELLOW}{Style.BRIGHT}ğŸ“‹ è¨“ç·´é…ç½®æ‘˜è¦{Style.RESET_ALL}")
        print(f"   å¯¦é©—åç¨±: {Fore.CYAN}{config.experiment.name}{Style.RESET_ALL}")
        print(f"   æ¨¡å‹: {Fore.GREEN}{config.model.model_name}{Style.RESET_ALL}")
        print(f"   è¨“ç·´è¼ªæ•¸: {config.training.num_epochs}")
        print(f"   æ‰¹æ¬¡å¤§å°: {config.data.batch_size}")
        print(f"   æ¢¯åº¦ç´¯ç©: {config.data.gradient_accumulation_steps}")
        print(f"   å­¸ç¿’ç‡: {config.optimizer.lr}")
        print(f"   æ··åˆç²¾åº¦: {'âœ…' if config.training.fp16 else 'âŒ'}")
        print(f"   è³‡æ–™å¢å¼·: {'âœ…' if config.data.data_augmentation else 'âŒ'}")
        print(f"   æ—©åœè€å¿ƒ: {config.training.early_stopping_patience}")

        # è¨˜æ†¶é«”ä¼°ç®—
        effective_batch = config.data.batch_size * config.data.gradient_accumulation_steps
        estimated_memory = self._estimate_memory_usage(config)

        print(f"   æœ‰æ•ˆæ‰¹æ¬¡å¤§å°: {effective_batch}")
        print(f"   é ä¼°è¨˜æ†¶é«”ç”¨é‡: {Fore.YELLOW}{estimated_memory:.1f}GB{Style.RESET_ALL}")

        # å®‰å…¨æª¢æŸ¥
        if self.device_info["cuda_available"]:
            available_memory = self.device_info["gpu_memory_gb"] * 0.9  # ä¿ç•™ 10%
            if estimated_memory > available_memory:
                print(f"   {Fore.RED}âš ï¸  è¨˜æ†¶é«”ç”¨é‡å¯èƒ½è¶…éå¯ç”¨å®¹é‡ï¼{Style.RESET_ALL}")
            else:
                print(f"   {Fore.GREEN}âœ… è¨˜æ†¶é«”ç”¨é‡å®‰å…¨{Style.RESET_ALL}")

        print()

    def _estimate_memory_usage(self, config: TrainingPipelineConfig) -> float:
        """ä¼°ç®—è¨˜æ†¶é«”ç”¨é‡"""
        # åŸºç¤æ¨¡å‹è¨˜æ†¶é«” (ä¾æ“šæ¨¡å‹å¤§å°)
        if "roberta" in config.model.model_name.lower():
            base_memory = 1.2  # RoBERTa è¼ƒå¤§
        else:
            base_memory = 0.8  # MacBERT

        # æ‰¹æ¬¡å¤§å°å½±éŸ¿
        batch_memory = config.data.batch_size * 0.15

        # æ¢¯åº¦æª¢æŸ¥é»ç¯€çœè¨˜æ†¶é«”
        if config.model.gradient_checkpointing:
            total_memory = (base_memory + batch_memory) * 0.7
        else:
            total_memory = base_memory + batch_memory

        # æ··åˆç²¾åº¦ç¯€çœè¨˜æ†¶é«”
        if config.training.fp16:
            total_memory *= 0.6

        return total_memory

    def _confirm_training(self) -> bool:
        """ç¢ºèªé–‹å§‹è¨“ç·´"""
        print(f"{Fore.YELLOW}{Style.BRIGHT}ğŸš€ é–‹å§‹è¨“ç·´ç¢ºèª{Style.RESET_ALL}")

        # æª¢æŸ¥æ•¸æ“šæ˜¯å¦å­˜åœ¨
        data_dir = PROJECT_ROOT / "data"
        if not data_dir.exists():
            print(f"{Fore.RED}âŒ æ•¸æ“šç›®éŒ„ä¸å­˜åœ¨: {data_dir}{Style.RESET_ALL}")
            print("   è«‹å…ˆåŸ·è¡Œ scripts/download_datasets.py ä¸‹è¼‰æ•¸æ“š")
            return False

        # æª¢æŸ¥ç£ç¢Ÿç©ºé–“ (ä¼°ç®—)
        free_space_gb = self._get_free_disk_space()
        estimated_space_needed = 2.0  # ä¼°ç®—éœ€è¦ 2GB

        if free_space_gb < estimated_space_needed:
            print(f"{Fore.RED}âš ï¸  ç£ç¢Ÿç©ºé–“ä¸è¶³ (éœ€è¦ {estimated_space_needed}GBï¼Œå¯ç”¨ {free_space_gb:.1f}GB){Style.RESET_ALL}")

        print(f"   é ä¼°è¨“ç·´æ™‚é–“: {Fore.CYAN}{self._estimate_training_time()}{Style.RESET_ALL}")
        print(f"   å¯ç”¨ç£ç¢Ÿç©ºé–“: {free_space_gb:.1f}GB")

        confirm = input(f"\nç¢ºèªé–‹å§‹è¨“ç·´? (y/N): ").strip().lower()
        return confirm in ('y', 'yes', '1', 'true')

    def _get_free_disk_space(self) -> float:
        """ç²å–å¯ç”¨ç£ç¢Ÿç©ºé–“ (GB)"""
        try:
            import shutil
            free_bytes = shutil.disk_usage(PROJECT_ROOT).free
            return free_bytes / (1024 ** 3)
        except:
            return 999.9  # ç„¡æ³•æª¢æ¸¬æ™‚è¿”å›å¤§æ•¸å€¼

    def _estimate_training_time(self) -> str:
        """ä¼°ç®—è¨“ç·´æ™‚é–“"""
        if not self.training_config:
            return "æœªçŸ¥"

        # åŸºæ–¼ç¶“é©—å€¼ä¼°ç®—
        epochs = self.training_config.training.num_epochs
        batch_size = self.training_config.data.batch_size

        # RTX 3050 ä¼°ç®— (æ¯å€‹ epoch ç´„ 10-30 åˆ†é˜ï¼Œä¾æ“šæ‰¹æ¬¡å¤§å°)
        minutes_per_epoch = 20 if batch_size <= 4 else 15
        total_minutes = epochs * minutes_per_epoch

        if total_minutes < 60:
            return f"{total_minutes} åˆ†é˜"
        else:
            hours = total_minutes // 60
            minutes = total_minutes % 60
            return f"{hours} å°æ™‚ {minutes} åˆ†é˜"

    def _setup_training_environment(self):
        """è¨­ç½®è¨“ç·´ç’°å¢ƒ"""
        print(f"{Fore.YELLOW}ğŸ”§ æº–å‚™è¨“ç·´ç’°å¢ƒ...{Style.RESET_ALL}")

        # å‰µå»ºå¿…è¦ç›®éŒ„
        dirs_to_create = [
            PROJECT_ROOT / "models",
            PROJECT_ROOT / "logs",
            PROJECT_ROOT / "checkpoints",
            PROJECT_ROOT / "reports"
        ]

        for dir_path in dirs_to_create:
            dir_path.mkdir(exist_ok=True)

        # ä¿å­˜é…ç½®
        config_path = PROJECT_ROOT / "configs" / f"{self.training_config.experiment.name}.json"
        config_path.parent.mkdir(exist_ok=True)
        self.training_config.save(config_path)

        print(f"âœ… é…ç½®å·²ä¿å­˜åˆ°: {config_path}")

    def _run_training_with_progress(self) -> Dict[str, Any]:
        """åŸ·è¡Œè¨“ç·´ä¸¦é¡¯ç¤ºé€²åº¦"""
        print(f"{Fore.GREEN}{Style.BRIGHT}ğŸš€ é–‹å§‹è¨“ç·´...{Style.RESET_ALL}")
        self.start_time = time.time()

        try:
            # æ¨¡æ“¬æ•¸æ“šè¼‰å…¥å’Œæ¨¡å‹åˆå§‹åŒ–
            print("ğŸ“Š è¼‰å…¥æ•¸æ“š...")
            time.sleep(2)  # æ¨¡æ“¬è¼‰å…¥æ™‚é–“

            print("ğŸ¤– åˆå§‹åŒ–æ¨¡å‹...")
            time.sleep(1)

            # å¯¦éš›è¨“ç·´é‚è¼¯æœƒåœ¨é€™è£¡
            # é€™è£¡æˆ‘å€‘æ¨¡æ“¬è¨“ç·´éç¨‹ä¾†å±•ç¤ºç•Œé¢
            return self._simulate_training()

        except KeyboardInterrupt:
            print(f"\n{Fore.YELLOW}â¸ï¸  è¨“ç·´è¢«ç”¨æˆ¶ä¸­æ–·{Style.RESET_ALL}")
            return {"status": "interrupted", "completed_epochs": 0}

        except Exception as e:
            print(f"\n{Fore.RED}âŒ è¨“ç·´éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}{Style.RESET_ALL}")
            return {"status": "error", "error": str(e)}

    def _simulate_training(self) -> Dict[str, Any]:
        """æ¨¡æ“¬è¨“ç·´éç¨‹ (å¯¦éš›å¯¦ç¾æ™‚æ›¿æ›ç‚ºçœŸå¯¦è¨“ç·´)"""
        epochs = self.training_config.training.num_epochs

        # æ¨¡æ“¬æ¯å€‹ epoch çš„é€²åº¦
        epoch_progress = tqdm(range(epochs), desc="Epochs", position=0,
                             bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]')

        best_f1 = 0.0
        results = {"status": "completed", "best_f1": 0.0, "final_f1": 0.0}

        for epoch in epoch_progress:
            # æ¨¡æ“¬è¨“ç·´æ­¥é©Ÿ
            steps_per_epoch = 100  # æ¨¡æ“¬æ­¥é©Ÿæ•¸
            step_progress = tqdm(range(steps_per_epoch), desc=f"Epoch {epoch+1}",
                               position=1, leave=False,
                               bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{rate_fmt}]')

            epoch_loss = 0.0

            for step in step_progress:
                # æ¨¡æ“¬è¨“ç·´æ­¥é©Ÿ
                time.sleep(0.02)  # æ¨¡æ“¬è¨ˆç®—æ™‚é–“

                # æ¨¡æ“¬æå¤±ä¸‹é™
                step_loss = max(0.1, 2.0 - (epoch * 100 + step) * 0.001)
                epoch_loss += step_loss

                # æ›´æ–°é€²åº¦æ¢
                step_progress.set_postfix({
                    'loss': f'{step_loss:.4f}',
                    'lr': f'{2e-5:.2e}',
                    'mem': f'{self._simulate_memory_usage():.1f}GB'
                })

                # æ¨¡æ“¬ OOM éŒ¯èª¤ (10% æ©Ÿç‡åœ¨ç¬¬ä¸€å€‹ epoch)
                if epoch == 0 and step == 50 and np.random.random() < 0.1:
                    print(f"\n{Fore.YELLOW}âš ï¸  æ¨¡æ“¬ OOM éŒ¯èª¤ï¼Œè‡ªå‹•èª¿æ•´æ‰¹æ¬¡å¤§å°...{Style.RESET_ALL}")
                    time.sleep(1)
                    continue

            step_progress.close()

            # æ¨¡æ“¬è©•ä¼°
            val_f1 = min(0.85, 0.3 + epoch * 0.05 + np.random.random() * 0.1)
            val_loss = max(0.2, 1.5 - epoch * 0.1)

            if val_f1 > best_f1:
                best_f1 = val_f1
                print(f"ğŸ’¾ æ–°çš„æœ€ä½³æ¨¡å‹ F1: {val_f1:.4f}")

            # æ›´æ–° epoch é€²åº¦
            epoch_progress.set_postfix({
                'train_loss': f'{epoch_loss/steps_per_epoch:.4f}',
                'val_f1': f'{val_f1:.4f}',
                'best_f1': f'{best_f1:.4f}'
            })

            # æ¨¡æ“¬æ—©åœæª¢æŸ¥
            if epoch > 5 and val_f1 < best_f1 - 0.05:
                print(f"\n{Fore.CYAN}â¹ï¸  æ—©åœè§¸ç™¼ (epoch {epoch+1}){Style.RESET_ALL}")
                break

        epoch_progress.close()

        results["best_f1"] = best_f1
        results["final_f1"] = val_f1
        results["completed_epochs"] = epoch + 1

        return results

    def _simulate_memory_usage(self) -> float:
        """æ¨¡æ“¬è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
        base_usage = 1.5
        variation = np.random.random() * 0.5
        return base_usage + variation

    def _generate_evaluation_report(self, results: Dict[str, Any]):
        """ç”Ÿæˆè©•ä¼°å ±å‘Š"""
        print(f"\n{Fore.GREEN}{Style.BRIGHT}ğŸ“Š ç”Ÿæˆè©•ä¼°å ±å‘Š...{Style.RESET_ALL}")

        # è¨ˆç®—è¨“ç·´æ™‚é–“
        if self.start_time:
            training_time = time.time() - self.start_time
            training_time_str = str(timedelta(seconds=int(training_time)))
        else:
            training_time_str = "æœªçŸ¥"

        # å‰µå»ºå ±å‘Š
        report = {
            "experiment_name": self.training_config.experiment.name,
            "timestamp": datetime.now().isoformat(),
            "training_time": training_time_str,
            "configuration": {
                "model": self.training_config.model.model_name,
                "epochs": self.training_config.training.num_epochs,
                "batch_size": self.training_config.data.batch_size,
                "learning_rate": self.training_config.optimizer.lr,
                "data_augmentation": self.training_config.data.data_augmentation
            },
            "system_info": self.device_info,
            "results": results
        }

        # ä¿å­˜å ±å‘Š
        report_dir = PROJECT_ROOT / "reports"
        report_file = report_dir / f"training_report_{self.training_config.experiment.name}.json"

        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        # é¡¯ç¤ºå ±å‘Šæ‘˜è¦
        print(f"{Fore.CYAN}{Style.BRIGHT}=" * 50)
        print("ğŸ¯ è¨“ç·´å®Œæˆå ±å‘Š")
        print("=" * 50)
        print(f"å¯¦é©—åç¨±: {report['experiment_name']}")
        print(f"è¨“ç·´æ™‚é–“: {training_time_str}")
        print(f"å®Œæˆ epochs: {results.get('completed_epochs', 'N/A')}")

        if results.get("status") == "completed":
            print(f"æœ€ä½³ F1 åˆ†æ•¸: {Fore.GREEN}{results.get('best_f1', 0):.4f}{Style.RESET_ALL}")
            print(f"æœ€çµ‚ F1 åˆ†æ•¸: {results.get('final_f1', 0):.4f}")
        elif results.get("status") == "interrupted":
            print(f"{Fore.YELLOW}ç‹€æ…‹: ç”¨æˆ¶ä¸­æ–·{Style.RESET_ALL}")
        else:
            print(f"{Fore.RED}ç‹€æ…‹: éŒ¯èª¤ - {results.get('error', 'æœªçŸ¥éŒ¯èª¤')}{Style.RESET_ALL}")

        print(f"å ±å‘Šæª”æ¡ˆ: {report_file}")
        print("=" * 50)
        print(f"{Style.RESET_ALL}")

        return report_file

    def run(self):
        """ä¸»è¦åŸ·è¡Œæµç¨‹"""
        try:
            # 1. é¡¯ç¤ºæ­¡è¿ä¿¡æ¯
            self._print_header()
            self._print_system_info()

            # 2. é¸æ“‡é…ç½®
            template = self._select_config_template()
            params = self._get_training_params()

            # 3. å‰µå»ºé…ç½®
            self.training_config = self._create_training_config(template, params)

            # 4. é¡¯ç¤ºé…ç½®æ‘˜è¦
            self._show_config_summary(self.training_config)

            # 5. ç¢ºèªè¨“ç·´
            if not self._confirm_training():
                print(f"{Fore.YELLOW}è¨“ç·´å·²å–æ¶ˆ{Style.RESET_ALL}")
                return

            # 6. æº–å‚™ç’°å¢ƒ
            self._setup_training_environment()

            # 7. åŸ·è¡Œè¨“ç·´
            results = self._run_training_with_progress()

            # 8. ç”Ÿæˆå ±å‘Š
            self._generate_evaluation_report(results)

            print(f"\n{Fore.GREEN}{Style.BRIGHT}ğŸ‰ è¨“ç·´æµç¨‹å®Œæˆï¼{Style.RESET_ALL}")

        except KeyboardInterrupt:
            print(f"\n{Fore.YELLOW}ğŸ‘‹ ç¨‹å¼è¢«ç”¨æˆ¶ä¸­æ–·{Style.RESET_ALL}")
        except Exception as e:
            print(f"\n{Fore.RED}âŒ ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {e}{Style.RESET_ALL}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    # Windows æ§åˆ¶å° UTF-8 æ”¯æ´
    if sys.platform == "win32":
        try:
            # è¨­ç½®æ§åˆ¶å°ç·¨ç¢¼
            import locale
            locale.setlocale(locale.LC_ALL, 'Chinese (Traditional)_Taiwan.utf8')
        except:
            pass

    # åŸ·è¡Œè¨“ç·´å•Ÿå‹•å™¨
    launcher = WindowsTrainingLauncher()
    launcher.run()


if __name__ == "__main__":
    main()