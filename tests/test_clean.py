#!/usr/bin/env python3
"""
è³‡æ–™æ¸…ç†æ¨¡çµ„çš„å–®å…ƒæ¸¬è©¦
"""

import json
import os
import shutil
import sys
import tempfile
import unittest
from pathlib import Path

# æ·»åŠ å°ˆæ¡ˆè·¯å¾‘åˆ°ç³»çµ±è·¯å¾‘
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from scripts.clean_normalize import (
    DatasetCleaner, TextNormalizer  # noqa: E402
)


class TestTextNormalizer(unittest.TestCase):
    """æ¸¬è©¦æ–‡å­—æ­£è¦åŒ–å™¨"""

    def setUp(self):
        """æ¸¬è©¦å‰åˆå§‹åŒ–"""
        self.normalizer = TextNormalizer(
            convert_mode=None, preserve_emoji=True, anonymize=True  # æ¸¬è©¦æ™‚ä¸åšç¹ç°¡è½‰æ›
        )

    def test_fullwidth_to_halfwidth(self):
        """æ¸¬è©¦å…¨å½¢è½‰åŠå½¢"""
        # æ¸¬è©¦å…¨å½¢è‹±æ–‡å’Œæ•¸å­—
        text = "ï¼¡ï¼¢ï¼£ï¼‘ï¼’ï¼“"
        expected = "ABC123"
        result = self.normalizer.fullwidth_to_halfwidth(text)
        self.assertEqual(result, expected)

        # æ¸¬è©¦å…¨å½¢ç©ºæ ¼
        text = "ä½ å¥½ã€€ä¸–ç•Œ"
        expected = "ä½ å¥½ ä¸–ç•Œ"
        result = self.normalizer.fullwidth_to_halfwidth(text)
        self.assertEqual(result, expected)

        # æ¸¬è©¦å…¨å½¢ç¬¦è™Ÿ
        text = "ï¼ï¼ ï¼ƒï¼„ï¼…"
        expected = "!@#$%"
        result = self.normalizer.fullwidth_to_halfwidth(text)
        self.assertEqual(result, expected)

    def test_normalize_whitespace(self):
        """æ¸¬è©¦ç©ºç™½æ­£è¦åŒ–"""
        # æ¸¬è©¦å¤šå€‹ç©ºæ ¼
        text = "hello    world    test"
        expected = "hello world test"
        result = self.normalizer.normalize_whitespace(text)
        self.assertEqual(result, expected)

        # æ¸¬è©¦æ··åˆç©ºç™½å­—ç¬¦
        text = "hello\t\n\r  world"
        expected = "hello world"
        result = self.normalizer.normalize_whitespace(text)
        self.assertEqual(result, expected)

        # æ¸¬è©¦é¦–å°¾ç©ºç™½
        text = "  hello world  "
        expected = "hello world"
        result = self.normalizer.normalize_whitespace(text)
        self.assertEqual(result, expected)

    def test_replace_urls(self):
        """æ¸¬è©¦URLæ›¿æ›"""
        test_cases = [
            ("Visit https://www.google.com for more", "Visit [URL] for more"),
            ("Check http://example.com and https://test.org", "Check [URL] and [URL]"),
            ("IP: 192.168.1.1:8080", "IP: [URL]"),
            ("No URL here", "No URL here"),
            ("è¤‡é›œURL: https://example.com/path?query=123#anchor", "è¤‡é›œURL: [URL]"), 
        ]

        for text, expected in test_cases:
            with self.subTest(text=text):
                result = self.normalizer.replace_urls(text)
                self.assertEqual(result, expected)

    def test_replace_mentions(self):
        """æ¸¬è©¦@mentionæ›¿æ›"""
        test_cases = [
            ("Hello @user123", "Hello [MENTION]"),
            ("@æ¸¬è©¦ç”¨æˆ¶ ä½ å¥½", "[MENTION] ä½ å¥½"),
            ("Multiple @user1 @user2", "Multiple [MENTION] [MENTION]"),
            ("Email: test@example.com", "Email: [EMAIL]"), 
        ]

        for text, expected in test_cases:
            with self.subTest(text=text):
                result = self.normalizer.replace_mentions(text)
                self.assertEqual(result, expected)

    def test_replace_hashtags(self):
        """æ¸¬è©¦hashtagæ›¿æ›"""
        test_cases = [
            ("#Python is great", "[HASHTAG] is great"),
            ("æ¨™ç±¤ #æ¸¬è©¦ #ä¸­æ–‡æ¨™ç±¤", "æ¨™ç±¤ [HASHTAG] [HASHTAG]"),
            ("No hashtag here", "No hashtag here"),
        ]

        for text, expected in test_cases:
            with self.subTest(text=text):
                result = self.normalizer.replace_hashtags(text)
                self.assertEqual(result, expected)

    def test_anonymize_email(self):
        """æ¸¬è©¦Emailå»è­˜åˆ¥åŒ–"""
        test_cases = [
            ("Contact: john@example.com", "Contact: [EMAIL]"),
            ("Emails: a@b.com and test@gmail.com", "Emails: [EMAIL] and [EMAIL]"), 
            ("No email here", "No email here"),
        ]

        for text, expected in test_cases:
            with self.subTest(text=text):
                result = self.normalizer.anonymize_sensitive(text)
                # åªæª¢æŸ¥emailéƒ¨åˆ†ï¼Œå› ç‚ºå¯èƒ½é‚„æœƒè™•ç†å…¶ä»–æ•æ„Ÿè³‡è¨Š
                self.assertIn(expected.split()[0], result)

    def test_anonymize_phone(self):
        """æ¸¬è©¦é›»è©±è™Ÿç¢¼å»è­˜åˆ¥åŒ–"""
        test_cases = [
            ("Call me at 0912345678", "Call me at [PHONE]"),
            ("æ‰‹æ©Ÿï¼š0987654321", "æ‰‹æ©Ÿï¼š[PHONE]"),
            ("é›»è©± 02-12345678", "é›»è©± [PHONE]"),
            ("å¤§é™¸æ‰‹æ©Ÿ 13912345678", "å¤§é™¸æ‰‹æ©Ÿ [PHONE]"),
        ]

        for text, expected in test_cases:
            with self.subTest(text=text):
                result = self.normalizer.anonymize_sensitive(text)
                self.assertEqual(result, expected)

    def test_anonymize_id(self):
        """æ¸¬è©¦èº«åˆ†è­‰è™Ÿç¢¼å»è­˜åˆ¥åŒ–"""
        test_cases = [
            ("èº«åˆ†è­‰ï¼šA123456789", "èº«åˆ†è­‰ï¼š[ID]"),
            ("ID: B234567890", "ID: [ID]"),
            ("å¤§é™¸èº«åˆ†è­‰ï¼š12345678901234567X", "å¤§é™¸èº«åˆ†è­‰ï¼š[ID]"),
        ]

        for text, expected in test_cases:
            with self.subTest(text=text):
                result = self.normalizer.anonymize_sensitive(text)
                self.assertEqual(result, expected)

    def test_mark_emojis(self):
        """æ¸¬è©¦è¡¨æƒ…ç¬¦è™Ÿæ¨™è¨˜"""
        # æ¸¬è©¦ä¿ç•™è¡¨æƒ…æ¨¡å¼
        normalizer_preserve = TextNormalizer(preserve_emoji=True)
        text = "Hello ğŸ˜€ World ğŸŒ"
        result = normalizer_preserve.mark_emojis(text)
        self.assertIn("[EMOJI:ğŸ˜€]", result)
        self.assertIn("[EMOJI:ğŸŒ]", result)

        # æ¸¬è©¦ç§»é™¤è¡¨æƒ…æ¨¡å¼
        normalizer_remove = TextNormalizer(preserve_emoji=False)
        result = normalizer_remove.mark_emojis(text)
        self.assertEqual(result, "Hello [EMOJI] World [EMOJI]")

    def test_complete_normalize(self):
        """æ¸¬è©¦å®Œæ•´çš„æ­£è¦åŒ–æµç¨‹"""
        text = (
            "è«‹è¨ªå•ã€€ã€€https://example.comã€€ã€€è¯çµ¡ @user"
                "ã€€éƒµç®±ï¼štest@email.comã€€é›»è©±ï¼š0912345678 ğŸ˜€"
        )
        result = self.normalizer.normalize(text)

        # æª¢æŸ¥å„é …è™•ç†æ˜¯å¦ç”Ÿæ•ˆ
        self.assertIn("[URL]", result)
        self.assertIn("[MENTION]", result)
        self.assertIn("[EMAIL]", result)
        self.assertIn("[PHONE]", result)
        self.assertIn("[EMOJI:", result)
        self.assertNotIn("ã€€ã€€", result)  # å…¨å½¢ç©ºæ ¼æ‡‰è¢«è™•ç†
        self.assertNotIn("  ", result)  # å¤šå€‹ç©ºæ ¼æ‡‰è¢«åˆä½µ

    def test_empty_input(self):
        """æ¸¬è©¦ç©ºè¼¸å…¥"""
        test_cases = [None, "", "   "]
        for text in test_cases:
            with self.subTest(text=text):
                result = self.normalizer.normalize(text)
                self.assertIn(result, [None, ""])


class TestDatasetCleaner(unittest.TestCase):
    """æ¸¬è©¦è³‡æ–™é›†æ¸…ç†å™¨"""

    def setUp(self):
        """æ¸¬è©¦å‰åˆå§‹åŒ–"""
        # å»ºç«‹è‡¨æ™‚ç›®éŒ„
        self.temp_dir = tempfile.mkdtemp()
        self.input_dir = Path(self.temp_dir) / "raw"
        self.output_dir = Path(self.temp_dir) / "processed"

        # å»ºç«‹æ¸¬è©¦è³‡æ–™çµæ§‹
        self.input_dir.mkdir(parents=True, exist_ok=True)

        # åˆå§‹åŒ–æ¸…ç†å™¨
        self.normalizer = TextNormalizer()
        self.cleaner = DatasetCleaner(
            input_dir=str(self.input_dir),
            output_dir=str(self.output_dir),
            normalizer=self.normalizer,
        )

    def tearDown(self):
        """æ¸¬è©¦å¾Œæ¸…ç†"""
        # åˆªé™¤è‡¨æ™‚ç›®éŒ„
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_generate_id(self):
        """æ¸¬è©¦IDç”Ÿæˆ"""
        text1 = "Hello World"
        text2 = "Hello World"
        text3 = "Different Text"

        # ç›¸åŒæ–‡å­—å’Œç´¢å¼•æ‡‰ç”Ÿæˆç›¸åŒID
        id1 = self.cleaner.generate_id(text1, 0)
        id2 = self.cleaner.generate_id(text2, 0)
        self.assertEqual(id1, id2)

        # ä¸åŒæ–‡å­—æ‡‰ç”Ÿæˆä¸åŒID
        id3 = self.cleaner.generate_id(text3, 0)
        self.assertNotEqual(id1, id3)

        # ç›¸åŒæ–‡å­—ä½†ä¸åŒç´¢å¼•æ‡‰ç”Ÿæˆä¸åŒID
        id4 = self.cleaner.generate_id(text1, 1)
        self.assertNotEqual(id1, id4)

        # IDæ ¼å¼æª¢æŸ¥
        self.assertTrue(id1.startswith("proc_"))
        self.assertEqual(len(id1), 17)  # proc_ + 12å€‹å­—ç¬¦

    def test_clean_json_dataset(self):
        """æ¸¬è©¦JSONè³‡æ–™é›†æ¸…ç†"""
        # å»ºç«‹æ¸¬è©¦JSONè³‡æ–™
        test_dataset_dir = self.input_dir / "test_dataset"
        test_dataset_dir.mkdir(parents=True, exist_ok=True)

        test_data = [
            {"text": "æ¸¬è©¦æ–‡å­—ï¼‘ï¼’ï¼“", "label": 0},
            {"text": "åŒ…å«URL https://test.com", "label": 1},
            {"text": "æœ‰@mentionå’Œ#hashtag", "label": 0},
        ]

        test_file = test_dataset_dir / "test.json"
        with open(test_file, "w", encoding="utf-8") as f:
            json.dump(test_data, f, ensure_ascii=False)

        # åŸ·è¡Œæ¸…ç†
        results = self.cleaner.clean_json_dataset("test_dataset", "text")

        # æª¢æŸ¥çµæœ
        self.assertIn("test_dataset_test", results)
        self.assertEqual(results["test_dataset_test"]["total_samples"], 3)

        # æª¢æŸ¥è¼¸å‡ºæª”æ¡ˆ
        output_file = self.output_dir / "test_dataset" / "test_processed.json"
        self.assertTrue(output_file.exists())

        # æª¢æŸ¥è™•ç†å¾Œçš„è³‡æ–™
        with open(output_file, "r", encoding="utf-8") as f:
            processed_data = json.load(f)

        self.assertEqual(len(processed_data), 3)

        # æª¢æŸ¥æ­£è¦åŒ–æ•ˆæœ
        self.assertEqual(processed_data[0]["text"], "æ¸¬è©¦æ–‡å­—123")  # å…¨å½¢è½‰åŠå½¢
        self.assertIn("[URL]", processed_data[1]["text"])  # URLæ›¿æ›
        self.assertIn("[MENTION]", processed_data[2]["text"])  # Mentionæ›¿æ›
        self.assertIn("[HASHTAG]", processed_data[2]["text"])  # Hashtagæ›¿æ›

        # æª¢æŸ¥ID
        for item in processed_data:
            self.assertIn("processed_id", item)
            self.assertIn("raw_id", item)
            self.assertTrue(item["processed_id"].startswith("proc_"))

    def test_save_mapping(self):
        """æ¸¬è©¦mappingå„²å­˜"""
        # æ·»åŠ ä¸€äº›æ¸¬è©¦mapping
        self.cleaner.mapping_data = [
            {"raw_id": "test_1", "processed_id": "proc_abc123", "text": "æ¸¬è©¦1"},
            {"raw_id": "test_2", "processed_id": "proc_def456", "text": "æ¸¬è©¦2"},
        ]

        # å„²å­˜mapping
        self.cleaner.save_mapping()

        # æª¢æŸ¥JSONæª”æ¡ˆ
        json_file = self.output_dir / "id_mapping.json"
        self.assertTrue(json_file.exists())

        with open(json_file, "r", encoding="utf-8") as f:
            loaded_mapping = json.load(f)

        self.assertEqual(len(loaded_mapping), 2)
        self.assertEqual(loaded_mapping[0]["raw_id"], "test_1")

        # æª¢æŸ¥CSVæª”æ¡ˆ
        csv_file = self.output_dir / "id_mapping.csv"
        self.assertTrue(csv_file.exists())


class TestIntegration(unittest.TestCase):
    """æ•´åˆæ¸¬è©¦"""

    def test_chinese_conversion(self):
        """æ¸¬è©¦ç¹ç°¡è½‰æ›ï¼ˆå¦‚æœå®‰è£äº†OpenCCï¼‰"""
        try:
            from opencc import OpenCC

            normalizer = TextNormalizer(convert_mode="s2t")

            text = "è¿™æ˜¯ç®€ä½“ä¸­æ–‡"
            result = normalizer.convert_chinese(text)
            # åªæª¢æŸ¥æ˜¯å¦åŸ·è¡ŒæˆåŠŸï¼Œä¸æª¢æŸ¥å…·é«”è½‰æ›çµæœï¼ˆå› ç‚ºå¯èƒ½æ²’å®‰è£OpenCCï¼‰
            self.assertIsNotNone(result)
        except ImportError:
            self.skipTest("OpenCC not installed")

    def test_stats_tracking(self):
        """æ¸¬è©¦çµ±è¨ˆè¿½è¹¤"""
        normalizer = TextNormalizer()

        # è™•ç†åŒ…å«å„ç¨®å…ƒç´ çš„æ–‡å­—
        texts = [
            "URL: https://example.com",
            "Mention: @user123",
            "Email: test@email.com",
            "Phone: 0912345678",
            "Emoji: ğŸ˜€",
        ]

        for text in texts:
            normalizer.normalize(text)

        stats = normalizer.get_stats()

        # æª¢æŸ¥çµ±è¨ˆæ•¸æ“š
        self.assertEqual(stats["total_processed"], 5)
        self.assertGreater(stats["urls_replaced"], 0)
        self.assertGreater(stats["mentions_replaced"], 0)
        self.assertGreater(stats["emails_replaced"], 0)
        self.assertGreater(stats["phones_replaced"], 0)
        self.assertGreater(stats["emojis_marked"], 0)


def run_tests():
    """åŸ·è¡Œæ‰€æœ‰æ¸¬è©¦"""
    # å»ºç«‹æ¸¬è©¦å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()

    # æ·»åŠ æ‰€æœ‰æ¸¬è©¦é¡
    suite.addTests(loader.loadTestsFromTestCase(TestTextNormalizer))
    suite.addTests(loader.loadTestsFromTestCase(TestDatasetCleaner))
    suite.addTests(loader.loadTestsFromTestCase(TestIntegration))

    # åŸ·è¡Œæ¸¬è©¦
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    # è¿”å›æ¸¬è©¦çµæœ
    return result.wasSuccessful()


if __name__ == "__main__":
    # åŸ·è¡Œæ¸¬è©¦
    success = run_tests()
    sys.exit(0 if success else 1)
