# 多任務訓練配置
# 同時訓練毒性偵測、霸凌偵測、角色識別、情緒分析

model:
  name: "hfl/chinese-roberta-wwm-ext"
  num_labels: 3  # 主要任務標籤數
  dropout_rate: 0.1
  hidden_size: 768
  max_sequence_length: 512

data:
  train_path: "data/processed/multi_task_train.json"
  val_path: "data/processed/multi_task_val.json"
  test_path: "data/processed/multi_task_test.json"
  cache_dir: "data/cache"
  num_workers: 2
  pin_memory: true
  prefetch_factor: 2

training:
  batch_size: 6
  auto_batch_size: true
  gradient_accumulation_steps: 6
  learning_rate: 1.5e-5  # 稍低學習率用於多任務
  weight_decay: 0.01
  num_epochs: 12
  warmup_ratio: 0.15  # 更長預熱期
  lr_scheduler: "cosine"
  fp16: true
  dataloader_drop_last: true

optimization:
  gradient_checkpointing: true
  max_grad_norm: 1.0
  optimizer: "AdamW"
  memory_efficient_attention: true
  cpu_offload: false

callbacks:
  early_stopping_patience: 4
  early_stopping_metric: "eval_f1_macro"
  early_stopping_mode: "max"
  save_best_only: true
  save_top_k: 3
  monitor_gpu_memory: true
  tensorboard_log_dir: "logs/tensorboard"

experiment:
  name: "multi_task_training"
  output_dir: "experiments"
  resume_from_checkpoint: null
  seed: 42
  log_level: "INFO"
  save_predictions: true