{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CyberPuppy 評估報告\n",
    "\n",
    "此 notebook 提供完整的離線評估報告，包含：\n",
    "- 宏 F1 分數\n",
    "- AUCPR (Average Precision)\n",
    "- 會話級指標\n",
    "- 線上收斂監控視覺化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 環境設定與資料載入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯入必要套件\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "# 設定繪圖風格\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# 支援中文顯示\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 添加專案路徑\n",
    "sys.path.append('..')\n",
    "\n",
    "# 匯入 CyberPuppy 模組\n",
    "from src.cyberpuppy.eval.metrics import (\n",
    "    MetricsCalculator,\n",
    "    SessionContext,\n",
    "    OnlineMonitor,\n",
    "    PrometheusExporter,\n",
    "    CSVExporter,\n",
    "    EvaluationReport\n",
    ")\n",
    "\n",
    "print(\"環境設定完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入或生成測試資料\n",
    "def generate_test_data(n_samples=1000, random_state=42):\n",
    "    \"\"\"生成測試資料\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # 標籤\n",
    "    toxicity_labels = ['none', 'toxic', 'severe']\n",
    "    emotion_labels = ['pos', 'neu', 'neg']\n",
    "    \n",
    "    # 生成真實標籤（模擬不平衡資料）\n",
    "    y_true_toxicity = np.random.choice(\n",
    "        toxicity_labels, n_samples, p=[0.7, 0.25, 0.05]\n",
    "    )\n",
    "    y_true_emotion = np.random.choice(\n",
    "        emotion_labels, n_samples, p=[0.3, 0.4, 0.3]\n",
    "    )\n",
    "    \n",
    "    # 生成預測（添加一些錯誤）\n",
    "    y_pred_toxicity = []\n",
    "    y_prob_toxicity = []\n",
    "    \n",
    "    for true_label in y_true_toxicity:\n",
    "        if np.random.random() < 0.8:  # 80% 準確率\n",
    "            pred = true_label\n",
    "        else:\n",
    "            pred = np.random.choice(toxicity_labels)\n",
    "        y_pred_toxicity.append(pred)\n",
    "        \n",
    "        # 生成機率\n",
    "        probs = np.random.dirichlet([1, 1, 1])\n",
    "        if pred == 'none':\n",
    "            probs[0] += 0.5\n",
    "        elif pred == 'toxic':\n",
    "            probs[1] += 0.5\n",
    "        else:\n",
    "            probs[2] += 0.5\n",
    "        probs = probs / probs.sum()\n",
    "        y_prob_toxicity.append(probs)\n",
    "    \n",
    "    y_prob_toxicity = np.array(y_prob_toxicity)\n",
    "    \n",
    "    return {\n",
    "        'y_true_toxicity': y_true_toxicity,\n",
    "        'y_pred_toxicity': y_pred_toxicity,\n",
    "        'y_prob_toxicity': y_prob_toxicity,\n",
    "        'y_true_emotion': y_true_emotion\n",
    "    }\n",
    "\n",
    "# 生成測試資料\n",
    "test_data = generate_test_data()\n",
    "print(f\"生成 {len(test_data['y_true_toxicity'])} 筆測試資料\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 分類指標評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算分類指標\n",
    "calculator = MetricsCalculator()\n",
    "\n",
    "# 毒性分類指標\n",
    "toxicity_metrics = calculator.calculate_classification_metrics(\n",
    "    test_data['y_true_toxicity'],\n",
    "    test_data['y_pred_toxicity'],\n",
    "    task_name='toxicity',\n",
    "    average='macro'\n",
    ")\n",
    "\n",
    "# 顯示主要指標\n",
    "print(\"=\" * 50)\n",
    "print(\"毒性偵測 - 分類指標\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, result in toxicity_metrics.items():\n",
    "    if name != 'toxicity_confusion_matrix':\n",
    "        print(f\"{name:30s}: {result.value:.4f}\")\n",
    "\n",
    "# 顯示混淆矩陣\n",
    "cm = toxicity_metrics['toxicity_confusion_matrix'].metadata['matrix']\n",
    "print(\"\\n混淆矩陣:\")\n",
    "print(pd.DataFrame(\n",
    "    cm,\n",
    "    index=['真實:none', '真實:toxic', '真實:severe'],\n",
    "    columns=['預測:none', '預測:toxic', '預測:severe']\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化混淆矩陣\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# 正規化混淆矩陣\n",
    "cm_normalized = cm / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "# 繪製熱圖\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt='.2f',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['none', 'toxic', 'severe'],\n",
    "    yticklabels=['none', 'toxic', 'severe'],\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_title('毒性偵測 - 正規化混淆矩陣')\n",
    "ax.set_xlabel('預測標籤')\n",
    "ax.set_ylabel('真實標籤')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 機率指標評估 (AUCPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算機率指標\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# 轉換標籤為數值\n",
    "le = LabelEncoder()\n",
    "y_true_encoded = le.fit_transform(test_data['y_true_toxicity'])\n",
    "\n",
    "# One-hot 編碼\n",
    "y_true_onehot = np.eye(3)[y_true_encoded]\n",
    "\n",
    "# 計算機率指標\n",
    "prob_metrics = calculator.calculate_probability_metrics(\n",
    "    y_true_onehot,\n",
    "    test_data['y_prob_toxicity'],\n",
    "    task_name='toxicity'\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"毒性偵測 - 機率指標\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, result in prob_metrics.items():\n",
    "    print(f\"{name:30s}: {result.value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製 Precision-Recall 曲線\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "labels = ['none', 'toxic', 'severe']\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    # 計算 PR 曲線\n",
    "    precision, recall, _ = precision_recall_curve(\n",
    "        y_true_onehot[:, i],\n",
    "        test_data['y_prob_toxicity'][:, i]\n",
    "    )\n",
    "    \n",
    "    ap = average_precision_score(\n",
    "        y_true_onehot[:, i],\n",
    "        test_data['y_prob_toxicity'][:, i]\n",
    "    )\n",
    "    \n",
    "    # 繪製曲線\n",
    "    axes[i].plot(recall, precision, lw=2, label=f'AP = {ap:.3f}')\n",
    "    axes[i].fill_between(recall, precision, alpha=0.3)\n",
    "    axes[i].set_xlabel('Recall')\n",
    "    axes[i].set_ylabel('Precision')\n",
    "    axes[i].set_title(f'{label.capitalize()} 類別 - PR 曲線')\n",
    "    axes[i].legend(loc='lower left')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Precision-Recall 曲線（各類別）', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 會話級指標評估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成模擬會話資料\n",
    "def generate_sessions(n_sessions=50):\n",
    "    \"\"\"生成模擬會話資料\"\"\"\n",
    "    sessions = []\n",
    "    \n",
    "    for i in range(n_sessions):\n",
    "        session = SessionContext(session_id=f\"session_{i}\")\n",
    "        n_messages = np.random.randint(3, 15)\n",
    "        \n",
    "        # 模擬會話中的毒性變化\n",
    "        base_toxicity = np.random.random()\n",
    "        \n",
    "        for j in range(n_messages):\n",
    "            # 添加一些變化\n",
    "            toxicity = max(0, min(1, base_toxicity + np.random.normal(0, 0.1)))\n",
    "            \n",
    "            message = {\n",
    "                'message_id': f\"msg_{j}\",\n",
    "                'text': f\"Message {j}\",\n",
    "                'scores': {\n",
    "                    'toxicity': toxicity,\n",
    "                    'emotion': np.random.choice(['pos', 'neu', 'neg'])\n",
    "                },\n",
    "                'intervention': toxicity > 0.7  # 高毒性時介入\n",
    "            }\n",
    "            \n",
    "            session.add_message(message)\n",
    "            \n",
    "            # 模擬介入效果\n",
    "            if message['intervention']:\n",
    "                base_toxicity *= 0.7  # 介入後降低毒性\n",
    "        \n",
    "        sessions.append(session)\n",
    "    \n",
    "    return sessions\n",
    "\n",
    "# 生成會話資料\n",
    "sessions = generate_sessions(50)\n",
    "print(f\"生成 {len(sessions)} 個會話\")\n",
    "print(f\"平均每會話 {np.mean([len(s.messages) for s in sessions]):.1f} 條訊息\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算會話級指標\n",
    "session_metrics = calculator.calculate_session_metrics(sessions, 'toxicity')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"會話級指標\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for name, result in session_metrics.items():\n",
    "    print(f\"{name:30s}: {result.value:.4f}\")\n",
    "    if result.metadata:\n",
    "        for key, value in result.metadata.items():\n",
    "            print(f\"  - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化會話毒性趨勢\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 選擇幾個代表性會話\n",
    "selected_sessions = sessions[:4]\n",
    "\n",
    "for i, (session, ax) in enumerate(zip(selected_sessions, axes.flat)):\n",
    "    # 提取毒性分數\n",
    "    toxicity_scores = []\n",
    "    intervention_points = []\n",
    "    \n",
    "    for j, msg in enumerate(session.messages):\n",
    "        score = msg['scores']['toxicity']\n",
    "        toxicity_scores.append(score)\n",
    "        if msg.get('intervention', False):\n",
    "            intervention_points.append(j)\n",
    "    \n",
    "    # 繪製毒性趨勢\n",
    "    x = range(len(toxicity_scores))\n",
    "    ax.plot(x, toxicity_scores, 'b-', linewidth=2, label='毒性分數')\n",
    "    \n",
    "    # 標記介入點\n",
    "    if intervention_points:\n",
    "        intervention_scores = [toxicity_scores[p] for p in intervention_points]\n",
    "        ax.scatter(intervention_points, intervention_scores, \n",
    "                  color='red', s=100, marker='v', label='介入點', zorder=5)\n",
    "    \n",
    "    # 添加危險閾值線\n",
    "    ax.axhline(y=0.7, color='orange', linestyle='--', alpha=0.5, label='危險閾值')\n",
    "    ax.axhline(y=0.3, color='green', linestyle='--', alpha=0.5, label='安全閾值')\n",
    "    \n",
    "    ax.set_xlabel('訊息順序')\n",
    "    ax.set_ylabel('毒性分數')\n",
    "    ax.set_title(f'會話 {i+1} - 毒性趨勢')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('會話毒性趨勢分析', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 線上收斂監控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模擬訓練過程\n",
    "monitor = OnlineMonitor(window_size=20, checkpoint_interval=10)\n",
    "\n",
    "# 生成模擬訓練資料\n",
    "n_steps = 200\n",
    "training_history = []\n",
    "\n",
    "for step in range(n_steps):\n",
    "    # 模擬收斂的 loss\n",
    "    loss = 2.0 * np.exp(-step/50) + 0.1 + np.random.normal(0, 0.05)\n",
    "    \n",
    "    # 模擬提升的準確率和 F1\n",
    "    accuracy = min(0.95, 0.5 + step * 0.002 + np.random.normal(0, 0.02))\n",
    "    f1_score = min(0.90, 0.4 + step * 0.002 + np.random.normal(0, 0.02))\n",
    "    \n",
    "    # 模擬學習率衰減\n",
    "    lr = 0.001 * (0.95 ** (step // 20))\n",
    "    \n",
    "    # 更新監控器\n",
    "    stats = monitor.update(loss, accuracy, f1_score, lr)\n",
    "    training_history.append(stats)\n",
    "\n",
    "# 取得摘要\n",
    "summary = monitor.get_summary()\n",
    "print(\"=\" * 50)\n",
    "print(\"訓練監控摘要\")\n",
    "print(\"=\" * 50)\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key:25s}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key:25s}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 視覺化訓練曲線\n",
    "df_history = pd.DataFrame(training_history)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss 曲線\n",
    "axes[0, 0].plot(df_history['step'], df_history['loss'], 'b-', alpha=0.3, label='即時 Loss')\n",
    "axes[0, 0].plot(df_history['step'], df_history['loss_avg'], 'r-', linewidth=2, label='移動平均')\n",
    "axes[0, 0].fill_between(df_history['step'], \n",
    "                        df_history['loss_avg'] - df_history['loss_std'],\n",
    "                        df_history['loss_avg'] + df_history['loss_std'],\n",
    "                        alpha=0.2, color='red')\n",
    "axes[0, 0].set_xlabel('步驟')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].set_title('Loss 收斂曲線')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 準確率曲線\n",
    "axes[0, 1].plot(df_history['step'], df_history['accuracy'], 'g-', alpha=0.3, label='即時準確率')\n",
    "axes[0, 1].plot(df_history['step'], df_history['accuracy_avg'], 'darkgreen', linewidth=2, label='移動平均')\n",
    "axes[0, 1].set_xlabel('步驟')\n",
    "axes[0, 1].set_ylabel('準確率')\n",
    "axes[0, 1].set_title('準確率提升曲線')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 分數曲線\n",
    "axes[1, 0].plot(df_history['step'], df_history['f1_score'], 'purple', alpha=0.3, label='即時 F1')\n",
    "axes[1, 0].plot(df_history['step'], df_history['f1_avg'], 'darkviolet', linewidth=2, label='移動平均')\n",
    "axes[1, 0].set_xlabel('步驟')\n",
    "axes[1, 0].set_ylabel('F1 分數')\n",
    "axes[1, 0].set_title('F1 分數提升曲線')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 學習率曲線\n",
    "axes[1, 1].plot(df_history['step'], df_history['learning_rate'], 'orange', linewidth=2)\n",
    "axes[1, 1].set_xlabel('步驟')\n",
    "axes[1, 1].set_ylabel('學習率')\n",
    "axes[1, 1].set_title('學習率衰減')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('訓練監控視覺化', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 指標匯出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯出到 Prometheus 格式\n",
    "prometheus = PrometheusExporter(job_name='cyberpuppy_eval')\n",
    "\n",
    "# 添加指標\n",
    "for name, result in toxicity_metrics.items():\n",
    "    if name != 'toxicity_confusion_matrix':\n",
    "        prometheus.update_metric(\n",
    "            name=name.replace('toxicity_', ''),\n",
    "            value=result.value,\n",
    "            labels={'task': 'toxicity', 'dataset': 'test'}\n",
    "        )\n",
    "\n",
    "# 添加會話指標\n",
    "for name, result in session_metrics.items():\n",
    "    prometheus.update_metric(\n",
    "        name=name,\n",
    "        value=result.value,\n",
    "        labels={'type': 'session'}\n",
    "    )\n",
    "\n",
    "# 顯示 Prometheus 格式\n",
    "print(\"Prometheus 格式輸出:\")\n",
    "print(\"=\" * 50)\n",
    "prometheus_output = prometheus.export()\n",
    "print(prometheus_output[:1000] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 匯出到 CSV\n",
    "csv_exporter = CSVExporter(output_dir='./metrics_output')\n",
    "\n",
    "# 匯出分類指標\n",
    "csv_path = csv_exporter.export_metrics(\n",
    "    toxicity_metrics,\n",
    "    filename='toxicity_metrics.csv'\n",
    ")\n",
    "print(f\"毒性指標已匯出到: {csv_path}\")\n",
    "\n",
    "# 匯出訓練歷史\n",
    "history_path = csv_exporter.export_history(\n",
    "    monitor.export_history(),\n",
    "    filename='training_history.csv'\n",
    ")\n",
    "print(f\"訓練歷史已匯出到: {history_path}\")\n",
    "\n",
    "# 顯示 CSV 內容預覽\n",
    "print(\"\\nCSV 內容預覽:\")\n",
    "df_metrics = pd.read_csv(csv_path)\n",
    "print(df_metrics.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 完整評估報告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成完整報告\n",
    "report = EvaluationReport()\n",
    "\n",
    "# 添加預測結果\n",
    "report.add_predictions(\n",
    "    y_true=test_data['y_true_toxicity'],\n",
    "    y_pred=test_data['y_pred_toxicity'],\n",
    "    y_prob=test_data['y_prob_toxicity'],\n",
    "    task_name='toxicity'\n",
    ")\n",
    "\n",
    "# 添加會話\n",
    "for session in sessions[:10]:  # 添加部分會話作為範例\n",
    "    report.add_session(session)\n",
    "\n",
    "# 生成報告\n",
    "full_report = report.generate_report()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"完整評估報告摘要\")\n",
    "print(\"=\" * 50)\n",
    "print(json.dumps(full_report['summary'], indent=2, ensure_ascii=False))\n",
    "\n",
    "# 儲存報告\n",
    "report_path = './metrics_output/evaluation_report.json'\n",
    "os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(full_report, f, ensure_ascii=False, indent=2)\n",
    "print(f\"\\n完整報告已儲存到: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 效能基準測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 與基準比較\n",
    "benchmarks = {\n",
    "    '目標': {\n",
    "        'toxicity_f1': 0.78,\n",
    "        'emotion_f1': 0.85,\n",
    "        'aucpr': 0.75,\n",
    "        'intervention_success': 0.60\n",
    "    },\n",
    "    '實際': {\n",
    "        'toxicity_f1': toxicity_metrics['f1_score'].value,\n",
    "        'emotion_f1': 0.83,  # 模擬值\n",
    "        'aucpr': prob_metrics.get('aucpr', toxicity_metrics['f1_score']).value,\n",
    "        'intervention_success': session_metrics['intervention_success_rate'].value\n",
    "    }\n",
    "}\n",
    "\n",
    "# 視覺化比較\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "metrics = list(benchmarks['目標'].keys())\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "target_values = [benchmarks['目標'][m] for m in metrics]\n",
    "actual_values = [benchmarks['實際'][m] for m in metrics]\n",
    "\n",
    "bars1 = ax.bar(x - width/2, target_values, width, label='目標', color='skyblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, actual_values, width, label='實際', color='lightcoral', alpha=0.8)\n",
    "\n",
    "# 添加數值標籤\n",
    "for bars in [bars1, bars2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.3f}',\n",
    "                   xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                   xytext=(0, 3),\n",
    "                   textcoords=\"offset points\",\n",
    "                   ha='center', va='bottom')\n",
    "\n",
    "# 設定圖表\n",
    "ax.set_xlabel('指標')\n",
    "ax.set_ylabel('分數')\n",
    "ax.set_title('效能基準比較')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([m.replace('_', ' ').title() for m in metrics])\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(True, axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 檢查是否達標\n",
    "print(\"\\n達標檢查:\")\n",
    "print(\"=\" * 50)\n",
    "for metric in metrics:\n",
    "    target = benchmarks['目標'][metric]\n",
    "    actual = benchmarks['實際'][metric]\n",
    "    status = \"✅ 達標\" if actual >= target else \"❌ 未達標\"\n",
    "    diff = actual - target\n",
    "    print(f\"{metric:20s}: {actual:.3f} vs {target:.3f} ({diff:+.3f}) {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "本評估報告提供了 CyberPuppy 系統的完整效能分析：\n",
    "\n",
    "1. **分類指標**：計算並視覺化了宏 F1、精確度、召回率等指標\n",
    "2. **機率指標**：評估了 AUCPR 和 ROC-AUC，並繪製 PR 曲線\n",
    "3. **會話級指標**：分析了會話內毒性變化、介入成功率等\n",
    "4. **線上監控**：展示了訓練過程的收斂情況與指標趨勢\n",
    "5. **指標匯出**：支援 Prometheus 和 CSV 格式匯出，便於整合監控系統\n",
    "\n",
    "所有指標均可透過程式化方式取得，適合整合到 CI/CD 流程中進行自動化評估。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}