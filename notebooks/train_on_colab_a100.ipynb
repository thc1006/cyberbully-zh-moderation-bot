{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 CyberPuppy 霸凌偵測訓練 - A100 優化版\n",
    "\n",
    "**GPU**: A100 (40GB)  \n",
    "**目標**: F1 ≥ 0.75  \n",
    "**優化**: 大 batch + bf16 + 快速訓練  \n",
    "\n",
    "**預計時間**: 1-2 小時（A100 加速）\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ GPU 驗證 - 確認 A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    print(f\"Compute Capability: {compute_capability}\")\n",
    "    print(f\"BF16 Support: {compute_capability[0] >= 8}\")\n",
    "    \n",
    "    if \"A100\" not in gpu_name:\n",
    "        print(f\"\\n⚠️ 警告: 當前 GPU 是 {gpu_name}，不是 A100\")\n",
    "        print(\"此 notebook 針對 A100 優化，其他 GPU 可能需要調整 batch size\")\n",
    "else:\n",
    "    print(\"❌ 未檢測到 GPU！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ GitHub 認證設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "# 從 Colab Secrets 或手動輸入\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "    print(\"✅ 從 Colab Secrets 載入 token\")\n",
    "except:\n",
    "    GITHUB_TOKEN = getpass(\"GitHub Token: \")\n",
    "\n",
    "GITHUB_USERNAME = \"thc1006\"\n",
    "REPO_NAME = \"cyberbully-zh-moderation-bot\"\n",
    "\n",
    "!git config --global user.email \"colab-a100@example.com\"\n",
    "!git config --global user.name \"Colab A100 Training\"\n",
    "\n",
    "print(\"✅ Git 配置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Clone Repository + 拉取 LFS 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# 清理舊目錄\n",
    "if os.path.exists(REPO_NAME):\n",
    "    shutil.rmtree(REPO_NAME, ignore_errors=True)\n",
    "\n",
    "os.chdir(\"/content\")\n",
    "\n",
    "# Clone\n",
    "print(\"📥 Cloning repository...\")\n",
    "repo_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
    "!git clone {repo_url}\n",
    "\n",
    "os.chdir(REPO_NAME)\n",
    "print(f\"📁 目錄: {os.getcwd()}\")\n",
    "\n",
    "# 拉取 LFS 資料\n",
    "print(\"\\n📦 拉取 Git LFS 資料...\")\n",
    "!git lfs install\n",
    "!git lfs pull\n",
    "\n",
    "# 驗證訓練資料\n",
    "train_file = \"data/processed/training_dataset/train.json\"\n",
    "file_size = os.path.getsize(train_file)\n",
    "print(f\"\\n{'✅' if file_size > 1000000 else '❌'} 訓練資料: {file_size / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 安裝依賴 - CUDA 12.x + PyTorch 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📦 安裝套件（A100 優化版本）...\")\n",
    "\n",
    "# PyTorch 2.8 + CUDA 12.6\n",
    "!pip install -q --index-url https://download.pytorch.org/whl/cu126 \\\n",
    "  torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n",
    "\n",
    "# NumPy 2.x\n",
    "!pip install -q \"numpy>=2,<2.3\"\n",
    "\n",
    "# Transformers + Accelerate\n",
    "!pip install -q transformers==4.46.3 accelerate==1.2.1 datasets==3.2.0\n",
    "!pip install -q scikit-learn==1.6.1 tqdm==4.67.1 pandas==2.2.2\n",
    "\n",
    "# TensorBoard\n",
    "!pip install -q \"tensorboard~=2.19.0\"\n",
    "\n",
    "# 驗證安裝\n",
    "import torch\n",
    "import numpy as np\n",
    "print(f\"\\n✅ PyTorch: {torch.__version__}\")\n",
    "print(f\"✅ NumPy: {np.__version__}\")\n",
    "print(f\"✅ CUDA: {torch.version.cuda}\")\n",
    "print(f\"✅ BF16 可用: {torch.cuda.is_bf16_supported()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ 驗證資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_dir = \"data/processed/training_dataset\"\n",
    "\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    filepath = os.path.join(data_dir, f\"{split}.json\")\n",
    "    file_size = os.path.getsize(filepath)\n",
    "    \n",
    "    if file_size > 100000:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"✅ {split}.json: {len(data):,} 樣本 ({file_size / 1024 / 1024:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"❌ {split}.json 是 LFS pointer ({file_size} bytes)\")\n",
    "\n",
    "print(\"\\n✅ 資料集就緒！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ A100 優化訓練配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class A100Config:\n",
    "    name: str\n",
    "    base_model: str\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    num_epochs: int\n",
    "    early_stopping_patience: int\n",
    "    bullying_weight: float\n",
    "    accumulation_steps: int = 1\n",
    "\n",
    "# A100 優化配置：更大 batch + 更快訓練\n",
    "configs = [\n",
    "    A100Config(\n",
    "        name=\"macbert_a100_optimized\",\n",
    "        base_model=\"hfl/chinese-macbert-base\",\n",
    "        learning_rate=2e-5,\n",
    "        batch_size=32,\n",
    "        num_epochs=15,\n",
    "        early_stopping_patience=4,\n",
    "        bullying_weight=2.5,\n",
    "        accumulation_steps=2,  # 等效 batch=64\n",
    "    ),\n",
    "    A100Config(\n",
    "        name=\"roberta_a100_aggressive\",\n",
    "        base_model=\"hfl/chinese-roberta-wwm-ext\",\n",
    "        learning_rate=3e-5,\n",
    "        batch_size=24,\n",
    "        num_epochs=18,\n",
    "        early_stopping_patience=3,\n",
    "        bullying_weight=2.8,\n",
    "        accumulation_steps=3,  # 等效 batch=72\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"📋 A100 訓練配置:\")\n",
    "for i, cfg in enumerate(configs, 1):\n",
    "    effective_batch = cfg.batch_size * cfg.accumulation_steps\n",
    "    print(f\"{i}. {cfg.name}\")\n",
    "    print(f\"   - Batch: {cfg.batch_size} × {cfg.accumulation_steps} = {effective_batch}\")\n",
    "    print(f\"   - LR: {cfg.learning_rate}\")\n",
    "    print(f\"   - BF16: Yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ 訓練 Model A - MacBERT (A100 優化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(f\"/content/{REPO_NAME}\")\n",
    "\n",
    "config = configs[0]\n",
    "print(f\"🚀 訓練: {config.name}\")\n",
    "print(f\"💾 等效 Batch Size: {config.batch_size * config.accumulation_steps}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_simple_with_args.py \\\n",
    "  --model_name {config.base_model} \\\n",
    "  --output_dir models/experiments/{config.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config.learning_rate} \\\n",
    "  --batch_size {config.batch_size} \\\n",
    "  --num_epochs {config.num_epochs} \\\n",
    "  --early_stopping_patience {config.early_stopping_patience} \\\n",
    "  --bullying_weight {config.bullying_weight} \\\n",
    "  --accumulation_steps {config.accumulation_steps} \\\n",
    "  --bf16\n",
    "\n",
    "print(f\"\\n✅ {config.name} 訓練完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8️⃣ 訓練 Model B - RoBERTa (激進配置)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configs[1]\n",
    "print(f\"🚀 訓練: {config.name}\")\n",
    "print(f\"💾 等效 Batch Size: {config.batch_size * config.accumulation_steps}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_simple_with_args.py \\\n",
    "  --model_name {config.base_model} \\\n",
    "  --output_dir models/experiments/{config.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config.learning_rate} \\\n",
    "  --batch_size {config.batch_size} \\\n",
    "  --num_epochs {config.num_epochs} \\\n",
    "  --early_stopping_patience {config.early_stopping_patience} \\\n",
    "  --bullying_weight {config.bullying_weight} \\\n",
    "  --accumulation_steps {config.accumulation_steps} \\\n",
    "  --bf16\n",
    "\n",
    "print(f\"\\n✅ {config.name} 訓練完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9️⃣ 評估所有模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport os\nimport glob\n\nresults = []\n\nprint(\"🔍 評估訓練結果...\\n\")\n\nfor config in configs:\n    model_dir = f\"models/experiments/{config.name}\"\n    \n    print(f\"檢查: {config.name}\")\n    print(f\"  路徑: {model_dir}\")\n    \n    if not os.path.exists(model_dir):\n        print(f\"  ❌ 目錄不存在\\n\")\n        continue\n    \n    # 列出目錄內所有檔案\n    files_in_dir = os.listdir(model_dir)\n    print(f\"  📁 目錄內容: {files_in_dir}\")\n    \n    # 尋找評估結果\n    eval_file = os.path.join(model_dir, \"eval_results.json\")\n    final_file = os.path.join(model_dir, \"final_results.json\")\n    \n    print(f\"  尋找: eval_results.json - {'✅存在' if os.path.exists(eval_file) else '❌不存在'}\")\n    print(f\"  尋找: final_results.json - {'✅存在' if os.path.exists(final_file) else '❌不存在'}\")\n    \n    metrics = None\n    if os.path.exists(final_file):\n        with open(final_file, 'r') as f:\n            metrics = json.load(f)\n        f1_score = metrics.get('test_bullying_f1', 0.0)\n        print(f\"  ✅ 使用 final_results.json\")\n    elif os.path.exists(eval_file):\n        with open(eval_file, 'r') as f:\n            metrics = json.load(f)\n        f1_score = metrics.get('bullying_f1', 0.0)\n        print(f\"  ✅ 使用 eval_results.json\")\n    else:\n        print(f\"  ⚠️ 未找到結果檔案 - 訓練可能失敗或未完成\\n\")\n        continue\n    \n    results.append({\n        'name': config.name,\n        'f1': f1_score,\n        'path': model_dir,\n        'metrics': metrics\n    })\n    \n    status = \"✅\" if f1_score >= 0.75 else \"⚠️\"\n    print(f\"  {status} F1 = {f1_score:.4f}\\n\")\n\n# 選出最佳模型\nprint(\"=\"*60)\nif results:\n    best_model = max(results, key=lambda x: x['f1'])\n    print(f\"🏆 最佳: {best_model['name']}\")\n    print(f\"📊 F1: {best_model['f1']:.4f}\")\n    print(\"=\"*60)\n    \n    with open('best_model_a100.json', 'w') as f:\n        json.dump(best_model, f, indent=2, ensure_ascii=False)\nelse:\n    print(\"❌ 沒有可用結果\")\n    print(\"可能原因:\")\n    print(\"  1. 訓練腳本執行失敗（檢查上面的輸出）\")\n    print(\"  2. 發生 CUDA OOM 或其他錯誤\")\n    print(\"  3. 資料載入失敗\")\n    print(\"  4. 請向上捲動查看訓練 cell 的完整輸出\")\n    print(\"=\"*60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔟 複製最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import shutil\nimport pandas as pd\n\nif 'best_model' in locals() and best_model['f1'] >= 0.70:\n    deploy_dir = \"models/bullying_a100_best\"\n    os.makedirs(deploy_dir, exist_ok=True)\n\n    # 驗證模型權重檔案是否存在\n    model_files = [f for f in os.listdir(best_model['path'])\n                   if f.endswith(('.safetensors', '.bin', '.pt', '.pth'))]\n\n    if not model_files:\n        print(\"❌ 錯誤: 未找到模型權重檔案！\")\n        print(f\"檢查目錄: {best_model['path']}\")\n        print(f\"目錄內容: {os.listdir(best_model['path'])}\")\n        print(\"\\n可能原因:\")\n        print(\"1. 訓練腳本沒有正確保存模型\")\n        print(\"2. 模型保存路徑不正確\")\n        print(\"3. 訓練過程中出現錯誤\")\n    else:\n        print(f\"✅ 找到 {len(model_files)} 個模型檔案:\")\n        total_size = 0\n        for f in model_files:\n            size = os.path.getsize(os.path.join(best_model['path'], f))\n            total_size += size\n            print(f\"  - {f}: {size / 1024 / 1024:.1f} MB\")\n        print(f\"總大小: {total_size / 1024 / 1024:.1f} MB\")\n\n        # 複製所有檔案\n        print(f\"\\n📦 複製到 {deploy_dir}...\")\n        for file in os.listdir(best_model['path']):\n            src = os.path.join(best_model['path'], file)\n            if os.path.isfile(src):\n                shutil.copy2(src, os.path.join(deploy_dir, file))\n\n        # 保存部署資訊\n        deploy_info = {\n            'model_name': best_model['name'],\n            'f1_score': best_model['f1'],\n            'metrics': best_model['metrics'],\n            'trained_on': 'Google Colab A100',\n            'timestamp': pd.Timestamp.now().isoformat(),\n            'model_files': model_files,\n            'total_size_mb': round(total_size / 1024 / 1024, 2)\n        }\n\n        with open(os.path.join(deploy_dir, 'deployment_info.json'), 'w') as f:\n            json.dump(deploy_info, f, indent=2, ensure_ascii=False)\n\n        # 驗證複製結果\n        copied_files = os.listdir(deploy_dir)\n        print(f\"\\n✅ 已複製 {len(copied_files)} 個檔案到 {deploy_dir}\")\n        print(f\"📊 F1: {best_model['f1']:.4f}\")\n\n        # 列出複製的檔案\n        print(\"\\n📁 部署目錄內容:\")\n        for f in sorted(copied_files):\n            size = os.path.getsize(os.path.join(deploy_dir, f))\n            print(f\"  - {f}: {size / 1024 / 1024:.1f} MB\")\nelse:\n    print(\"⚠️ 未達標或無可用模型\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣1️⃣ 推送到 GitHub (如果達標 ≥0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "TARGET_F1 = 0.75\n\nif 'best_model' in locals() and best_model['f1'] >= TARGET_F1:\n    print(f\"🎉 達標！F1 = {best_model['f1']:.4f} ≥ {TARGET_F1}\")\n    \n    # 檢查模型檔案是否存在\n    deploy_dir = \"models/bullying_a100_best\"\n    model_files = [f for f in os.listdir(deploy_dir) \n                   if f.endswith(('.safetensors', '.bin', '.pt', '.pth'))]\n    \n    if not model_files:\n        print(\"\\n❌ 錯誤: 部署目錄中沒有模型權重檔案！\")\n        print(\"請檢查上一個 cell 的輸出，確認模型是否正確複製。\")\n    else:\n        print(f\"\\n✅ 確認 {len(model_files)} 個模型檔案存在\")\n        for f in model_files:\n            size = os.path.getsize(os.path.join(deploy_dir, f))\n            print(f\"  - {f}: {size / 1024 / 1024:.1f} MB\")\n        \n        print(\"\\n推送到 GitHub...\\n\")\n        \n        # Git LFS 設定\n        print(\"📦 設定 Git LFS...\")\n        !git lfs install\n        \n        # 確保 .gitattributes 正確追蹤大檔案\n        gitattributes_content = \"\"\"# Model weights (large files)\nmodels/**/*.safetensors filter=lfs diff=lfs merge=lfs -text\nmodels/**/*.bin filter=lfs diff=lfs merge=lfs -text\nmodels/**/*.pt filter=lfs diff=lfs merge=lfs -text\nmodels/**/*.pth filter=lfs diff=lfs merge=lfs -text\nmodels/**/*.ckpt filter=lfs diff=lfs merge=lfs -text\n\n# Training data (large files)\ndata/**/*.json filter=lfs diff=lfs merge=lfs -text\ndata/**/*.csv filter=lfs diff=lfs merge=lfs -text\ndata/**/*.txt filter=lfs diff=lfs merge=lfs -text\n\"\"\"\n        \n        with open('.gitattributes', 'w') as f:\n            f.write(gitattributes_content)\n        \n        print(\"✅ .gitattributes 已更新\")\n        \n        # 添加到 Git\n        !git add .gitattributes\n        !git add models/bullying_a100_best/\n        \n        # 檢查 Git 狀態\n        print(\"\\n📋 Git 狀態:\")\n        !git status --short\n        \n        # 檢查 LFS 追蹤狀態\n        print(\"\\n📦 Git LFS 追蹤的檔案:\")\n        !git lfs ls-files\n        \n        # 提交\n        commit_msg = f\"feat: A100 trained model (F1={best_model['f1']:.4f})\"\n        print(f\"\\n💾 提交訊息: {commit_msg}\")\n        !git commit -m \"{commit_msg}\"\n        \n        # 推送（包含 LFS 檔案）\n        print(\"\\n⬆️ 推送到 GitHub（包含 LFS 檔案）...\")\n        !git push origin main\n        \n        print(\"\\n✅ 推送完成！\")\n        print(f\"\\n🎯 訓練結果:\")\n        print(f\"  - 模型: {best_model['name']}\")\n        print(f\"  - F1: {best_model['f1']:.4f}\")\n        print(f\"  - 檔案: {', '.join(model_files)}\")\n        \nelif 'best_model' in locals():\n    print(f\"⚠️ 未達標: F1 = {best_model['f1']:.4f} < {TARGET_F1}\")\n    print(\"模型未推送到 GitHub\")\nelse:\n    print(\"❌ 無可用模型\")\n    print(\"請檢查訓練過程是否有錯誤\")"
  },
  {
   "cell_type": "markdown",
   "source": "## 💾 備份到 Google Drive (可選)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 可選：備份模型到 Google Drive\n# 如果 GitHub 推送失敗或想要額外備份，可執行此 cell\n\nBACKUP_TO_DRIVE = False  # 設為 True 來啟用 Drive 備份\n\nif BACKUP_TO_DRIVE and 'best_model' in locals():\n    try:\n        from google.colab import drive\n        drive.mount('/content/drive', force_remount=True)\n        \n        # 設定備份路徑\n        drive_backup_dir = f\"/content/drive/MyDrive/CyberPuppy_Models/{best_model['name']}\"\n        os.makedirs(drive_backup_dir, exist_ok=True)\n        \n        # 複製模型到 Drive\n        deploy_dir = \"models/bullying_a100_best\"\n        print(f\"📦 備份模型到 Google Drive...\")\n        print(f\"目標: {drive_backup_dir}\")\n        \n        for file in os.listdir(deploy_dir):\n            src = os.path.join(deploy_dir, file)\n            dst = os.path.join(drive_backup_dir, file)\n            if os.path.isfile(src):\n                shutil.copy2(src, dst)\n                size = os.path.getsize(dst) / 1024 / 1024\n                print(f\"  ✅ {file} ({size:.1f} MB)\")\n        \n        print(f\"\\n✅ 備份完成！\")\n        print(f\"📁 位置: {drive_backup_dir}\")\n        \n    except Exception as e:\n        print(f\"❌ Drive 備份失敗: {e}\")\n        print(\"模型仍保存在 Colab 本地和 GitHub（如果推送成功）\")\nelse:\n    print(\"💡 提示: 如需備份到 Google Drive，請將 BACKUP_TO_DRIVE 設為 True\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣2️⃣ 訓練總結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"🎯 A100 訓練總結\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'results' in locals() and results:\n",
    "    print(\"\\n訓練結果:\")\n",
    "    for model in sorted(results, key=lambda x: x['f1'], reverse=True):\n",
    "        status = \"✅\" if model['f1'] >= TARGET_F1 else \"⚠️\"\n",
    "        print(f\"  {status} {model['name']}: F1 = {model['f1']:.4f}\")\n",
    "    \n",
    "    if 'best_model' in locals():\n",
    "        print(f\"\\n🏆 最佳: {best_model['name']}\")\n",
    "        print(f\"📊 F1: {best_model['f1']:.4f}\")\n",
    "        print(f\"🎯 目標: {TARGET_F1}\")\n",
    "        \n",
    "        if best_model['f1'] >= TARGET_F1:\n",
    "            print(\"\\n✅ 成功！模型已推送到 GitHub\")\n",
    "        else:\n",
    "            gap = TARGET_F1 - best_model['f1']\n",
    "            print(f\"\\n⚠️ 距離目標: {gap:.4f}\")\n",
    "else:\n",
    "    print(\"\\n❌ 無訓練結果\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}