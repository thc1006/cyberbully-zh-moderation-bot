{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 CyberPuppy 霸凌偵測訓練 - A100 優化版\n",
    "\n",
    "**GPU**: A100 (40GB)  \n",
    "**目標**: F1 ≥ 0.75  \n",
    "**優化**: 大 batch + bf16 + 快速訓練  \n",
    "\n",
    "**預計時間**: 1-2 小時（A100 加速）\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ GPU 驗證 - 確認 A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    print(f\"Compute Capability: {compute_capability}\")\n",
    "    print(f\"BF16 Support: {compute_capability[0] >= 8}\")\n",
    "    \n",
    "    if \"A100\" not in gpu_name:\n",
    "        print(f\"\\n⚠️ 警告: 當前 GPU 是 {gpu_name}，不是 A100\")\n",
    "        print(\"此 notebook 針對 A100 優化，其他 GPU 可能需要調整 batch size\")\n",
    "else:\n",
    "    print(\"❌ 未檢測到 GPU！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ GitHub 認證設置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "# 從 Colab Secrets 或手動輸入\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "    print(\"✅ 從 Colab Secrets 載入 token\")\n",
    "except:\n",
    "    GITHUB_TOKEN = getpass(\"GitHub Token: \")\n",
    "\n",
    "GITHUB_USERNAME = \"thc1006\"\n",
    "REPO_NAME = \"cyberbully-zh-moderation-bot\"\n",
    "\n",
    "!git config --global user.email \"colab-a100@example.com\"\n",
    "!git config --global user.name \"Colab A100 Training\"\n",
    "\n",
    "print(\"✅ Git 配置完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Clone Repository + 拉取 LFS 資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# 清理舊目錄\n",
    "if os.path.exists(REPO_NAME):\n",
    "    shutil.rmtree(REPO_NAME, ignore_errors=True)\n",
    "\n",
    "os.chdir(\"/content\")\n",
    "\n",
    "# Clone\n",
    "print(\"📥 Cloning repository...\")\n",
    "repo_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
    "!git clone {repo_url}\n",
    "\n",
    "os.chdir(REPO_NAME)\n",
    "print(f\"📁 目錄: {os.getcwd()}\")\n",
    "\n",
    "# 拉取 LFS 資料\n",
    "print(\"\\n📦 拉取 Git LFS 資料...\")\n",
    "!git lfs install\n",
    "!git lfs pull\n",
    "\n",
    "# 驗證訓練資料\n",
    "train_file = \"data/processed/training_dataset/train.json\"\n",
    "file_size = os.path.getsize(train_file)\n",
    "print(f\"\\n{'✅' if file_size > 1000000 else '❌'} 訓練資料: {file_size / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 安裝依賴 - CUDA 12.x + PyTorch 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📦 安裝套件（A100 優化版本）...\")\n",
    "\n",
    "# PyTorch 2.8 + CUDA 12.6\n",
    "!pip install -q --index-url https://download.pytorch.org/whl/cu126 \\\n",
    "  torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n",
    "\n",
    "# NumPy 2.x\n",
    "!pip install -q \"numpy>=2,<2.3\"\n",
    "\n",
    "# Transformers + Accelerate\n",
    "!pip install -q transformers==4.46.3 accelerate==1.2.1 datasets==3.2.0\n",
    "!pip install -q scikit-learn==1.6.1 tqdm==4.67.1 pandas==2.2.2\n",
    "\n",
    "# TensorBoard\n",
    "!pip install -q \"tensorboard~=2.19.0\"\n",
    "\n",
    "# 驗證安裝\n",
    "import torch\n",
    "import numpy as np\n",
    "print(f\"\\n✅ PyTorch: {torch.__version__}\")\n",
    "print(f\"✅ NumPy: {np.__version__}\")\n",
    "print(f\"✅ CUDA: {torch.version.cuda}\")\n",
    "print(f\"✅ BF16 可用: {torch.cuda.is_bf16_supported()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ 驗證資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_dir = \"data/processed/training_dataset\"\n",
    "\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    filepath = os.path.join(data_dir, f\"{split}.json\")\n",
    "    file_size = os.path.getsize(filepath)\n",
    "    \n",
    "    if file_size > 100000:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"✅ {split}.json: {len(data):,} 樣本 ({file_size / 1024 / 1024:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"❌ {split}.json 是 LFS pointer ({file_size} bytes)\")\n",
    "\n",
    "print(\"\\n✅ 資料集就緒！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ A100 優化訓練配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class A100Config:\n",
    "    name: str\n",
    "    base_model: str\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    num_epochs: int\n",
    "    early_stopping_patience: int\n",
    "    bullying_weight: float\n",
    "    accumulation_steps: int = 1\n",
    "\n",
    "# A100 優化配置：更大 batch + 更快訓練\n",
    "configs = [\n",
    "    A100Config(\n",
    "        name=\"macbert_a100_optimized\",\n",
    "        base_model=\"hfl/chinese-macbert-base\",\n",
    "        learning_rate=2e-5,\n",
    "        batch_size=32,\n",
    "        num_epochs=15,\n",
    "        early_stopping_patience=4,\n",
    "        bullying_weight=2.5,\n",
    "        accumulation_steps=2,  # 等效 batch=64\n",
    "    ),\n",
    "    A100Config(\n",
    "        name=\"roberta_a100_aggressive\",\n",
    "        base_model=\"hfl/chinese-roberta-wwm-ext\",\n",
    "        learning_rate=3e-5,\n",
    "        batch_size=24,\n",
    "        num_epochs=18,\n",
    "        early_stopping_patience=3,\n",
    "        bullying_weight=2.8,\n",
    "        accumulation_steps=3,  # 等效 batch=72\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"📋 A100 訓練配置:\")\n",
    "for i, cfg in enumerate(configs, 1):\n",
    "    effective_batch = cfg.batch_size * cfg.accumulation_steps\n",
    "    print(f\"{i}. {cfg.name}\")\n",
    "    print(f\"   - Batch: {cfg.batch_size} × {cfg.accumulation_steps} = {effective_batch}\")\n",
    "    print(f\"   - LR: {cfg.learning_rate}\")\n",
    "    print(f\"   - BF16: Yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ 訓練 Model A - MacBERT (A100 優化)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(f\"/content/{REPO_NAME}\")\n",
    "\n",
    "config = configs[0]\n",
    "print(f\"🚀 訓練: {config.name}\")\n",
    "print(f\"💾 等效 Batch Size: {config.batch_size * config.accumulation_steps}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_simple_with_args.py \\\n",
    "  --model_name {config.base_model} \\\n",
    "  --output_dir models/experiments/{config.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config.learning_rate} \\\n",
    "  --batch_size {config.batch_size} \\\n",
    "  --num_epochs {config.num_epochs} \\\n",
    "  --early_stopping_patience {config.early_stopping_patience} \\\n",
    "  --bullying_weight {config.bullying_weight} \\\n",
    "  --accumulation_steps {config.accumulation_steps} \\\n",
    "  --bf16\n",
    "\n",
    "print(f\"\\n✅ {config.name} 訓練完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8️⃣ 訓練 Model B - RoBERTa (激進配置)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configs[1]\n",
    "print(f\"🚀 訓練: {config.name}\")\n",
    "print(f\"💾 等效 Batch Size: {config.batch_size * config.accumulation_steps}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_simple_with_args.py \\\n",
    "  --model_name {config.base_model} \\\n",
    "  --output_dir models/experiments/{config.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config.learning_rate} \\\n",
    "  --batch_size {config.batch_size} \\\n",
    "  --num_epochs {config.num_epochs} \\\n",
    "  --early_stopping_patience {config.early_stopping_patience} \\\n",
    "  --bullying_weight {config.bullying_weight} \\\n",
    "  --accumulation_steps {config.accumulation_steps} \\\n",
    "  --bf16\n",
    "\n",
    "print(f\"\\n✅ {config.name} 訓練完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9️⃣ 評估所有模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"🔍 評估訓練結果...\\n\")\n",
    "\n",
    "for config in configs:\n",
    "    model_dir = f\"models/experiments/{config.name}\"\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        print(f\"⚠️ {config.name}: 目錄不存在\")\n",
    "        continue\n",
    "    \n",
    "    # 尋找評估結果\n",
    "    eval_file = os.path.join(model_dir, \"eval_results.json\")\n",
    "    final_file = os.path.join(model_dir, \"final_results.json\")\n",
    "    \n",
    "    metrics = None\n",
    "    if os.path.exists(final_file):\n",
    "        with open(final_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        f1_score = metrics.get('test_bullying_f1', 0.0)\n",
    "    elif os.path.exists(eval_file):\n",
    "        with open(eval_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        f1_score = metrics.get('bullying_f1', 0.0)\n",
    "    else:\n",
    "        print(f\"⚠️ {config.name}: 未找到評估結果\")\n",
    "        continue\n",
    "    \n",
    "    results.append({\n",
    "        'name': config.name,\n",
    "        'f1': f1_score,\n",
    "        'path': model_dir,\n",
    "        'metrics': metrics\n",
    "    })\n",
    "    \n",
    "    status = \"✅\" if f1_score >= 0.75 else \"⚠️\"\n",
    "    print(f\"{status} {config.name}: F1 = {f1_score:.4f}\")\n",
    "\n",
    "# 選出最佳模型\n",
    "if results:\n",
    "    best_model = max(results, key=lambda x: x['f1'])\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"🏆 最佳: {best_model['name']}\")\n",
    "    print(f\"📊 F1: {best_model['f1']:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with open('best_model_a100.json', 'w') as f:\n",
    "        json.dump(best_model, f, indent=2, ensure_ascii=False)\n",
    "else:\n",
    "    print(\"\\n❌ 沒有可用結果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔟 複製最佳模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "if 'best_model' in locals() and best_model['f1'] >= 0.70:\n",
    "    deploy_dir = \"models/bullying_a100_best\"\n",
    "    os.makedirs(deploy_dir, exist_ok=True)\n",
    "    \n",
    "    # 複製模型\n",
    "    for file in os.listdir(best_model['path']):\n",
    "        src = os.path.join(best_model['path'], file)\n",
    "        if os.path.isfile(src):\n",
    "            shutil.copy2(src, os.path.join(deploy_dir, file))\n",
    "    \n",
    "    # 保存資訊\n",
    "    deploy_info = {\n",
    "        'model_name': best_model['name'],\n",
    "        'f1_score': best_model['f1'],\n",
    "        'metrics': best_model['metrics'],\n",
    "        'trained_on': 'Google Colab A100',\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(deploy_dir, 'deployment_info.json'), 'w') as f:\n",
    "        json.dump(deploy_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"✅ 模型已複製到: {deploy_dir}\")\n",
    "    print(f\"📊 F1: {best_model['f1']:.4f}\")\n",
    "else:\n",
    "    print(\"⚠️ 未達標或無可用模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣1️⃣ 推送到 GitHub (如果達標 ≥0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_F1 = 0.75\n",
    "\n",
    "if 'best_model' in locals() and best_model['f1'] >= TARGET_F1:\n",
    "    print(f\"🎉 達標！F1 = {best_model['f1']:.4f} ≥ {TARGET_F1}\")\n",
    "    print(\"推送到 GitHub...\\n\")\n",
    "    \n",
    "    # Git LFS\n",
    "    !git lfs install\n",
    "    !git lfs track \"models/bullying_a100_best/**/*.safetensors\"\n",
    "    !git lfs track \"models/bullying_a100_best/**/*.bin\"\n",
    "    !git add .gitattributes\n",
    "    \n",
    "    # 添加模型\n",
    "    !git add models/bullying_a100_best/\n",
    "    \n",
    "    # 提交\n",
    "    commit_msg = f\"feat: A100 trained model (F1={best_model['f1']:.4f})\"\n",
    "    !git commit -m \"{commit_msg}\"\n",
    "    \n",
    "    # 推送\n",
    "    !git push origin main\n",
    "    \n",
    "    print(\"\\n✅ 推送完成！\")\n",
    "elif 'best_model' in locals():\n",
    "    print(f\"⚠️ 未達標: F1 = {best_model['f1']:.4f} < {TARGET_F1}\")\n",
    "else:\n",
    "    print(\"❌ 無可用模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣2️⃣ 訓練總結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"🎯 A100 訓練總結\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'results' in locals() and results:\n",
    "    print(\"\\n訓練結果:\")\n",
    "    for model in sorted(results, key=lambda x: x['f1'], reverse=True):\n",
    "        status = \"✅\" if model['f1'] >= TARGET_F1 else \"⚠️\"\n",
    "        print(f\"  {status} {model['name']}: F1 = {model['f1']:.4f}\")\n",
    "    \n",
    "    if 'best_model' in locals():\n",
    "        print(f\"\\n🏆 最佳: {best_model['name']}\")\n",
    "        print(f\"📊 F1: {best_model['f1']:.4f}\")\n",
    "        print(f\"🎯 目標: {TARGET_F1}\")\n",
    "        \n",
    "        if best_model['f1'] >= TARGET_F1:\n",
    "            print(\"\\n✅ 成功！模型已推送到 GitHub\")\n",
    "        else:\n",
    "            gap = TARGET_F1 - best_model['f1']\n",
    "            print(f\"\\n⚠️ 距離目標: {gap:.4f}\")\n",
    "else:\n",
    "    print(\"\\n❌ 無訓練結果\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}