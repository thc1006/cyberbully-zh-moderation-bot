{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ CyberPuppy éœ¸å‡Œåµæ¸¬è¨“ç·´ - A100 å„ªåŒ–ç‰ˆ\n",
    "\n",
    "**GPU**: A100 (40GB)  \n",
    "**ç›®æ¨™**: F1 â‰¥ 0.75  \n",
    "**å„ªåŒ–**: å¤§ batch + bf16 + å¿«é€Ÿè¨“ç·´  \n",
    "\n",
    "**é è¨ˆæ™‚é–“**: 1-2 å°æ™‚ï¼ˆA100 åŠ é€Ÿï¼‰\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ GPU é©—è­‰ - ç¢ºèª A100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {gpu_name}\")\n",
    "    print(f\"Memory: {gpu_memory:.1f} GB\")\n",
    "    \n",
    "    compute_capability = torch.cuda.get_device_capability(0)\n",
    "    print(f\"Compute Capability: {compute_capability}\")\n",
    "    print(f\"BF16 Support: {compute_capability[0] >= 8}\")\n",
    "    \n",
    "    if \"A100\" not in gpu_name:\n",
    "        print(f\"\\nâš ï¸ è­¦å‘Š: ç•¶å‰ GPU æ˜¯ {gpu_name}ï¼Œä¸æ˜¯ A100\")\n",
    "        print(\"æ­¤ notebook é‡å° A100 å„ªåŒ–ï¼Œå…¶ä»– GPU å¯èƒ½éœ€è¦èª¿æ•´ batch size\")\n",
    "else:\n",
    "    print(\"âŒ æœªæª¢æ¸¬åˆ° GPUï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ GitHub èªè­‰è¨­ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "# å¾ Colab Secrets æˆ–æ‰‹å‹•è¼¸å…¥\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "    print(\"âœ… å¾ Colab Secrets è¼‰å…¥ token\")\n",
    "except:\n",
    "    GITHUB_TOKEN = getpass(\"GitHub Token: \")\n",
    "\n",
    "GITHUB_USERNAME = \"thc1006\"\n",
    "REPO_NAME = \"cyberbully-zh-moderation-bot\"\n",
    "\n",
    "!git config --global user.email \"colab-a100@example.com\"\n",
    "!git config --global user.name \"Colab A100 Training\"\n",
    "\n",
    "print(\"âœ… Git é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Clone Repository + æ‹‰å– LFS è³‡æ–™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import shutil\n",
    "\n",
    "# æ¸…ç†èˆŠç›®éŒ„\n",
    "if os.path.exists(REPO_NAME):\n",
    "    shutil.rmtree(REPO_NAME, ignore_errors=True)\n",
    "\n",
    "os.chdir(\"/content\")\n",
    "\n",
    "# Clone\n",
    "print(\"ğŸ“¥ Cloning repository...\")\n",
    "repo_url = f\"https://{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
    "!git clone {repo_url}\n",
    "\n",
    "os.chdir(REPO_NAME)\n",
    "print(f\"ğŸ“ ç›®éŒ„: {os.getcwd()}\")\n",
    "\n",
    "# æ‹‰å– LFS è³‡æ–™\n",
    "print(\"\\nğŸ“¦ æ‹‰å– Git LFS è³‡æ–™...\")\n",
    "!git lfs install\n",
    "!git lfs pull\n",
    "\n",
    "# é©—è­‰è¨“ç·´è³‡æ–™\n",
    "train_file = \"data/processed/training_dataset/train.json\"\n",
    "file_size = os.path.getsize(train_file)\n",
    "print(f\"\\n{'âœ…' if file_size > 1000000 else 'âŒ'} è¨“ç·´è³‡æ–™: {file_size / 1024 / 1024:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ å®‰è£ä¾è³´ - CUDA 12.x + PyTorch 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“¦ å®‰è£å¥—ä»¶ï¼ˆA100 å„ªåŒ–ç‰ˆæœ¬ï¼‰...\")\n",
    "\n",
    "# PyTorch 2.8 + CUDA 12.6\n",
    "!pip install -q --index-url https://download.pytorch.org/whl/cu126 \\\n",
    "  torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n",
    "\n",
    "# NumPy 2.x\n",
    "!pip install -q \"numpy>=2,<2.3\"\n",
    "\n",
    "# Transformers + Accelerate\n",
    "!pip install -q transformers==4.46.3 accelerate==1.2.1 datasets==3.2.0\n",
    "!pip install -q scikit-learn==1.6.1 tqdm==4.67.1 pandas==2.2.2\n",
    "\n",
    "# TensorBoard\n",
    "!pip install -q \"tensorboard~=2.19.0\"\n",
    "\n",
    "# é©—è­‰å®‰è£\n",
    "import torch\n",
    "import numpy as np\n",
    "print(f\"\\nâœ… PyTorch: {torch.__version__}\")\n",
    "print(f\"âœ… NumPy: {np.__version__}\")\n",
    "print(f\"âœ… CUDA: {torch.version.cuda}\")\n",
    "print(f\"âœ… BF16 å¯ç”¨: {torch.cuda.is_bf16_supported()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ é©—è­‰è³‡æ–™é›†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_dir = \"data/processed/training_dataset\"\n",
    "\n",
    "for split in [\"train\", \"dev\", \"test\"]:\n",
    "    filepath = os.path.join(data_dir, f\"{split}.json\")\n",
    "    file_size = os.path.getsize(filepath)\n",
    "    \n",
    "    if file_size > 100000:\n",
    "        with open(filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"âœ… {split}.json: {len(data):,} æ¨£æœ¬ ({file_size / 1024 / 1024:.1f} MB)\")\n",
    "    else:\n",
    "        print(f\"âŒ {split}.json æ˜¯ LFS pointer ({file_size} bytes)\")\n",
    "\n",
    "print(\"\\nâœ… è³‡æ–™é›†å°±ç·’ï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ A100 å„ªåŒ–è¨“ç·´é…ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class A100Config:\n",
    "    name: str\n",
    "    base_model: str\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    num_epochs: int\n",
    "    early_stopping_patience: int\n",
    "    bullying_weight: float\n",
    "    accumulation_steps: int = 1\n",
    "\n",
    "# A100 å„ªåŒ–é…ç½®ï¼šæ›´å¤§ batch + æ›´å¿«è¨“ç·´\n",
    "configs = [\n",
    "    A100Config(\n",
    "        name=\"macbert_a100_optimized\",\n",
    "        base_model=\"hfl/chinese-macbert-base\",\n",
    "        learning_rate=2e-5,\n",
    "        batch_size=32,\n",
    "        num_epochs=15,\n",
    "        early_stopping_patience=4,\n",
    "        bullying_weight=2.5,\n",
    "        accumulation_steps=2,  # ç­‰æ•ˆ batch=64\n",
    "    ),\n",
    "    A100Config(\n",
    "        name=\"roberta_a100_aggressive\",\n",
    "        base_model=\"hfl/chinese-roberta-wwm-ext\",\n",
    "        learning_rate=3e-5,\n",
    "        batch_size=24,\n",
    "        num_epochs=18,\n",
    "        early_stopping_patience=3,\n",
    "        bullying_weight=2.8,\n",
    "        accumulation_steps=3,  # ç­‰æ•ˆ batch=72\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"ğŸ“‹ A100 è¨“ç·´é…ç½®:\")\n",
    "for i, cfg in enumerate(configs, 1):\n",
    "    effective_batch = cfg.batch_size * cfg.accumulation_steps\n",
    "    print(f\"{i}. {cfg.name}\")\n",
    "    print(f\"   - Batch: {cfg.batch_size} Ã— {cfg.accumulation_steps} = {effective_batch}\")\n",
    "    print(f\"   - LR: {cfg.learning_rate}\")\n",
    "    print(f\"   - BF16: Yes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ è¨“ç·´ Model A - MacBERT (A100 å„ªåŒ–)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(f\"/content/{REPO_NAME}\")\n",
    "\n",
    "config = configs[0]\n",
    "print(f\"ğŸš€ è¨“ç·´: {config.name}\")\n",
    "print(f\"ğŸ’¾ ç­‰æ•ˆ Batch Size: {config.batch_size * config.accumulation_steps}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_simple_with_args.py \\\n",
    "  --model_name {config.base_model} \\\n",
    "  --output_dir models/experiments/{config.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config.learning_rate} \\\n",
    "  --batch_size {config.batch_size} \\\n",
    "  --num_epochs {config.num_epochs} \\\n",
    "  --early_stopping_patience {config.early_stopping_patience} \\\n",
    "  --bullying_weight {config.bullying_weight} \\\n",
    "  --accumulation_steps {config.accumulation_steps} \\\n",
    "  --bf16\n",
    "\n",
    "print(f\"\\nâœ… {config.name} è¨“ç·´å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ è¨“ç·´ Model B - RoBERTa (æ¿€é€²é…ç½®)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configs[1]\n",
    "print(f\"ğŸš€ è¨“ç·´: {config.name}\")\n",
    "print(f\"ğŸ’¾ ç­‰æ•ˆ Batch Size: {config.batch_size * config.accumulation_steps}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_simple_with_args.py \\\n",
    "  --model_name {config.base_model} \\\n",
    "  --output_dir models/experiments/{config.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config.learning_rate} \\\n",
    "  --batch_size {config.batch_size} \\\n",
    "  --num_epochs {config.num_epochs} \\\n",
    "  --early_stopping_patience {config.early_stopping_patience} \\\n",
    "  --bullying_weight {config.bullying_weight} \\\n",
    "  --accumulation_steps {config.accumulation_steps} \\\n",
    "  --bf16\n",
    "\n",
    "print(f\"\\nâœ… {config.name} è¨“ç·´å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ è©•ä¼°æ‰€æœ‰æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"ğŸ” è©•ä¼°è¨“ç·´çµæœ...\\n\")\n",
    "\n",
    "for config in configs:\n",
    "    model_dir = f\"models/experiments/{config.name}\"\n",
    "    \n",
    "    if not os.path.exists(model_dir):\n",
    "        print(f\"âš ï¸ {config.name}: ç›®éŒ„ä¸å­˜åœ¨\")\n",
    "        continue\n",
    "    \n",
    "    # å°‹æ‰¾è©•ä¼°çµæœ\n",
    "    eval_file = os.path.join(model_dir, \"eval_results.json\")\n",
    "    final_file = os.path.join(model_dir, \"final_results.json\")\n",
    "    \n",
    "    metrics = None\n",
    "    if os.path.exists(final_file):\n",
    "        with open(final_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        f1_score = metrics.get('test_bullying_f1', 0.0)\n",
    "    elif os.path.exists(eval_file):\n",
    "        with open(eval_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        f1_score = metrics.get('bullying_f1', 0.0)\n",
    "    else:\n",
    "        print(f\"âš ï¸ {config.name}: æœªæ‰¾åˆ°è©•ä¼°çµæœ\")\n",
    "        continue\n",
    "    \n",
    "    results.append({\n",
    "        'name': config.name,\n",
    "        'f1': f1_score,\n",
    "        'path': model_dir,\n",
    "        'metrics': metrics\n",
    "    })\n",
    "    \n",
    "    status = \"âœ…\" if f1_score >= 0.75 else \"âš ï¸\"\n",
    "    print(f\"{status} {config.name}: F1 = {f1_score:.4f}\")\n",
    "\n",
    "# é¸å‡ºæœ€ä½³æ¨¡å‹\n",
    "if results:\n",
    "    best_model = max(results, key=lambda x: x['f1'])\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ† æœ€ä½³: {best_model['name']}\")\n",
    "    print(f\"ğŸ“Š F1: {best_model['f1']:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    with open('best_model_a100.json', 'w') as f:\n",
    "        json.dump(best_model, f, indent=2, ensure_ascii=False)\n",
    "else:\n",
    "    print(\"\\nâŒ æ²’æœ‰å¯ç”¨çµæœ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ è¤‡è£½æœ€ä½³æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "if 'best_model' in locals() and best_model['f1'] >= 0.70:\n",
    "    deploy_dir = \"models/bullying_a100_best\"\n",
    "    os.makedirs(deploy_dir, exist_ok=True)\n",
    "    \n",
    "    # è¤‡è£½æ¨¡å‹\n",
    "    for file in os.listdir(best_model['path']):\n",
    "        src = os.path.join(best_model['path'], file)\n",
    "        if os.path.isfile(src):\n",
    "            shutil.copy2(src, os.path.join(deploy_dir, file))\n",
    "    \n",
    "    # ä¿å­˜è³‡è¨Š\n",
    "    deploy_info = {\n",
    "        'model_name': best_model['name'],\n",
    "        'f1_score': best_model['f1'],\n",
    "        'metrics': best_model['metrics'],\n",
    "        'trained_on': 'Google Colab A100',\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(deploy_dir, 'deployment_info.json'), 'w') as f:\n",
    "        json.dump(deploy_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"âœ… æ¨¡å‹å·²è¤‡è£½åˆ°: {deploy_dir}\")\n",
    "    print(f\"ğŸ“Š F1: {best_model['f1']:.4f}\")\n",
    "else:\n",
    "    print(\"âš ï¸ æœªé”æ¨™æˆ–ç„¡å¯ç”¨æ¨¡å‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ æ¨é€åˆ° GitHub (å¦‚æœé”æ¨™ â‰¥0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_F1 = 0.75\n",
    "\n",
    "if 'best_model' in locals() and best_model['f1'] >= TARGET_F1:\n",
    "    print(f\"ğŸ‰ é”æ¨™ï¼F1 = {best_model['f1']:.4f} â‰¥ {TARGET_F1}\")\n",
    "    print(\"æ¨é€åˆ° GitHub...\\n\")\n",
    "    \n",
    "    # Git LFS\n",
    "    !git lfs install\n",
    "    !git lfs track \"models/bullying_a100_best/**/*.safetensors\"\n",
    "    !git lfs track \"models/bullying_a100_best/**/*.bin\"\n",
    "    !git add .gitattributes\n",
    "    \n",
    "    # æ·»åŠ æ¨¡å‹\n",
    "    !git add models/bullying_a100_best/\n",
    "    \n",
    "    # æäº¤\n",
    "    commit_msg = f\"feat: A100 trained model (F1={best_model['f1']:.4f})\"\n",
    "    !git commit -m \"{commit_msg}\"\n",
    "    \n",
    "    # æ¨é€\n",
    "    !git push origin main\n",
    "    \n",
    "    print(\"\\nâœ… æ¨é€å®Œæˆï¼\")\n",
    "elif 'best_model' in locals():\n",
    "    print(f\"âš ï¸ æœªé”æ¨™: F1 = {best_model['f1']:.4f} < {TARGET_F1}\")\n",
    "else:\n",
    "    print(\"âŒ ç„¡å¯ç”¨æ¨¡å‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ è¨“ç·´ç¸½çµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ğŸ¯ A100 è¨“ç·´ç¸½çµ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'results' in locals() and results:\n",
    "    print(\"\\nè¨“ç·´çµæœ:\")\n",
    "    for model in sorted(results, key=lambda x: x['f1'], reverse=True):\n",
    "        status = \"âœ…\" if model['f1'] >= TARGET_F1 else \"âš ï¸\"\n",
    "        print(f\"  {status} {model['name']}: F1 = {model['f1']:.4f}\")\n",
    "    \n",
    "    if 'best_model' in locals():\n",
    "        print(f\"\\nğŸ† æœ€ä½³: {best_model['name']}\")\n",
    "        print(f\"ğŸ“Š F1: {best_model['f1']:.4f}\")\n",
    "        print(f\"ğŸ¯ ç›®æ¨™: {TARGET_F1}\")\n",
    "        \n",
    "        if best_model['f1'] >= TARGET_F1:\n",
    "            print(\"\\nâœ… æˆåŠŸï¼æ¨¡å‹å·²æ¨é€åˆ° GitHub\")\n",
    "        else:\n",
    "            gap = TARGET_F1 - best_model['f1']\n",
    "            print(f\"\\nâš ï¸ è·é›¢ç›®æ¨™: {gap:.4f}\")\n",
    "else:\n",
    "    print(\"\\nâŒ ç„¡è¨“ç·´çµæœ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}