{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ CyberPuppy éœ¸å‡Œåµæ¸¬è¨“ç·´ - Google Colab\n",
    "\n",
    "**ç›®æ¨™**: é”æˆ F1 â‰¥ 0.75 çš„éœ¸å‡Œåµæ¸¬æ¨¡å‹  \n",
    "**ç­–ç•¥**: å¤šæ¨¡å‹è¨“ç·´ + æ™ºèƒ½é¸æ“‡ + è‡ªå‹•æ¨é€  \n",
    "**GPU**: T4 (å…è²») / V100 / A100 (Pro)  \n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“‹ ä½¿ç”¨èªªæ˜\n",
    "\n",
    "1. **æª¢æŸ¥ GPU**: Runtime â†’ Change runtime type â†’ GPU\n",
    "2. **åŸ·è¡Œæ‰€æœ‰ cell**: Runtime â†’ Run all\n",
    "3. **ç›£æ§è¨“ç·´**: TensorBoard æœƒè‡ªå‹•é¡¯ç¤º\n",
    "4. **è‡ªå‹•æ¨é€**: é”æ¨™æ¨¡å‹æœƒè‡ªå‹•æ¨é€å› GitHub\n",
    "\n",
    "**é è¨ˆæ™‚é–“**:\n",
    "- T4: 6-9 å°æ™‚ (å…è²»)\n",
    "- V100: 3-5 å°æ™‚ (Pro)\n",
    "- A100: 2-3 å°æ™‚ (Pro+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ ç’°å¢ƒè¨­ç½®èˆ‡ GPU æª¢æŸ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æª¢æŸ¥ GPU å¯ç”¨æ€§\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ è­¦å‘Š: æœªåµæ¸¬åˆ° GPUï¼è«‹æª¢æŸ¥ Runtime è¨­ç½®\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Clone Repository (å„ªåŒ–ç‰ˆ - è·³éå¤§æ¨¡å‹)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨­ç½® GitHub èªè­‰ (éœ€è¦å€‹äººè¨ªå•ä»¤ç‰Œ)\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# è¼¸å…¥ä½ çš„ GitHub è³‡è¨Š\n",
    "GITHUB_USERNAME = input(\"GitHub ç”¨æˆ¶å: \")\n",
    "GITHUB_TOKEN = getpass(\"GitHub Personal Access Token (éœ€è¦ repo æ¬Šé™): \")\n",
    "REPO_NAME = \"cyberbully-zh-moderation-bot\"\n",
    "\n",
    "# è¨­ç½® Git é…ç½®\n",
    "!git config --global user.email \"colab@example.com\"\n",
    "!git config --global user.name \"Colab Training Bot\"\n",
    "\n",
    "print(\"âœ… Git é…ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone repository (è·³é LFS å¤§æª”æ¡ˆ)\nimport os\n\nif os.path.exists(REPO_NAME):\n    print(\"ğŸ“‚ Repository å·²å­˜åœ¨ï¼Œè·³é clone\")\nelse:\n    print(\"ğŸ“¥ é–‹å§‹ clone repository...\")\n    \n    # ä½¿ç”¨ token é€²è¡Œèªè­‰\n    repo_url = f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n    \n    # Clone repository (å…ˆè·³é LFS)\n    !GIT_LFS_SKIP_SMUDGE=1 git clone --depth 1 {repo_url}\n    %cd {REPO_NAME}\n\n    # å®‰è£ Git LFS\n    !git lfs install\n\n    # è¨­ç½® Git LFS èªè­‰ (é¿å… Bad credentials éŒ¯èª¤)\n    !git config lfs.url https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git/info/lfs\n\n    print(\"ğŸ“¥ ä¸‹è¼‰è¨“ç·´è³‡æ–™ (é€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜)...\")\n    \n    # ä¸‹è¼‰è¨“ç·´è³‡æ–™\n    !git lfs pull --include=\"data/processed/training_dataset/train.json\"\n    !git lfs pull --include=\"data/processed/training_dataset/dev.json\"\n    !git lfs pull --include=\"data/processed/training_dataset/test.json\"\n    !git lfs pull --include=\"data/processed/cold_augmented.csv\"\n\n    # é©—è­‰æª”æ¡ˆå®Œæ•´æ€§\n    train_file = \"data/processed/training_dataset/train.json\"\n    if os.path.exists(train_file):\n        file_size = os.path.getsize(train_file)\n        if file_size > 1000000:  # æ‡‰è©²è‡³å°‘ 1 MB\n            print(f\"âœ… è¨“ç·´è³‡æ–™å·²ä¸‹è¼‰: {file_size / 1024 / 1024:.1f} MB\")\n        else:\n            print(f\"âš ï¸ è¨“ç·´è³‡æ–™å¯èƒ½ä¸å®Œæ•´: {file_size} bytes\")\n            print(\"å¦‚æœä¸‹è¼‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥:\")\n            print(\"1. GitHub Token æ˜¯å¦æœ‰æ•ˆ\")\n            print(\"2. Token æ˜¯å¦æœ‰ repo å®Œæ•´æ¬Šé™\")\n            print(\"3. Git LFS é »å¯¬æ˜¯å¦è¶³å¤ \")\n    else:\n        print(\"âŒ è¨“ç·´è³‡æ–™ä¸‹è¼‰å¤±æ•—\")\n\n    print(\"âœ… Repository è¨­ç½®å®Œæˆ\")\n\n# åˆ‡æ›åˆ°å°ˆæ¡ˆç›®éŒ„\n%cd /content/{REPO_NAME}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ å®‰è£ä¾è³´å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# å®‰è£å¿…è¦å¥—ä»¶ï¼ˆCUDA 12.6 + PyTorch 2.8 ä¸‰ä»¶å¥—ã€NumPy 2.xã€TensorBoard å°é½Šï¼‰\nprint(\"ğŸ“¦ å®‰è£ä¾è³´å¥—ä»¶...\")\n\n# â”€â”€ GPU (CUDA 12.6) ç‰ˆæœ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n!pip install -q --index-url https://download.pytorch.org/whl/cu126 \\\n  torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n\n# è‹¥æ²’æœ‰ GPUï¼Œè¦ CPU ç‰ˆè«‹æ”¹ç”¨ï¼š\n# !pip install -q --index-url https://download.pytorch.org/whl/cpu \\\n#   torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n\n# ç§‘å­¸è¨ˆç®—åŸºç¤ï¼šNumPy 2.xï¼ˆOpenCV 4.12.* éœ€è¦ >=2 ä¸” <2.3ï¼‰\n!pip install -q \"numpy>=2,<2.3\"\n\n# å…¶é¤˜å¥—ä»¶ï¼ˆèˆ‡ä¸Šé¢ç‰ˆæœ¬ç›¸å®¹ï¼‰\n!pip install -q transformers==4.46.3 accelerate==1.2.1 datasets==3.2.0\n!pip install -q scikit-learn==1.6.1 tqdm==4.67.1\n\n# Colab å¸¸è¦‹ç›¸ä¾ï¼šé¿å… google-colab 1.0.0 çš„ pandas é‡˜ç‰ˆè­¦å‘Š\n!pip install -q pandas==2.2.2\n\n# TensorBoard å°é½Š TensorFlow 2.19\n!pip install -q \"tensorboard~=2.19.0\"\n\n# WandBï¼ˆå¯é¸ï¼šæ›´å¥½çš„å¯¦é©—è¿½è¹¤ï¼‰\n!pip install -q wandb==0.19.1\n\n# é©—è­‰æ˜¯å¦é‚„æœ‰æ®˜ç•™ä¸ç›¸å®¹\n!python -m pip check\n\nprint(\"âœ… å¥—ä»¶å®‰è£å®Œæˆ\")\n\n# é©—è­‰ç‰ˆæœ¬\nimport torch\nimport numpy as np\nprint(f\"âœ… PyTorch: {torch.__version__}\")\nprint(f\"âœ… NumPy: {np.__version__}\")\nprint(f\"âœ… CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"âœ… CUDA version: {torch.version.cuda}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ é©—è­‰è³‡æ–™é›†å®Œæ•´æ€§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# æª¢æŸ¥è¨“ç·´è³‡æ–™\nimport json\nimport os\n\ndata_dir = \"data/processed/training_dataset\"\nall_ok = True\n\nfor split in [\"train\", \"dev\", \"test\"]:\n    filepath = os.path.join(data_dir, f\"{split}.json\")\n    if os.path.exists(filepath):\n        file_size = os.path.getsize(filepath)\n        if file_size > 100000:  # è‡³å°‘è¦å¤§æ–¼ 100KB\n            try:\n                with open(filepath, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                print(f\"âœ… {split}.json: {len(data)} æ¨£æœ¬ ({file_size / 1024 / 1024:.1f} MB)\")\n            except json.JSONDecodeError as e:\n                print(f\"âŒ {split}.json JSON æ ¼å¼éŒ¯èª¤: {e}\")\n                print(f\"   æª”æ¡ˆå¤§å°: {file_size} bytes\")\n                print(f\"   é€™å¯èƒ½æ˜¯ Git LFS æŒ‡æ¨™æª”æ¡ˆï¼Œä¸æ˜¯å¯¦éš›è³‡æ–™\")\n                all_ok = False\n        else:\n            print(f\"âš ï¸ {split}.json æª”æ¡ˆå¤ªå° ({file_size} bytes)\")\n            print(f\"   é€™æ˜¯ Git LFS æŒ‡æ¨™æª”æ¡ˆï¼Œå¯¦éš›è³‡æ–™æœªä¸‹è¼‰\")\n            all_ok = False\n    else:\n        print(f\"âŒ ç¼ºå°‘ {split}.json\")\n        all_ok = False\n\n# æª¢æŸ¥å¢å¼·è³‡æ–™\naugmented_path = \"data/processed/cold_augmented.csv\"\nif os.path.exists(augmented_path):\n    file_size = os.path.getsize(augmented_path)\n    if file_size > 1000000:  # è‡³å°‘ 1MB\n        print(f\"âœ… å¢å¼·è³‡æ–™: {file_size / 1024 / 1024:.1f} MB\")\n    else:\n        print(f\"âš ï¸ å¢å¼·è³‡æ–™æª”æ¡ˆå¤ªå°: {file_size} bytes\")\nelse:\n    print(\"âš ï¸ æœªæ‰¾åˆ°å¢å¼·è³‡æ–™\")\n\nif not all_ok:\n    print(\"\\n\" + \"=\"*60)\n    print(\"âŒ Git LFS æª”æ¡ˆä¸‹è¼‰å¤±æ•—\")\n    print(\"=\"*60)\n    print(\"\\nå¯èƒ½çš„åŸå› :\")\n    print(\"1. GitHub Token æ¬Šé™ä¸è¶³\")\n    print(\"   â†’ ç¢ºèª Token æœ‰ 'repo' å®Œæ•´æ¬Šé™\")\n    print(\"2. Git LFS é »å¯¬ç”¨å®Œ\")\n    print(\"   â†’ æª¢æŸ¥ GitHub Settings â†’ Billing â†’ Git LFS ç”¨é‡\")\n    print(\"3. Token å·²éæœŸ\")\n    print(\"   â†’ é‡æ–°ç”Ÿæˆæ–°çš„ Token\")\n    print(\"\\nè§£æ±ºæ–¹æ³•:\")\n    print(\"1. åˆªé™¤ repository ç›®éŒ„: !rm -rf \" + REPO_NAME)\n    print(\"2. é‡æ–°ç”Ÿæˆ Token (æœ‰æ•ˆæœŸé¸ 90 days)\")\n    print(\"3. é‡æ–°åŸ·è¡Œ Cell 4 å’Œ Cell 5\")\nelse:\n    print(\"\\nâœ… æ‰€æœ‰è¨“ç·´è³‡æ–™å®Œæ•´ï¼å¯ä»¥é–‹å§‹è¨“ç·´\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ é…ç½®è¨“ç·´åƒæ•¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´é…ç½®\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"è¨“ç·´é…ç½®\"\"\"\n",
    "    name: str\n",
    "    base_model: str\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    num_epochs: int\n",
    "    early_stopping_patience: int\n",
    "    focal_loss_alpha: float\n",
    "    focal_loss_gamma: float\n",
    "    warmup_ratio: float = 0.1\n",
    "    weight_decay: float = 0.01\n",
    "    gradient_accumulation_steps: int = 1\n",
    "\n",
    "# å®šç¾©ä¸‰å€‹è¨“ç·´é…ç½®\n",
    "configs = [\n",
    "    TrainingConfig(\n",
    "        name=\"macbert_conservative\",\n",
    "        base_model=\"hfl/chinese-macbert-base\",\n",
    "        learning_rate=1e-5,\n",
    "        batch_size=8,\n",
    "        num_epochs=20,\n",
    "        early_stopping_patience=5,\n",
    "        focal_loss_alpha=2.0,\n",
    "        focal_loss_gamma=2.5,\n",
    "    ),\n",
    "    TrainingConfig(\n",
    "        name=\"macbert_aggressive\",\n",
    "        base_model=\"hfl/chinese-macbert-base\",\n",
    "        learning_rate=3e-5,\n",
    "        batch_size=16,\n",
    "        num_epochs=15,\n",
    "        early_stopping_patience=3,\n",
    "        focal_loss_alpha=2.5,\n",
    "        focal_loss_gamma=3.0,\n",
    "        gradient_accumulation_steps=2,\n",
    "    ),\n",
    "    TrainingConfig(\n",
    "        name=\"roberta_balanced\",\n",
    "        base_model=\"hfl/chinese-roberta-wwm-ext\",\n",
    "        learning_rate=2e-5,\n",
    "        batch_size=12,\n",
    "        num_epochs=18,\n",
    "        early_stopping_patience=4,\n",
    "        focal_loss_alpha=2.2,\n",
    "        focal_loss_gamma=2.8,\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"ğŸ“‹ è¨“ç·´é…ç½®:\")\n",
    "for i, cfg in enumerate(configs, 1):\n",
    "    print(f\"{i}. {cfg.name}\")\n",
    "    print(f\"   - å­¸ç¿’ç‡: {cfg.learning_rate}\")\n",
    "    print(f\"   - Batch size: {cfg.batch_size}\")\n",
    "    print(f\"   - Epochs: {cfg.num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ è¼‰å…¥è¨“ç·´è…³æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç¢ºä¿è…³æœ¬å¯åŸ·è¡Œ\n",
    "!chmod +x scripts/train_bullying_f1_optimizer.py\n",
    "\n",
    "# æª¢æŸ¥è…³æœ¬æ˜¯å¦å­˜åœ¨\n",
    "import os\n",
    "script_path = \"scripts/train_bullying_f1_optimizer.py\"\n",
    "if os.path.exists(script_path):\n",
    "    print(f\"âœ… è¨“ç·´è…³æœ¬å°±ç·’: {script_path}\")\n",
    "else:\n",
    "    print(f\"âŒ è¨“ç·´è…³æœ¬ä¸å­˜åœ¨: {script_path}\")\n",
    "    print(\"è«‹ç¢ºä¿ repository å®Œæ•´ clone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ å•Ÿå‹• TensorBoard ç›£æ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¼‰å…¥ TensorBoard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# å•Ÿå‹• TensorBoard\n",
    "%tensorboard --logdir runs/\n",
    "\n",
    "print(\"âœ… TensorBoard å·²å•Ÿå‹•ï¼Œè«‹æŸ¥çœ‹ä¸Šæ–¹çš„å„€è¡¨æ¿\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ åŸ·è¡Œè¨“ç·´ - Model A (ä¿å®ˆé…ç½®)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´ Model A\n",
    "config_a = configs[0]\n",
    "print(f\"ğŸš€ é–‹å§‹è¨“ç·´: {config_a.name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_bullying_f1_optimizer.py \\\n",
    "  --model_name {config_a.base_model} \\\n",
    "  --output_dir models/experiments/{config_a.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config_a.learning_rate} \\\n",
    "  --batch_size {config_a.batch_size} \\\n",
    "  --num_epochs {config_a.num_epochs} \\\n",
    "  --early_stopping_patience {config_a.early_stopping_patience} \\\n",
    "  --focal_loss_alpha {config_a.focal_loss_alpha} \\\n",
    "  --focal_loss_gamma {config_a.focal_loss_gamma} \\\n",
    "  --fp16 \\\n",
    "  --use_tensorboard\n",
    "\n",
    "print(f\"âœ… {config_a.name} è¨“ç·´å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ åŸ·è¡Œè¨“ç·´ - Model B (æ¿€é€²é…ç½®)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´ Model B\n",
    "config_b = configs[1]\n",
    "print(f\"ğŸš€ é–‹å§‹è¨“ç·´: {config_b.name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_bullying_f1_optimizer.py \\\n",
    "  --model_name {config_b.base_model} \\\n",
    "  --output_dir models/experiments/{config_b.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config_b.learning_rate} \\\n",
    "  --batch_size {config_b.batch_size} \\\n",
    "  --num_epochs {config_b.num_epochs} \\\n",
    "  --early_stopping_patience {config_b.early_stopping_patience} \\\n",
    "  --focal_loss_alpha {config_b.focal_loss_alpha} \\\n",
    "  --focal_loss_gamma {config_b.focal_loss_gamma} \\\n",
    "  --gradient_accumulation_steps {config_b.gradient_accumulation_steps} \\\n",
    "  --fp16 \\\n",
    "  --use_tensorboard \\\n",
    "  --use_data_augmentation\n",
    "\n",
    "print(f\"âœ… {config_b.name} è¨“ç·´å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ åŸ·è¡Œè¨“ç·´ - Model C (RoBERTa è®Šé«”)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¨“ç·´ Model C\n",
    "config_c = configs[2]\n",
    "print(f\"ğŸš€ é–‹å§‹è¨“ç·´: {config_c.name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_bullying_f1_optimizer.py \\\n",
    "  --model_name {config_c.base_model} \\\n",
    "  --output_dir models/experiments/{config_c.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config_c.learning_rate} \\\n",
    "  --batch_size {config_c.batch_size} \\\n",
    "  --num_epochs {config_c.num_epochs} \\\n",
    "  --early_stopping_patience {config_c.early_stopping_patience} \\\n",
    "  --focal_loss_alpha {config_c.focal_loss_alpha} \\\n",
    "  --focal_loss_gamma {config_c.focal_loss_gamma} \\\n",
    "  --fp16 \\\n",
    "  --use_tensorboard\n",
    "\n",
    "print(f\"âœ… {config_c.name} è¨“ç·´å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ è©•ä¼°æ‰€æœ‰æ¨¡å‹ä¸¦é¸å‡ºæœ€ä½³"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è©•ä¼°æ‰€æœ‰è¨“ç·´çš„æ¨¡å‹\n",
    "import json\n",
    "import os\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in configs:\n",
    "    model_dir = f\"models/experiments/{config.name}\"\n",
    "    metrics_file = os.path.join(model_dir, \"best_model\", \"eval_results.json\")\n",
    "    \n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        f1_score = metrics.get('bullying_f1', 0.0)\n",
    "        results.append({\n",
    "            'name': config.name,\n",
    "            'f1': f1_score,\n",
    "            'path': os.path.join(model_dir, \"best_model\"),\n",
    "            'metrics': metrics\n",
    "        })\n",
    "        print(f\"{config.name}: F1 = {f1_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸ {config.name}: è©•ä¼°çµæœæœªæ‰¾åˆ°\")\n",
    "\n",
    "# é¸å‡ºæœ€ä½³æ¨¡å‹\n",
    "if results:\n",
    "    best_model = max(results, key=lambda x: x['f1'])\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"ğŸ† æœ€ä½³æ¨¡å‹: {best_model['name']}\")\n",
    "    print(f\"ğŸ“Š F1 Score: {best_model['f1']:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # ä¿å­˜æœ€ä½³æ¨¡å‹è³‡è¨Š\n",
    "    with open('best_model_info.json', 'w') as f:\n",
    "        json.dump(best_model, f, indent=2, ensure_ascii=False)\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰æ‰¾åˆ°ä»»ä½•è©•ä¼°çµæœ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ è¤‡è£½æœ€ä½³æ¨¡å‹åˆ°éƒ¨ç½²ç›®éŒ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¤‡è£½æœ€ä½³æ¨¡å‹\n",
    "import shutil\n",
    "\n",
    "if 'best_model' in locals() and best_model['f1'] >= 0.70:\n",
    "    deploy_dir = \"models/bullying_improved/best_single_model\"\n",
    "    os.makedirs(deploy_dir, exist_ok=True)\n",
    "    \n",
    "    # è¤‡è£½æ¨¡å‹æª”æ¡ˆ\n",
    "    for file in os.listdir(best_model['path']):\n",
    "        src = os.path.join(best_model['path'], file)\n",
    "        dst = os.path.join(deploy_dir, file)\n",
    "        if os.path.isfile(src):\n",
    "            shutil.copy2(src, dst)\n",
    "    \n",
    "    print(f\"âœ… æœ€ä½³æ¨¡å‹å·²è¤‡è£½åˆ°: {deploy_dir}\")\n",
    "    print(f\"ğŸ“Š F1 Score: {best_model['f1']:.4f}\")\n",
    "    \n",
    "    # ä¿å­˜éƒ¨ç½²è³‡è¨Š\n",
    "    deploy_info = {\n",
    "        'model_name': best_model['name'],\n",
    "        'f1_score': best_model['f1'],\n",
    "        'metrics': best_model['metrics'],\n",
    "        'trained_on': 'Google Colab',\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(deploy_dir, 'deployment_info.json'), 'w') as f:\n",
    "        json.dump(deploy_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"âœ… éƒ¨ç½²è³‡è¨Šå·²ä¿å­˜\")\n",
    "else:\n",
    "    print(\"âš ï¸ æœªé”åˆ°æœ€ä½ F1 é–€æª» (0.70) æˆ–æ²’æœ‰å¯ç”¨æ¨¡å‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£3ï¸âƒ£ æ¨é€æœ€ä½³æ¨¡å‹åˆ° GitHub (å¦‚æœé”æ¨™)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå‹•æ¨é€é”æ¨™æ¨¡å‹\n",
    "TARGET_F1 = 0.75\n",
    "\n",
    "if 'best_model' in locals() and best_model['f1'] >= TARGET_F1:\n",
    "    print(f\"ğŸ‰ æ¨¡å‹é”æ¨™ï¼F1 = {best_model['f1']:.4f} â‰¥ {TARGET_F1}\")\n",
    "    print(\"é–‹å§‹æ¨é€æ¨¡å‹åˆ° GitHub...\")\n",
    "    \n",
    "    # é…ç½® Git LFS\n",
    "    !git lfs install\n",
    "    !git lfs track \"models/bullying_improved/**/*.safetensors\"\n",
    "    !git lfs track \"models/bullying_improved/**/*.bin\"\n",
    "    \n",
    "    # æ·»åŠ  .gitattributes\n",
    "    !git add .gitattributes\n",
    "    \n",
    "    # æ·»åŠ æœ€ä½³æ¨¡å‹\n",
    "    !git add models/bullying_improved/best_single_model/\n",
    "    \n",
    "    # æäº¤\n",
    "    commit_msg = f\"feat: Add bullying detection model (F1={best_model['f1']:.4f}) trained on Colab\"\n",
    "    !git commit -m \"{commit_msg}\"\n",
    "    \n",
    "    # æ¨é€\n",
    "    !git push origin main\n",
    "    \n",
    "    print(\"âœ… æ¨¡å‹å·²æˆåŠŸæ¨é€åˆ° GitHubï¼\")\n",
    "    print(f\"ğŸ“Š Git LFS ç”¨é‡: ~390 MB\")\n",
    "    \n",
    "elif 'best_model' in locals():\n",
    "    print(f\"âš ï¸ æ¨¡å‹æœªé”æ¨™: F1 = {best_model['f1']:.4f} < {TARGET_F1}\")\n",
    "    print(\"å»ºè­°:\")\n",
    "    print(\"1. æª¢æŸ¥ TensorBoard åˆ†æè¨“ç·´æ›²ç·š\")\n",
    "    print(\"2. å˜—è©¦èª¿æ•´è¶…åƒæ•¸\")\n",
    "    print(\"3. è€ƒæ…®ä½¿ç”¨æ¨¡å‹é›†æˆ\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰å¯ç”¨çš„æ¨¡å‹é€²è¡Œæ¨é€\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£4ï¸âƒ£ (å¯é¸) æ¨¡å‹é›†æˆ - å¦‚æœå–®æ¨¡å‹æœªé”æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¦‚æœå–®æ¨¡å‹æœªé”æ¨™ï¼Œå˜—è©¦é›†æˆ\n",
    "if 'best_model' in locals() and best_model['f1'] < TARGET_F1 and len(results) >= 2:\n",
    "    print(\"ğŸ”§ å–®æ¨¡å‹æœªé”æ¨™ï¼Œå»ºç«‹æ¨¡å‹é›†æˆ...\")\n",
    "    \n",
    "    # é¸å‡º Top-3 æ¨¡å‹\n",
    "    top_models = sorted(results, key=lambda x: x['f1'], reverse=True)[:3]\n",
    "    \n",
    "    print(\"\\né›†æˆæ¨¡å‹:\")\n",
    "    for i, model in enumerate(top_models, 1):\n",
    "        print(f\"{i}. {model['name']}: F1 = {model['f1']:.4f}\")\n",
    "    \n",
    "    # åŸ·è¡Œé›†æˆè©•ä¼°\n",
    "    !python scripts/ensemble_models.py \\\n",
    "      --models {\" \".join([m['path'] for m in top_models])} \\\n",
    "      --test_file data/processed/training_dataset/test.json \\\n",
    "      --output_dir models/bullying_improved/ensemble_models \\\n",
    "      --method soft_voting\n",
    "    \n",
    "    print(\"âœ… é›†æˆè©•ä¼°å®Œæˆï¼Œè«‹æŸ¥çœ‹çµæœ\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ è·³éé›†æˆï¼šå–®æ¨¡å‹å·²é”æ¨™æˆ–å¯ç”¨æ¨¡å‹ä¸è¶³\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£5ï¸âƒ£ ç”¢ç”Ÿå®Œæ•´è©•ä¼°å ±å‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”¢ç”Ÿè©³ç´°è©•ä¼°å ±å‘Š\n",
    "if 'best_model' in locals():\n",
    "    !python scripts/evaluate_comprehensive.py \\\n",
    "      --model {best_model['path']} \\\n",
    "      --dataset data/processed/training_dataset/test.json \\\n",
    "      --output evaluation_results/ \\\n",
    "      --include_explainability \\\n",
    "      --include_error_analysis\n",
    "    \n",
    "    print(\"âœ… å®Œæ•´è©•ä¼°å ±å‘Šå·²ç”Ÿæˆæ–¼ evaluation_results/\")\n",
    "    print(\"åŒ…å«:\")\n",
    "    print(\"- æ··æ·†çŸ©é™£\")\n",
    "    print(\"- éŒ¯èª¤æ¡ˆä¾‹åˆ†æ\")\n",
    "    print(\"- SHAP å¯è§£é‡‹æ€§åˆ†æ\")\n",
    "    print(\"- è©³ç´°æŒ‡æ¨™å ±å‘Š\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£6ï¸âƒ£ ä¸‹è¼‰æ¨¡å‹åˆ°æœ¬åœ°ï¼ˆå¯é¸ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å£“ç¸®ä¸¦ä¸‹è¼‰æ¨¡å‹\n",
    "if 'best_model' in locals() and best_model['f1'] >= 0.70:\n",
    "    import shutil\n",
    "    from google.colab import files\n",
    "    \n",
    "    # å£“ç¸®æ¨¡å‹\n",
    "    archive_name = f\"bullying_model_f1_{best_model['f1']:.4f}\"\n",
    "    shutil.make_archive(archive_name, 'zip', 'models/bullying_improved/best_single_model')\n",
    "    \n",
    "    print(f\"âœ… æ¨¡å‹å·²å£“ç¸®: {archive_name}.zip\")\n",
    "    print(f\"å¤§å°: ~390 MB\")\n",
    "    print(\"\\næ˜¯å¦è¦ä¸‹è¼‰åˆ°æœ¬åœ°? (åŸ·è¡Œä¸‹æ–¹çš„ cell)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸ·è¡Œæ­¤ cell ä»¥ä¸‹è¼‰æ¨¡å‹\n",
    "# æ³¨æ„: æª”æ¡ˆè¼ƒå¤§ (~390 MB)ï¼Œä¸‹è¼‰å¯èƒ½éœ€è¦å¹¾åˆ†é˜\n",
    "from google.colab import files\n",
    "\n",
    "if 'archive_name' in locals():\n",
    "    files.download(f\"{archive_name}.zip\")\n",
    "    print(\"âœ… ä¸‹è¼‰é–‹å§‹...\")\n",
    "else:\n",
    "    print(\"âŒ æ²’æœ‰å¯ä¸‹è¼‰çš„æ¨¡å‹\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š è¨“ç·´ç¸½çµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é¡¯ç¤ºè¨“ç·´ç¸½çµ\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ¯ CyberPuppy éœ¸å‡Œåµæ¸¬æ¨¡å‹è¨“ç·´ç¸½çµ\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'results' in locals() and results:\n",
    "    print(\"\\nè¨“ç·´çš„æ¨¡å‹:\")\n",
    "    for model in sorted(results, key=lambda x: x['f1'], reverse=True):\n",
    "        status = \"âœ… é”æ¨™\" if model['f1'] >= TARGET_F1 else \"âš ï¸ æœªé”æ¨™\"\n",
    "        print(f\"  {status} {model['name']}: F1 = {model['f1']:.4f}\")\n",
    "    \n",
    "    if 'best_model' in locals():\n",
    "        print(f\"\\nğŸ† æœ€ä½³æ¨¡å‹: {best_model['name']}\")\n",
    "        print(f\"ğŸ“Š F1 Score: {best_model['f1']:.4f}\")\n",
    "        print(f\"ğŸ¯ ç›®æ¨™: {TARGET_F1}\")\n",
    "        \n",
    "        if best_model['f1'] >= TARGET_F1:\n",
    "            print(\"\\nâœ… è¨“ç·´æˆåŠŸï¼æ¨¡å‹å·²é”æ¨™ä¸¦æ¨é€åˆ° GitHub\")\n",
    "            print(f\"ğŸ“¦ Git LFS ç”¨é‡: ~390 MB\")\n",
    "        else:\n",
    "            gap = TARGET_F1 - best_model['f1']\n",
    "            print(f\"\\nâš ï¸ è·é›¢ç›®æ¨™é‚„å·® {gap:.4f}\")\n",
    "            print(\"å»ºè­°ä¸‹ä¸€æ­¥:\")\n",
    "            print(\"  1. åˆ†æéŒ¯èª¤æ¡ˆä¾‹ (evaluation_results/)\")\n",
    "            print(\"  2. èª¿æ•´è¶…åƒæ•¸é‡æ–°è¨“ç·´\")\n",
    "            print(\"  3. å˜—è©¦æ¨¡å‹é›†æˆ\")\n",
    "else:\n",
    "    print(\"\\nâŒ æ²’æœ‰å®Œæˆçš„è¨“ç·´\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"æ„Ÿè¬ä½¿ç”¨ CyberPuppy è¨“ç·´ç³»çµ±ï¼\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}