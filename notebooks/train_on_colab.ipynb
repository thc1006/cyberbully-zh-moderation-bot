{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 CyberPuppy 霸凌偵測訓練 - Google Colab\n",
    "\n",
    "**目標**: 達成 F1 ≥ 0.75 的霸凌偵測模型  \n",
    "**策略**: 多模型訓練 + 智能選擇 + 自動推送  \n",
    "**GPU**: T4 (免費) / V100 / A100 (Pro)  \n",
    "\n",
    "---\n",
    "\n",
    "## 📋 使用說明\n",
    "\n",
    "1. **檢查 GPU**: Runtime → Change runtime type → GPU\n",
    "2. **執行所有 cell**: Runtime → Run all\n",
    "3. **監控訓練**: TensorBoard 會自動顯示\n",
    "4. **自動推送**: 達標模型會自動推送回 GitHub\n",
    "\n",
    "**預計時間**:\n",
    "- T4: 6-9 小時 (免費)\n",
    "- V100: 3-5 小時 (Pro)\n",
    "- A100: 2-3 小時 (Pro+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣ 環境設置與 GPU 檢查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查 GPU 可用性\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"⚠️ 警告: 未偵測到 GPU！請檢查 Runtime 設置\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Clone Repository (優化版 - 跳過大模型)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設置 GitHub 認證 (需要個人訪問令牌)\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# 輸入你的 GitHub 資訊\n",
    "GITHUB_USERNAME = input(\"GitHub 用戶名: \")\n",
    "GITHUB_TOKEN = getpass(\"GitHub Personal Access Token (需要 repo 權限): \")\n",
    "REPO_NAME = \"cyberbully-zh-moderation-bot\"\n",
    "\n",
    "# 設置 Git 配置\n",
    "!git config --global user.email \"colab@example.com\"\n",
    "!git config --global user.name \"Colab Training Bot\"\n",
    "\n",
    "print(\"✅ Git 配置完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Clone repository (跳過 LFS 大檔案)\nimport os\n\nif os.path.exists(REPO_NAME):\n    print(\"📂 Repository 已存在，跳過 clone\")\nelse:\n    print(\"📥 開始 clone repository...\")\n    \n    # 使用 token 進行認證\n    repo_url = f\"https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n    \n    # Clone repository (先跳過 LFS)\n    !GIT_LFS_SKIP_SMUDGE=1 git clone --depth 1 {repo_url}\n    %cd {REPO_NAME}\n\n    # 安裝 Git LFS\n    !git lfs install\n\n    # 設置 Git LFS 認證 (避免 Bad credentials 錯誤)\n    !git config lfs.url https://{GITHUB_USERNAME}:{GITHUB_TOKEN}@github.com/{GITHUB_USERNAME}/{REPO_NAME}.git/info/lfs\n\n    print(\"📥 下載訓練資料 (這可能需要幾分鐘)...\")\n    \n    # 下載訓練資料\n    !git lfs pull --include=\"data/processed/training_dataset/train.json\"\n    !git lfs pull --include=\"data/processed/training_dataset/dev.json\"\n    !git lfs pull --include=\"data/processed/training_dataset/test.json\"\n    !git lfs pull --include=\"data/processed/cold_augmented.csv\"\n\n    # 驗證檔案完整性\n    train_file = \"data/processed/training_dataset/train.json\"\n    if os.path.exists(train_file):\n        file_size = os.path.getsize(train_file)\n        if file_size > 1000000:  # 應該至少 1 MB\n            print(f\"✅ 訓練資料已下載: {file_size / 1024 / 1024:.1f} MB\")\n        else:\n            print(f\"⚠️ 訓練資料可能不完整: {file_size} bytes\")\n            print(\"如果下載失敗，請檢查:\")\n            print(\"1. GitHub Token 是否有效\")\n            print(\"2. Token 是否有 repo 完整權限\")\n            print(\"3. Git LFS 頻寬是否足夠\")\n    else:\n        print(\"❌ 訓練資料下載失敗\")\n\n    print(\"✅ Repository 設置完成\")\n\n# 切換到專案目錄\n%cd /content/{REPO_NAME}"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ 安裝依賴套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 安裝必要套件（CUDA 12.6 + PyTorch 2.8 三件套、NumPy 2.x、TensorBoard 對齊）\nprint(\"📦 安裝依賴套件...\")\n\n# ── GPU (CUDA 12.6) 版本 ─────────────────────────────\n!pip install -q --index-url https://download.pytorch.org/whl/cu126 \\\n  torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n\n# 若沒有 GPU，要 CPU 版請改用：\n# !pip install -q --index-url https://download.pytorch.org/whl/cpu \\\n#   torch==2.8.0 torchvision==0.23.0 torchaudio==2.8.0\n\n# 科學計算基礎：NumPy 2.x（OpenCV 4.12.* 需要 >=2 且 <2.3）\n!pip install -q \"numpy>=2,<2.3\"\n\n# 其餘套件（與上面版本相容）\n!pip install -q transformers==4.46.3 accelerate==1.2.1 datasets==3.2.0\n!pip install -q scikit-learn==1.6.1 tqdm==4.67.1\n\n# Colab 常見相依：避免 google-colab 1.0.0 的 pandas 釘版警告\n!pip install -q pandas==2.2.2\n\n# TensorBoard 對齊 TensorFlow 2.19\n!pip install -q \"tensorboard~=2.19.0\"\n\n# WandB（可選：更好的實驗追蹤）\n!pip install -q wandb==0.19.1\n\n# 驗證是否還有殘留不相容\n!python -m pip check\n\nprint(\"✅ 套件安裝完成\")\n\n# 驗證版本\nimport torch\nimport numpy as np\nprint(f\"✅ PyTorch: {torch.__version__}\")\nprint(f\"✅ NumPy: {np.__version__}\")\nprint(f\"✅ CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"✅ CUDA version: {torch.version.cuda}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ 驗證資料集完整性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 檢查訓練資料\nimport json\nimport os\n\ndata_dir = \"data/processed/training_dataset\"\nall_ok = True\n\nfor split in [\"train\", \"dev\", \"test\"]:\n    filepath = os.path.join(data_dir, f\"{split}.json\")\n    if os.path.exists(filepath):\n        file_size = os.path.getsize(filepath)\n        if file_size > 100000:  # 至少要大於 100KB\n            try:\n                with open(filepath, 'r', encoding='utf-8') as f:\n                    data = json.load(f)\n                print(f\"✅ {split}.json: {len(data)} 樣本 ({file_size / 1024 / 1024:.1f} MB)\")\n            except json.JSONDecodeError as e:\n                print(f\"❌ {split}.json JSON 格式錯誤: {e}\")\n                print(f\"   檔案大小: {file_size} bytes\")\n                print(f\"   這可能是 Git LFS 指標檔案，不是實際資料\")\n                all_ok = False\n        else:\n            print(f\"⚠️ {split}.json 檔案太小 ({file_size} bytes)\")\n            print(f\"   這是 Git LFS 指標檔案，實際資料未下載\")\n            all_ok = False\n    else:\n        print(f\"❌ 缺少 {split}.json\")\n        all_ok = False\n\n# 檢查增強資料\naugmented_path = \"data/processed/cold_augmented.csv\"\nif os.path.exists(augmented_path):\n    file_size = os.path.getsize(augmented_path)\n    if file_size > 1000000:  # 至少 1MB\n        print(f\"✅ 增強資料: {file_size / 1024 / 1024:.1f} MB\")\n    else:\n        print(f\"⚠️ 增強資料檔案太小: {file_size} bytes\")\nelse:\n    print(\"⚠️ 未找到增強資料\")\n\nif not all_ok:\n    print(\"\\n\" + \"=\"*60)\n    print(\"❌ Git LFS 檔案下載失敗\")\n    print(\"=\"*60)\n    print(\"\\n可能的原因:\")\n    print(\"1. GitHub Token 權限不足\")\n    print(\"   → 確認 Token 有 'repo' 完整權限\")\n    print(\"2. Git LFS 頻寬用完\")\n    print(\"   → 檢查 GitHub Settings → Billing → Git LFS 用量\")\n    print(\"3. Token 已過期\")\n    print(\"   → 重新生成新的 Token\")\n    print(\"\\n解決方法:\")\n    print(\"1. 刪除 repository 目錄: !rm -rf \" + REPO_NAME)\n    print(\"2. 重新生成 Token (有效期選 90 days)\")\n    print(\"3. 重新執行 Cell 4 和 Cell 5\")\nelse:\n    print(\"\\n✅ 所有訓練資料完整！可以開始訓練\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ 配置訓練參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練配置\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"訓練配置\"\"\"\n",
    "    name: str\n",
    "    base_model: str\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    num_epochs: int\n",
    "    early_stopping_patience: int\n",
    "    focal_loss_alpha: float\n",
    "    focal_loss_gamma: float\n",
    "    warmup_ratio: float = 0.1\n",
    "    weight_decay: float = 0.01\n",
    "    gradient_accumulation_steps: int = 1\n",
    "\n",
    "# 定義三個訓練配置\n",
    "configs = [\n",
    "    TrainingConfig(\n",
    "        name=\"macbert_conservative\",\n",
    "        base_model=\"hfl/chinese-macbert-base\",\n",
    "        learning_rate=1e-5,\n",
    "        batch_size=8,\n",
    "        num_epochs=20,\n",
    "        early_stopping_patience=5,\n",
    "        focal_loss_alpha=2.0,\n",
    "        focal_loss_gamma=2.5,\n",
    "    ),\n",
    "    TrainingConfig(\n",
    "        name=\"macbert_aggressive\",\n",
    "        base_model=\"hfl/chinese-macbert-base\",\n",
    "        learning_rate=3e-5,\n",
    "        batch_size=16,\n",
    "        num_epochs=15,\n",
    "        early_stopping_patience=3,\n",
    "        focal_loss_alpha=2.5,\n",
    "        focal_loss_gamma=3.0,\n",
    "        gradient_accumulation_steps=2,\n",
    "    ),\n",
    "    TrainingConfig(\n",
    "        name=\"roberta_balanced\",\n",
    "        base_model=\"hfl/chinese-roberta-wwm-ext\",\n",
    "        learning_rate=2e-5,\n",
    "        batch_size=12,\n",
    "        num_epochs=18,\n",
    "        early_stopping_patience=4,\n",
    "        focal_loss_alpha=2.2,\n",
    "        focal_loss_gamma=2.8,\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(\"📋 訓練配置:\")\n",
    "for i, cfg in enumerate(configs, 1):\n",
    "    print(f\"{i}. {cfg.name}\")\n",
    "    print(f\"   - 學習率: {cfg.learning_rate}\")\n",
    "    print(f\"   - Batch size: {cfg.batch_size}\")\n",
    "    print(f\"   - Epochs: {cfg.num_epochs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ 載入訓練腳本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確保腳本可執行\n",
    "!chmod +x scripts/train_bullying_f1_optimizer.py\n",
    "\n",
    "# 檢查腳本是否存在\n",
    "import os\n",
    "script_path = \"scripts/train_bullying_f1_optimizer.py\"\n",
    "if os.path.exists(script_path):\n",
    "    print(f\"✅ 訓練腳本就緒: {script_path}\")\n",
    "else:\n",
    "    print(f\"❌ 訓練腳本不存在: {script_path}\")\n",
    "    print(\"請確保 repository 完整 clone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ 啟動 TensorBoard 監控"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 TensorBoard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# 啟動 TensorBoard\n",
    "%tensorboard --logdir runs/\n",
    "\n",
    "print(\"✅ TensorBoard 已啟動，請查看上方的儀表板\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8️⃣ 執行訓練 - Model A (保守配置)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練 Model A\n",
    "config_a = configs[0]\n",
    "print(f\"🚀 開始訓練: {config_a.name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_bullying_f1_optimizer.py \\\n",
    "  --model_name {config_a.base_model} \\\n",
    "  --output_dir models/experiments/{config_a.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config_a.learning_rate} \\\n",
    "  --batch_size {config_a.batch_size} \\\n",
    "  --num_epochs {config_a.num_epochs} \\\n",
    "  --early_stopping_patience {config_a.early_stopping_patience} \\\n",
    "  --focal_loss_alpha {config_a.focal_loss_alpha} \\\n",
    "  --focal_loss_gamma {config_a.focal_loss_gamma} \\\n",
    "  --fp16 \\\n",
    "  --use_tensorboard\n",
    "\n",
    "print(f\"✅ {config_a.name} 訓練完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9️⃣ 執行訓練 - Model B (激進配置)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練 Model B\n",
    "config_b = configs[1]\n",
    "print(f\"🚀 開始訓練: {config_b.name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_bullying_f1_optimizer.py \\\n",
    "  --model_name {config_b.base_model} \\\n",
    "  --output_dir models/experiments/{config_b.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config_b.learning_rate} \\\n",
    "  --batch_size {config_b.batch_size} \\\n",
    "  --num_epochs {config_b.num_epochs} \\\n",
    "  --early_stopping_patience {config_b.early_stopping_patience} \\\n",
    "  --focal_loss_alpha {config_b.focal_loss_alpha} \\\n",
    "  --focal_loss_gamma {config_b.focal_loss_gamma} \\\n",
    "  --gradient_accumulation_steps {config_b.gradient_accumulation_steps} \\\n",
    "  --fp16 \\\n",
    "  --use_tensorboard \\\n",
    "  --use_data_augmentation\n",
    "\n",
    "print(f\"✅ {config_b.name} 訓練完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔟 執行訓練 - Model C (RoBERTa 變體)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練 Model C\n",
    "config_c = configs[2]\n",
    "print(f\"🚀 開始訓練: {config_c.name}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "!python scripts/train_bullying_f1_optimizer.py \\\n",
    "  --model_name {config_c.base_model} \\\n",
    "  --output_dir models/experiments/{config_c.name} \\\n",
    "  --train_file data/processed/training_dataset/train.json \\\n",
    "  --dev_file data/processed/training_dataset/dev.json \\\n",
    "  --test_file data/processed/training_dataset/test.json \\\n",
    "  --learning_rate {config_c.learning_rate} \\\n",
    "  --batch_size {config_c.batch_size} \\\n",
    "  --num_epochs {config_c.num_epochs} \\\n",
    "  --early_stopping_patience {config_c.early_stopping_patience} \\\n",
    "  --focal_loss_alpha {config_c.focal_loss_alpha} \\\n",
    "  --focal_loss_gamma {config_c.focal_loss_gamma} \\\n",
    "  --fp16 \\\n",
    "  --use_tensorboard\n",
    "\n",
    "print(f\"✅ {config_c.name} 訓練完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣1️⃣ 評估所有模型並選出最佳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估所有訓練的模型\n",
    "import json\n",
    "import os\n",
    "\n",
    "results = []\n",
    "\n",
    "for config in configs:\n",
    "    model_dir = f\"models/experiments/{config.name}\"\n",
    "    metrics_file = os.path.join(model_dir, \"best_model\", \"eval_results.json\")\n",
    "    \n",
    "    if os.path.exists(metrics_file):\n",
    "        with open(metrics_file, 'r') as f:\n",
    "            metrics = json.load(f)\n",
    "        \n",
    "        f1_score = metrics.get('bullying_f1', 0.0)\n",
    "        results.append({\n",
    "            'name': config.name,\n",
    "            'f1': f1_score,\n",
    "            'path': os.path.join(model_dir, \"best_model\"),\n",
    "            'metrics': metrics\n",
    "        })\n",
    "        print(f\"{config.name}: F1 = {f1_score:.4f}\")\n",
    "    else:\n",
    "        print(f\"⚠️ {config.name}: 評估結果未找到\")\n",
    "\n",
    "# 選出最佳模型\n",
    "if results:\n",
    "    best_model = max(results, key=lambda x: x['f1'])\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"🏆 最佳模型: {best_model['name']}\")\n",
    "    print(f\"📊 F1 Score: {best_model['f1']:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 保存最佳模型資訊\n",
    "    with open('best_model_info.json', 'w') as f:\n",
    "        json.dump(best_model, f, indent=2, ensure_ascii=False)\n",
    "else:\n",
    "    print(\"❌ 沒有找到任何評估結果\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣2️⃣ 複製最佳模型到部署目錄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 複製最佳模型\n",
    "import shutil\n",
    "\n",
    "if 'best_model' in locals() and best_model['f1'] >= 0.70:\n",
    "    deploy_dir = \"models/bullying_improved/best_single_model\"\n",
    "    os.makedirs(deploy_dir, exist_ok=True)\n",
    "    \n",
    "    # 複製模型檔案\n",
    "    for file in os.listdir(best_model['path']):\n",
    "        src = os.path.join(best_model['path'], file)\n",
    "        dst = os.path.join(deploy_dir, file)\n",
    "        if os.path.isfile(src):\n",
    "            shutil.copy2(src, dst)\n",
    "    \n",
    "    print(f\"✅ 最佳模型已複製到: {deploy_dir}\")\n",
    "    print(f\"📊 F1 Score: {best_model['f1']:.4f}\")\n",
    "    \n",
    "    # 保存部署資訊\n",
    "    deploy_info = {\n",
    "        'model_name': best_model['name'],\n",
    "        'f1_score': best_model['f1'],\n",
    "        'metrics': best_model['metrics'],\n",
    "        'trained_on': 'Google Colab',\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(deploy_dir, 'deployment_info.json'), 'w') as f:\n",
    "        json.dump(deploy_info, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(\"✅ 部署資訊已保存\")\n",
    "else:\n",
    "    print(\"⚠️ 未達到最低 F1 門檻 (0.70) 或沒有可用模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣3️⃣ 推送最佳模型到 GitHub (如果達標)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自動推送達標模型\n",
    "TARGET_F1 = 0.75\n",
    "\n",
    "if 'best_model' in locals() and best_model['f1'] >= TARGET_F1:\n",
    "    print(f\"🎉 模型達標！F1 = {best_model['f1']:.4f} ≥ {TARGET_F1}\")\n",
    "    print(\"開始推送模型到 GitHub...\")\n",
    "    \n",
    "    # 配置 Git LFS\n",
    "    !git lfs install\n",
    "    !git lfs track \"models/bullying_improved/**/*.safetensors\"\n",
    "    !git lfs track \"models/bullying_improved/**/*.bin\"\n",
    "    \n",
    "    # 添加 .gitattributes\n",
    "    !git add .gitattributes\n",
    "    \n",
    "    # 添加最佳模型\n",
    "    !git add models/bullying_improved/best_single_model/\n",
    "    \n",
    "    # 提交\n",
    "    commit_msg = f\"feat: Add bullying detection model (F1={best_model['f1']:.4f}) trained on Colab\"\n",
    "    !git commit -m \"{commit_msg}\"\n",
    "    \n",
    "    # 推送\n",
    "    !git push origin main\n",
    "    \n",
    "    print(\"✅ 模型已成功推送到 GitHub！\")\n",
    "    print(f\"📊 Git LFS 用量: ~390 MB\")\n",
    "    \n",
    "elif 'best_model' in locals():\n",
    "    print(f\"⚠️ 模型未達標: F1 = {best_model['f1']:.4f} < {TARGET_F1}\")\n",
    "    print(\"建議:\")\n",
    "    print(\"1. 檢查 TensorBoard 分析訓練曲線\")\n",
    "    print(\"2. 嘗試調整超參數\")\n",
    "    print(\"3. 考慮使用模型集成\")\n",
    "else:\n",
    "    print(\"❌ 沒有可用的模型進行推送\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣4️⃣ (可選) 模型集成 - 如果單模型未達標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果單模型未達標，嘗試集成\n",
    "if 'best_model' in locals() and best_model['f1'] < TARGET_F1 and len(results) >= 2:\n",
    "    print(\"🔧 單模型未達標，建立模型集成...\")\n",
    "    \n",
    "    # 選出 Top-3 模型\n",
    "    top_models = sorted(results, key=lambda x: x['f1'], reverse=True)[:3]\n",
    "    \n",
    "    print(\"\\n集成模型:\")\n",
    "    for i, model in enumerate(top_models, 1):\n",
    "        print(f\"{i}. {model['name']}: F1 = {model['f1']:.4f}\")\n",
    "    \n",
    "    # 執行集成評估\n",
    "    !python scripts/ensemble_models.py \\\n",
    "      --models {\" \".join([m['path'] for m in top_models])} \\\n",
    "      --test_file data/processed/training_dataset/test.json \\\n",
    "      --output_dir models/bullying_improved/ensemble_models \\\n",
    "      --method soft_voting\n",
    "    \n",
    "    print(\"✅ 集成評估完成，請查看結果\")\n",
    "else:\n",
    "    print(\"ℹ️ 跳過集成：單模型已達標或可用模型不足\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣5️⃣ 產生完整評估報告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 產生詳細評估報告\n",
    "if 'best_model' in locals():\n",
    "    !python scripts/evaluate_comprehensive.py \\\n",
    "      --model {best_model['path']} \\\n",
    "      --dataset data/processed/training_dataset/test.json \\\n",
    "      --output evaluation_results/ \\\n",
    "      --include_explainability \\\n",
    "      --include_error_analysis\n",
    "    \n",
    "    print(\"✅ 完整評估報告已生成於 evaluation_results/\")\n",
    "    print(\"包含:\")\n",
    "    print(\"- 混淆矩陣\")\n",
    "    print(\"- 錯誤案例分析\")\n",
    "    print(\"- SHAP 可解釋性分析\")\n",
    "    print(\"- 詳細指標報告\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1️⃣6️⃣ 下載模型到本地（可選）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 壓縮並下載模型\n",
    "if 'best_model' in locals() and best_model['f1'] >= 0.70:\n",
    "    import shutil\n",
    "    from google.colab import files\n",
    "    \n",
    "    # 壓縮模型\n",
    "    archive_name = f\"bullying_model_f1_{best_model['f1']:.4f}\"\n",
    "    shutil.make_archive(archive_name, 'zip', 'models/bullying_improved/best_single_model')\n",
    "    \n",
    "    print(f\"✅ 模型已壓縮: {archive_name}.zip\")\n",
    "    print(f\"大小: ~390 MB\")\n",
    "    print(\"\\n是否要下載到本地? (執行下方的 cell)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 執行此 cell 以下載模型\n",
    "# 注意: 檔案較大 (~390 MB)，下載可能需要幾分鐘\n",
    "from google.colab import files\n",
    "\n",
    "if 'archive_name' in locals():\n",
    "    files.download(f\"{archive_name}.zip\")\n",
    "    print(\"✅ 下載開始...\")\n",
    "else:\n",
    "    print(\"❌ 沒有可下載的模型\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 訓練總結"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顯示訓練總結\n",
    "print(\"=\"*80)\n",
    "print(\"🎯 CyberPuppy 霸凌偵測模型訓練總結\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'results' in locals() and results:\n",
    "    print(\"\\n訓練的模型:\")\n",
    "    for model in sorted(results, key=lambda x: x['f1'], reverse=True):\n",
    "        status = \"✅ 達標\" if model['f1'] >= TARGET_F1 else \"⚠️ 未達標\"\n",
    "        print(f\"  {status} {model['name']}: F1 = {model['f1']:.4f}\")\n",
    "    \n",
    "    if 'best_model' in locals():\n",
    "        print(f\"\\n🏆 最佳模型: {best_model['name']}\")\n",
    "        print(f\"📊 F1 Score: {best_model['f1']:.4f}\")\n",
    "        print(f\"🎯 目標: {TARGET_F1}\")\n",
    "        \n",
    "        if best_model['f1'] >= TARGET_F1:\n",
    "            print(\"\\n✅ 訓練成功！模型已達標並推送到 GitHub\")\n",
    "            print(f\"📦 Git LFS 用量: ~390 MB\")\n",
    "        else:\n",
    "            gap = TARGET_F1 - best_model['f1']\n",
    "            print(f\"\\n⚠️ 距離目標還差 {gap:.4f}\")\n",
    "            print(\"建議下一步:\")\n",
    "            print(\"  1. 分析錯誤案例 (evaluation_results/)\")\n",
    "            print(\"  2. 調整超參數重新訓練\")\n",
    "            print(\"  3. 嘗試模型集成\")\n",
    "else:\n",
    "    print(\"\\n❌ 沒有完成的訓練\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"感謝使用 CyberPuppy 訓練系統！\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}