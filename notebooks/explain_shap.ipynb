{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP 可解釋性分析示範\n",
    "\n",
    "本筆記本展示如何使用SHAP對中文網路霸凌偵測模型進行可解釋性分析\n",
    "\n",
    "## 功能展示\n",
    "- Force plots (局部解釋)\n",
    "- Waterfall plots (層次化解釋)\n",
    "- Text plots (文本級解釋)\n",
    "- Summary plots (全局解釋)\n",
    "- 與IG結果對比\n",
    "- 誤判分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要的庫\n",
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# 添加專案路徑\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 設定中文字體\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"環境設定完成\")\n",
    "print(f\"專案根目錄: {project_root}\")\n",
    "print(f\"Python版本: {sys.version}\")\n",
    "print(f\"PyTorch版本: {torch.__version__}\")\n",
    "print(f\"GPU可用: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入專案模組\n",
    "from cyberpuppy.models.improved_detector import ImprovedDetector, create_improved_config\n",
    "from cyberpuppy.explain.shap_explainer import (\n",
    "    SHAPExplainer, SHAPVisualizer, MisclassificationAnalyzer,\n",
    "    compare_ig_shap_explanations\n",
    ")\n",
    "from cyberpuppy.explain.ig import IntegratedGradientsExplainer\n",
    "\n",
    "print(\"模組導入成功\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 載入訓練好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入模型配置\n",
    "config = create_improved_config()\n",
    "print(f\"模型配置: {config.model_name}\")\n",
    "\n",
    "# 初始化模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImprovedDetector(config)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"模型已載入到設備: {device}\")\n",
    "print(f\"模型參數量: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "# 注意：實際使用時需要載入訓練好的權重\n",
    "# model.load_state_dict(torch.load('path/to/trained_model.pth'))\n",
    "print(\"\\n⚠️ 注意：這是未訓練的模型，實際使用時需要載入訓練好的權重\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 初始化SHAP解釋器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化SHAP解釋器\n",
    "shap_explainer = SHAPExplainer(model, device)\n",
    "shap_visualizer = SHAPVisualizer(shap_explainer)\n",
    "\n",
    "print(\"SHAP解釋器初始化完成\")\n",
    "\n",
    "# 同時初始化IG解釋器用於對比\n",
    "try:\n",
    "    ig_explainer = IntegratedGradientsExplainer(model, device)\n",
    "    print(\"IG解釋器初始化完成\")\n",
    "    ig_available = True\n",
    "except Exception as e:\n",
    "    print(f\"IG解釋器初始化失敗: {e}\")\n",
    "    ig_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 準備測試文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試文本集合\n",
    "test_texts = [\n",
    "    \"你這個垃圾，快去死吧！\",  # 明顯毒性/威脅\n",
    "    \"今天天氣真好，心情很愉快\",  # 正面情緒\n",
    "    \"這個政策實在是太爛了\",  # 輕微負面\n",
    "    \"你再這樣我就要告訴老師了\",  # 輕微威脅\n",
    "    \"謝謝你幫助我完成作業\",  # 正面感謝\n",
    "    \"你們這些笨蛋什麼都不懂\",  # 輕微霸凌\n",
    "    \"我覺得這個想法不太好\",  # 中性意見\n",
    "    \"去你的，別煩我！\",  # 粗俗語言\n",
    "    \"大家一起努力完成這個專案\",  # 正面合作\n",
    "    \"你這個白癡真是無可救藥\"  # 人身攻擊\n",
    "]\n",
    "\n",
    "print(f\"準備了 {len(test_texts)} 個測試文本\")\n",
    "for i, text in enumerate(test_texts, 1):\n",
    "    print(f\"{i:2d}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. SHAP解釋示範"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選擇一個文本進行詳細分析\n",
    "sample_text = test_texts[0]  # \"你這個垃圾，快去死吧！\"\n",
    "print(f\"分析文本: {sample_text}\")\n",
    "\n",
    "# 獲取SHAP解釋\n",
    "print(\"\\n計算SHAP值...\")\n",
    "shap_result = shap_explainer.explain_text(sample_text, max_evals=500)\n",
    "\n",
    "# 顯示預測結果\n",
    "print(\"\\n=== 預測結果 ===\")\n",
    "print(f\"毒性預測: {shap_result.toxicity_pred} (置信度: {shap_result.toxicity_prob:.3f})\")\n",
    "print(f\"霸凌預測: {shap_result.bullying_pred} (置信度: {shap_result.bullying_prob:.3f})\")\n",
    "print(f\"角色預測: {shap_result.role_pred} (置信度: {shap_result.role_prob:.3f})\")\n",
    "print(f\"情緒預測: {shap_result.emotion_pred} (置信度: {shap_result.emotion_prob:.3f})\")\n",
    "\n",
    "# 顯示特徵重要性\n",
    "print(\"\\n=== 特徵重要性 ===\")\n",
    "for task, importance in shap_result.feature_importance.items():\n",
    "    print(f\"{task}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\nSHAP解釋完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Force Plot 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建毒性分類的Force Plot\n",
    "print(\"創建Force Plot - 毒性分類\")\n",
    "try:\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    shap_visualizer.create_force_plot(\n",
    "        shap_result, \n",
    "        task=\"toxicity\",\n",
    "        save_path=\"../reports/shap_force_plot_toxicity.png\"\n",
    "    )\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Force plot創建失敗: {e}\")\n",
    "    print(\"嘗試使用手動繪製\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建霸凌分類的Force Plot\n",
    "print(\"創建Force Plot - 霸凌分類\")\n",
    "try:\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    shap_visualizer.create_force_plot(\n",
    "        shap_result, \n",
    "        task=\"bullying\",\n",
    "        save_path=\"../reports/shap_force_plot_bullying.png\"\n",
    "    )\n",
    "    plt.show()\n",
    "except Exception as e:\n",
    "    print(f\"Force plot創建失敗: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Waterfall Plot 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建Waterfall Plot\n",
    "print(\"創建Waterfall Plot - 毒性分類\")\n",
    "fig = shap_visualizer.create_waterfall_plot(\n",
    "    shap_result, \n",
    "    task=\"toxicity\",\n",
    "    save_path=\"../reports/shap_waterfall_plot_toxicity.png\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建情緒分類的Waterfall Plot\n",
    "print(\"創建Waterfall Plot - 情緒分類\")\n",
    "fig = shap_visualizer.create_waterfall_plot(\n",
    "    shap_result, \n",
    "    task=\"emotion\",\n",
    "    save_path=\"../reports/shap_waterfall_plot_emotion.png\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Text Plot 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建Text Plot\n",
    "print(\"創建Text Plot - 毒性分類\")\n",
    "fig = shap_visualizer.create_text_plot(\n",
    "    shap_result, \n",
    "    task=\"toxicity\",\n",
    "    save_path=\"../reports/shap_text_plot_toxicity.png\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 批量分析多個文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量分析所有測試文本\n",
    "print(\"批量分析所有測試文本...\")\n",
    "all_shap_results = []\n",
    "\n",
    "for i, text in enumerate(tqdm(test_texts, desc=\"SHAP分析\")):\n",
    "    try:\n",
    "        result = shap_explainer.explain_text(text, max_evals=200)  # 減少評估次數加速\n",
    "        all_shap_results.append(result)\n",
    "        print(f\"{i+1}. {text[:20]}... -> 毒性:{result.toxicity_pred}, 霸凌:{result.bullying_pred}\")\n",
    "    except Exception as e:\n",
    "        print(f\"分析失敗 - {text[:20]}...: {e}\")\n",
    "\n",
    "print(f\"\\n完成 {len(all_shap_results)} 個文本的SHAP分析\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Plot 全局分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建Summary Plot\n",
    "if len(all_shap_results) > 0:\n",
    "    print(\"創建Summary Plot - 毒性分類\")\n",
    "    fig = shap_visualizer.create_summary_plot(\n",
    "        all_shap_results, \n",
    "        task=\"toxicity\",\n",
    "        max_features=15,\n",
    "        save_path=\"../reports/shap_summary_plot_toxicity.png\"\n",
    "    )\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"沒有可用的SHAP結果用於Summary Plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結\n",
    "\n",
    "本筆記本展示了如何使用SHAP對中文網路霸凌偵測模型進行全面的可解釋性分析：\n",
    "\n",
    "1. **Force Plots**: 顯示各個token對最終預測的正負貢獻\n",
    "2. **Waterfall Plots**: 層次化展示特徵如何影響預測結果\n",
    "3. **Text Plots**: 直觀的文本級可視化，易於理解\n",
    "4. **Summary Plots**: 全局特徵重要性分析\n",
    "5. **誤判分析**: 識別模型的錯誤模式\n",
    "6. **方法對比**: SHAP與IG結果的對比驗證\n",
    "\n",
    "這些可視化方法有助於：\n",
    "- 理解模型的決策過程\n",
    "- 識別重要的語言特徵\n",
    "- 發現模型的偏見和錯誤模式\n",
    "- 提高模型的可信度和可解釋性\n",
    "\n",
    "建議在實際部署前使用這些工具對模型進行全面的可解釋性評估。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}