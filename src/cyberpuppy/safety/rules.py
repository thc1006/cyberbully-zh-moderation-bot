"""
å®‰å…¨è¦å‰‡èˆ‡å›è¦†ç­–ç•¥å¯¦ä½œ

æ ¹æ“š POLICY.md å®šç¾©çš„è¦å‰‡å¯¦ä½œå›è¦†åˆ†ç´šã€éš±ç§ä¿è­·èˆ‡èª¤åˆ¤è™•ç†æ©Ÿåˆ¶
"""

import hashlib
import json
import logging
import re
import uuid
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum, IntEnum
from typing import Any, Dict, List, Optional, Tuple

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)


class ResponseLevel(IntEnum):
    """å›è¦†åˆ†ç´š"""

    NONE = 0  # ç„¡éœ€å›æ‡‰
    GENTLE_REMINDER = 1  # æº«å’Œæç¤º
    SOFT_INTERVENTION = 2  # æŸ”æ€§å‹¸é˜»
    RESOURCE_ESCALATION = 3  # è³‡æºæä¾›èˆ‡å‡ç´š
    SILENT_HANDOVER = 4  # æ²‰é»˜æˆ–ç§»äº¤


class AppealStatus(Enum):
    """ç”³è¨´ç‹€æ…‹"""

    PENDING = "pending"
    UNDER_REVIEW = "under_review"
    APPROVED = "approved"
    REJECTED = "rejected"
    ESCALATED = "escalated"


@dataclass
class UserViolationHistory:
    """ä½¿ç”¨è€…é•è¦æ­·å²"""

    user_id: str
    violations: List[Dict[str, Any]] = field(default_factory=list)
    total_count: int = 0
    last_violation_time: Optional[datetime] = None
    appeal_count: int = 0

    def add_violation(self, level: ResponseLevel, scores: Dict[str, float]):
        """æ–°å¢é•è¦è¨˜éŒ„"""
        self.violations.append(
            {
                "timestamp": datetime.now().isoformat(),
                "level": level.value,
                "scores": scores,
                "hash": hashlib.sha256(f"{level.value}_{scores}".encode()).hexdigest()
            }
        )
        self.total_count += 1
        self.last_violation_time = datetime.now()

        # ä¿ç•™æœ€è¿‘ 10 ç­†è¨˜éŒ„
        if len(self.violations) > 10:
            self.violations.pop(0)

    def get_recent_violations(self, hours: int = 24) -> List[Dict[str, Any]]:
        """å–å¾—æœ€è¿‘çš„é•è¦è¨˜éŒ„"""
        cutoff = datetime.now() - timedelta(hours=hours)
        return [v for v in self.violations if datetime.fromisoformat(v["time"
            "stamp"]) > cutoff]


@dataclass
class ResponseStrategy:
    """å›æ‡‰ç­–ç•¥"""

    level: ResponseLevel
    message: str
    resources: List[Dict[str, str]] = field(default_factory=list)
    notify_admin: bool = False
    log_detail: bool = True


@dataclass
class Appeal:
    """ç”³è¨´æ¡ˆä»¶"""

    appeal_id: str
    user_id: str
    event_hash: str
    reason: str
    status: AppealStatus
    created_at: datetime
    updated_at: datetime
    reviewer: Optional[str] = None
    resolution: Optional[str] = None

    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            "appeal_id": self.appeal_id,
            "user_id": self.user_id,
            "event_hash": self.event_hash,
            "reason": self.reason,
            "status": self.status.value,
            "created_at": self.created_at.isoformat(),
            "updated_at": self.updated_at.isoformat(),
            "reviewer": self.reviewer,
            "resolution": self.resolution,
        }


class PIIHandler:
    """å€‹äººè­˜åˆ¥è³‡è¨Šè™•ç†å™¨"""

    # PII æ­£å‰‡è¡¨é”å¼æ¨¡å¼
    PII_PATTERNS = {
        "email": (r"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}", "[EMAIL]"),
        "phone_tw": (r"09\d{8}", "[PHONE]"),
        "phone_intl": (r"\+\d{1,3}[\s-]?\d{1,14}", "[PHONE]"),
        "id_tw": (r"[A-Z][12]\d{8}", "[ID]"),
        "credit_card": (r"\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}", "[CARD]"),
        "ip_address": (r"\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}", "[IP]"),
        "url_personal": (
            r"https?://[^\s]*(?:facebook|instagram|twitter|line)\.com/[^\s]+",
            "[SOCIAL]",
        ),
    }

    @classmethod
    def remove_pii(cls, text: str) -> Tuple[str, Dict[str, int]]:
        """
        ç§»é™¤å€‹äººè­˜åˆ¥è³‡è¨Š

        Args:
            text: åŸå§‹æ–‡æœ¬

        Returns:
            Tuple[æ¸…ç†å¾Œæ–‡æœ¬, PIIé¡å‹çµ±è¨ˆ]
        """
        cleaned_text = text
        pii_stats = {}

        for pii_type, (pattern, replacement) in cls.PII_PATTERNS.items():
            matches = re.findall(pattern, cleaned_text, re.IGNORECASE)
            if matches:
                pii_stats[pii_type] = len(matches)
                cleaned_text = re.sub(
                    pattern,
                    replacement,
                    cleaned_text,
                    flags=re.IGNORECASE
                )

        return cleaned_text, pii_stats

    @classmethod
    def hash_user_id(cls, user_id: str, salt: str = "cyberpuppy") -> str:
        """
        é›œæ¹Šè™•ç†ä½¿ç”¨è€… ID

        Args:
            user_id: åŸå§‹ä½¿ç”¨è€… ID
            salt: åŠ é¹½å€¼

        Returns:
            é›œæ¹Šå¾Œçš„ ID
        """
        combined = f"{salt}:{user_id}"
        return hashlib.sha256(combined.encode()).hexdigest()[:16]

    @classmethod
    def anonymize_ip(cls, ip_address: str) -> str:
        """
        åŒ¿ååŒ– IP åœ°å€ï¼ˆä¿ç•™å‰å…©æ®µï¼‰

        Args:
            ip_address: åŸå§‹ IP

        Returns:
            åŒ¿ååŒ–çš„ IP
        """
        parts = ip_address.split(".")
        if len(parts) == 4:
            return f"{parts[0]}.{parts[1]}.X.X"
        return "X.X.X.X"


class SafetyRules:
    """å®‰å…¨è¦å‰‡å¼•æ“"""

    # å›è¦†è¨Šæ¯æ¨¡æ¿
    RESPONSE_TEMPLATES = {
        ResponseLevel.GENTLE_REMINDER: [
            "å—¨ï¼è®“æˆ‘å€‘ä¿æŒå‹å–„çš„å°è©±ç’°å¢ƒå§ ğŸ˜Š",
            "æˆ–è¨±å¯ä»¥ç”¨æ›´æº«å’Œçš„æ–¹å¼è¡¨é”æƒ³æ³•å‘¢ï¼Ÿ",
            "æ¯å€‹äººéƒ½å€¼å¾—è¢«å°Šé‡å°å¾… ğŸ’",
            "å‹å–„çš„æºé€šè®“å°è©±æ›´æœ‰æ„ç¾© ğŸ¤",
        ],
        ResponseLevel.SOFT_INTERVENTION: [
            "æˆ‘å€‘æ³¨æ„åˆ°æ‚¨çš„è¨Šæ¯å¯èƒ½è®“ä»–äººæ„Ÿåˆ°ä¸èˆ’æœã€‚\nç¶²è·¯æºé€šæœ‰æ™‚å®¹æ˜“ç”¢ç”Ÿèª¤è§£ï¼Œè©¦è©¦æ›´æ¸…æ¥šåœ°è¡¨é”æ‚¨çš„æƒ³æ³•ï¼Ÿ",
            "ç¶²è·¯éœ¸å‡Œæœƒå°ä»–äººé€ æˆå‚·å®³ã€‚\nè®“æˆ‘å€‘ä¸€èµ·ç‡Ÿé€ å‹å–„çš„ç¶²è·¯ç’°å¢ƒã€‚",
            "æ‚¨çš„è¨Šæ¯åŒ…å«ä¸é©ç•¶å…§å®¹ã€‚\nè«‹æ³¨æ„æ‚¨çš„ç”¨è©ï¼Œä¿æŒç†æ€§è¨è«–ã€‚",
        ],
        ResponseLevel.RESOURCE_ESCALATION: [
            "å¦‚æœæ‚¨æ­£åœ¨ç¶“æ­·å›°é›£ï¼Œä»¥ä¸‹è³‡æºå¯èƒ½å°æ‚¨æœ‰å¹«åŠ©ï¼š",
            "æˆ‘å€‘é—œå¿ƒæ‚¨çš„æ„Ÿå—ï¼Œé€™è£¡æœ‰ä¸€äº›æ”¯æ´ç®¡é“ï¼š",
            "è«‹è¨˜å¾—ï¼Œæ‚¨ä¸¦ä¸å­¤å–®ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›æ±‚åŠ©è³‡æºï¼š",
        ],
    }

    # æ±‚åŠ©è³‡æº
    HELP_RESOURCES = [
        {"name": "å¿ƒç†å¥åº·å°ˆç·š", "phone": "1925", "url": None},
        {"name": "ç”Ÿå‘½ç·šå”è«‡å°ˆç·š", "phone": "1995", "url": None},
        {"name": "iWIN ç¶²è·¯å…§å®¹é˜²è­·", "phone": None, "url": "https://i.win.org.tw/"},
        {"name": "å®¶æš´é˜²æ²»å°ˆç·š", "phone": "113", "url": None},
    ]

    def __init__(self):
        """åˆå§‹åŒ–å®‰å…¨è¦å‰‡å¼•æ“"""
        self.user_histories: Dict[str, UserViolationHistory] = {}

    def determine_response_level(
        self,
        toxicity_score: float,
        bullying_score: float,
        user_id: str,
        emotion: str = "neu",
        emotion_strength: int = 0,
    ) -> ResponseLevel:
        """
        æ±ºå®šå›æ‡‰ç­‰ç´š

        Args:
            toxicity_score: æ¯’æ€§åˆ†æ•¸
            bullying_score: éœ¸å‡Œåˆ†æ•¸
            user_id: ä½¿ç”¨è€… ID
            emotion: æƒ…ç·’é¡åˆ¥
            emotion_strength: æƒ…ç·’å¼·åº¦

        Returns:
            å›æ‡‰ç­‰ç´š
        """
        # å–å¾—ä½¿ç”¨è€…é•è¦æ­·å²
        history = self.user_histories.get(user_id)
        recent_violations = 0
        if history:
            recent_violations = len(history.get_recent_violations(24))

        # æ±ºå®šåŸºç¤ç­‰ç´š
        max_score = max(toxicity_score, bullying_score)

        if max_score > 0.9:
            return ResponseLevel.SILENT_HANDOVER
        elif max_score > 0.7:
            return ResponseLevel.RESOURCE_ESCALATION
        elif max_score > 0.5:
            # è€ƒæ…®é•è¦æ­·å²
            if recent_violations >= 2:
                return ResponseLevel.RESOURCE_ESCALATION
            return ResponseLevel.SOFT_INTERVENTION
        elif max_score > 0.3:
            # è€ƒæ…®é•è¦æ­·å²
            if recent_violations >= 1:
                return ResponseLevel.SOFT_INTERVENTION
            return ResponseLevel.GENTLE_REMINDER

        # æª¢æŸ¥æƒ…ç·’ç‹€æ…‹ï¼ˆè‡ªå‚·å‚¾å‘ï¼‰
        if emotion == "neg" and emotion_strength >= 4:
            return ResponseLevel.RESOURCE_ESCALATION

        return ResponseLevel.NONE

    def generate_response(
        self, level: ResponseLevel, context: Optional[Dict[str, Any]] = None
    ) -> ResponseStrategy:
        """
        ç”Ÿæˆå›æ‡‰ç­–ç•¥

        Args:
            level: å›æ‡‰ç­‰ç´š
            context: é¡å¤–ä¸Šä¸‹æ–‡

        Returns:
            å›æ‡‰ç­–ç•¥
        """
        if level == ResponseLevel.NONE:
            return ResponseStrategy(
                level=level, message=""
                    "", resources=[], notify_admin=False, log_detail=False
            )

        # é¸æ“‡è¨Šæ¯æ¨¡æ¿
        import random

        templates = self.RESPONSE_TEMPLATES.get(level, [])
        message = random.choice(templates) if templates else ""

        # æ±ºå®šæ˜¯å¦éœ€è¦è³‡æº
        resources = []
        if level >= ResponseLevel.RESOURCE_ESCALATION:
            resources = self.HELP_RESOURCES

        # æ±ºå®šæ˜¯å¦é€šçŸ¥ç®¡ç†å“¡
        notify_admin = level >= ResponseLevel.SILENT_HANDOVER

        return ResponseStrategy(
            level=level,
            message=message,
            resources=resources,
            notify_admin=notify_admin,
            log_detail=True,
        )

    def update_user_history(
        self,
        user_id: str,
        level: ResponseLevel,
        scores: Dict[str,
        float]
    ):
        """æ›´æ–°ä½¿ç”¨è€…é•è¦æ­·å²"""
        if user_id not in self.user_histories:
            self.user_histories[user_id] = UserViolationHistory(user_id=user_id)

        if level > ResponseLevel.NONE:
            self.user_histories[user_id].add_violation(level, scores)

    def should_apply_special_protection(
        self, user_age: Optional[int] = None, is_vulnerable: bool = False
    ) -> Dict[str, Any]:
        """
        åˆ¤æ–·æ˜¯å¦éœ€è¦ç‰¹æ®Šä¿è­·

        Args:
            user_age: ä½¿ç”¨è€…å¹´é½¡
            is_vulnerable: æ˜¯å¦ç‚ºè„†å¼±æ—ç¾¤

        Returns:
            ç‰¹æ®Šä¿è­·è¨­å®š
        """
        protection = {
            "lower_threshold": False,
            "priority_resources": False,
            "parental_notify": False,
            "extra_logging": False,
        }

        # æœªæˆå¹´äººä¿è­·
        if user_age and user_age < 18:
            protection["lower_threshold"] = True
            protection["priority_resources"] = True
            if user_age < 13:
                protection["parental_notify"] = True

        # è„†å¼±æ—ç¾¤ä¿è­·
        if is_vulnerable:
            protection["priority_resources"] = True
            protection["extra_logging"] = True

        return protection


class PrivacyLogger:
    """éš±ç§ä¿è­·æ—¥èªŒè¨˜éŒ„å™¨"""

    def __init__(self, log_file: Optional[str] = None):
        """åˆå§‹åŒ–æ—¥èªŒè¨˜éŒ„å™¨"""
        self.log_file = log_file
        self.pii_handler = PIIHandler()

    def log_event(
        self,
        event_type: str,
        text: str,
        scores: Dict[str, float],
        action: ResponseLevel,
        user_id: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        è¨˜éŒ„äº‹ä»¶ï¼ˆéš±ç§ä¿è­·ï¼‰

        Args:
            event_type: äº‹ä»¶é¡å‹
            text: åŸå§‹æ–‡æœ¬
            scores: åˆ†æåˆ†æ•¸
            action: æ¡å–çš„è¡Œå‹•
            user_id: ä½¿ç”¨è€… ID
            metadata: é¡å¤–å…ƒè³‡æ–™

        Returns:
            æ—¥èªŒè¨˜éŒ„
        """
        # ç”Ÿæˆæ–‡æœ¬é›œæ¹Š
        text_hash = hashlib.sha256(text.encode()).hexdigest()[:16]

        # åŒ¿ååŒ–ä½¿ç”¨è€… ID
        anon_user_id = None
        if user_id:
            anon_user_id = self.pii_handler.hash_user_id(user_id)

        # ç§»é™¤ PII
        _, pii_stats = self.pii_handler.remove_pii(text)

        # å»ºç«‹æ—¥èªŒè¨˜éŒ„
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "event_type": event_type,
            "text_hash": text_hash,
            "text_length": len(text),
            "scores": scores,
            "action": action.name,
            "session_id": anon_user_id,
            "pii_detected": pii_stats,
            "metadata": metadata or {},
        }

        # å¯«å…¥æ—¥èªŒ
        if self.log_file:
            try:
                with open(self.log_file, "a", encoding="utf-8") as f:
                    f.write(json.dumps(log_entry, ensure_ascii=False) + "\n")
            except Exception as e:
                logger.error(f"æ—¥èªŒå¯«å…¥å¤±æ•—: {e}")

        logger.info(f"äº‹ä»¶è¨˜éŒ„ - é¡å‹: {event_type}, Hash:"
            " {text_hash}, è¡Œå‹•: {action.name}")

        return log_entry


class AppealManager:
    """ç”³è¨´ç®¡ç†å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–ç”³è¨´ç®¡ç†å™¨"""
        self.appeals: Dict[str, Appeal] = {}
        self.user_appeals: Dict[str, List[str]] = {}  # user_id -> appeal_ids

    def create_appeal(
        self,
        user_id: str,
        event_hash: str,
        reason: str
    ) -> Appeal:
        """
        å»ºç«‹ç”³è¨´

        Args:
            user_id: ä½¿ç”¨è€… ID
            event_hash: äº‹ä»¶é›œæ¹Šå€¼
            reason: ç”³è¨´åŸå› 

        Returns:
            ç”³è¨´æ¡ˆä»¶
        """
        appeal_id = str(uuid.uuid4())[:8]
        appeal = Appeal(
            appeal_id=appeal_id,
            user_id=PIIHandler.hash_user_id(user_id),
            event_hash=event_hash,
            reason=reason[:500],  # é™åˆ¶é•·åº¦
            status=AppealStatus.PENDING,
            created_at=datetime.now(),
            updated_at=datetime.now(),
        )

        self.appeals[appeal_id] = appeal

        # è¨˜éŒ„ä½¿ç”¨è€…ç”³è¨´
        anon_user = appeal.user_id
        if anon_user not in self.user_appeals:
            self.user_appeals[anon_user] = []
        self.user_appeals[anon_user].append(appeal_id)

        logger.info(f"ç”³è¨´å»ºç«‹ - ID: {appeal_id}, Hash: {event_hash}")

        return appeal

    def review_appeal(
        self, appeal_id: str, reviewer: str, decision: AppealStatus,
            resolution: str
    ) -> Optional[Appeal]:
        """
        å¯©æ ¸ç”³è¨´

        Args:
            appeal_id: ç”³è¨´ ID
            reviewer: å¯©æ ¸å“¡ ID
            decision: æ±ºå®š
            resolution: è§£æ±ºèªªæ˜

        Returns:
            æ›´æ–°å¾Œçš„ç”³è¨´æ¡ˆä»¶
        """
        if appeal_id not in self.appeals:
            logger.error(f"ç”³è¨´ä¸å­˜åœ¨: {appeal_id}")
            return None

        appeal = self.appeals[appeal_id]
        appeal.status = decision
        appeal.reviewer = reviewer
        appeal.resolution = resolution
        appeal.updated_at = datetime.now()

        logger.info(f"ç”³è¨´å¯©æ ¸ - ID: {appeal_id}, æ±ºå®š: {decision.value}")

        # å¦‚æœèª¤åˆ¤æˆç«‹ï¼ŒåŸ·è¡Œè£œå„Ÿ
        if decision == AppealStatus.APPROVED:
            self._apply_compensation(appeal)

        return appeal

    def _apply_compensation(self, appeal: Appeal):
        """åŸ·è¡Œèª¤åˆ¤è£œå„Ÿ"""
        logger.info(f"åŸ·è¡Œè£œå„Ÿ - ç”³è¨´ ID: {appeal.appeal_id}")
        # å¯¦éš›å¯¦ä½œæ™‚ï¼š
        # 1. æ¸…é™¤é•è¦è¨˜éŒ„
        # 2. æ¢å¾©æ¬Šé™
        # 3. ç™¼é€é€šçŸ¥
        # 4. æ›´æ–°æ¨¡å‹è¨“ç·´è³‡æ–™

    def get_user_appeals(
        self, user_id: str, status_filter: Optional[AppealStatus] = None
    ) -> List[Appeal]:
        """å–å¾—ä½¿ç”¨è€…çš„ç”³è¨´è¨˜éŒ„"""
        anon_user = PIIHandler.hash_user_id(user_id)
        appeal_ids = self.user_appeals.get(anon_user, [])

        appeals = [self.appeals[aid] for aid in appeal_ids if aid in
            self.appeals]

        if status_filter:
            appeals = [a for a in appeals if a.status == status_filter]

        return sorted(appeals, key=lambda x: x.created_at, reverse=True)

    def get_appeal_stats(self) -> Dict[str, Any]:
        """å–å¾—ç”³è¨´çµ±è¨ˆ"""
        total = len(self.appeals)
        if total == 0:
            return {"total": 0, "by_status": {}, "approval_rate": 0}

        by_status = {}
        for appeal in self.appeals.values():
            status = appeal.status.value
            by_status[status] = by_status.get(status, 0) + 1

        approved = by_status.get(AppealStatus.APPROVED.value, 0)
        rejected = by_status.get(AppealStatus.REJECTED.value, 0)
        reviewed = approved + rejected

        approval_rate = (approved / reviewed * 100) if reviewed > 0 else 0

        return {
            "total": total,
            "by_status": by_status,
            "approval_rate": round(approval_rate, 2),
            "average_review_time": self._calculate_avg_review_time(),
        }

    def _calculate_avg_review_time(self) -> float:
        """è¨ˆç®—å¹³å‡å¯©æ ¸æ™‚é–“ï¼ˆå°æ™‚ï¼‰"""
        reviewed = [
            a
            for a in self.appeals.values()
            if a.status in [AppealStatus.APPROVED, AppealStatus.REJECTED]
        ]

        if not reviewed:
            return 0

        total_time = sum((a.updated_at -
            a.created_at).total_seconds() for a in reviewed)

        return round(total_time / len(reviewed) / 3600, 2)  # è½‰æ›ç‚ºå°æ™‚


# ä½¿ç”¨ç¯„ä¾‹
def example_usage():
    """ä½¿ç”¨ç¯„ä¾‹"""

    # åˆå§‹åŒ–å…ƒä»¶
    safety_rules = SafetyRules()
    privacy_logger = PrivacyLogger(log_file="safety_logs.jsonl")
    appeal_manager = AppealManager()

    # æ¨¡æ“¬åˆ†æçµæœ
    user_id = "user123"
    text = "ä½ é€™å€‹ç¬¨è›‹ï¼Œçµ¦æˆ‘æ»¾é–‹ï¼æˆ‘çš„ä¿¡ç®±æ˜¯ test@example.com"
    scores = {"toxicity": 0.75, "bullying": 0.60, "emotion": "neg"}

    # 1. æ±ºå®šå›æ‡‰ç­‰ç´š
    response_level = safety_rules.determine_response_level(
        toxicity_score=scores["toxicity"],
        bullying_score=scores["bullying"],
        user_id=user_id,
        emotion=scores.get("emotion", "neu"),
    )
    print(f"å›æ‡‰ç­‰ç´š: {response_level.name}")

    # 2. ç”Ÿæˆå›æ‡‰ç­–ç•¥
    strategy = safety_rules.generate_response(response_level)
    print(f"å›æ‡‰è¨Šæ¯: {strategy.message}")
    if strategy.resources:
        print("æä¾›è³‡æº:")
        for resource in strategy.resources:
            print(f"  - {resource['name']}")

    # 3. è¨˜éŒ„äº‹ä»¶ï¼ˆéš±ç§ä¿è­·ï¼‰
    log_entry = privacy_logger.log_event(
        event_type="toxicity_detected",
        text=text,
        scores=scores,
        action=response_level,
        user_id=user_id,
    )
    print(f"æ—¥èªŒè¨˜éŒ„ - Hash: {log_entry['text_hash']}"
        ", PII åµæ¸¬: {log_entry['pii_detected']}")

    # 4. æ›´æ–°é•è¦æ­·å²
    safety_rules.update_user_history(user_id, response_level, scores)

    # 5. æ¨¡æ“¬ç”³è¨´æµç¨‹
    appeal = appeal_manager.create_appeal(
        user_id=user_id,
        event_hash=log_entry["text_hash"],
        reason="é€™æ˜¯æœ‹å‹é–“çš„ç©ç¬‘è©±ï¼Œä¸æ˜¯çœŸçš„éœ¸å‡Œ",
    )
    print(f"ç”³è¨´å»ºç«‹ - ID: {appeal.appeal_id}")

    # 6. å¯©æ ¸ç”³è¨´
    reviewed = appeal_manager.review_appeal(
        appeal_id=appeal.appeal_id,
        reviewer="admin001",
        decision=AppealStatus.APPROVED,
        resolution="ç¶“æŸ¥è­‰ç¢ºå¯¦ç‚ºæœ‹å‹é–“ç©ç¬‘ï¼Œåˆ¤å®šç‚ºèª¤åˆ¤",
    )
    print(f"ç”³è¨´çµæœ: {reviewed.status.value}")

    # 7. æŸ¥çœ‹çµ±è¨ˆ
    stats = appeal_manager.get_appeal_stats()
    print(f"ç”³è¨´çµ±è¨ˆ: {stats}")


if __name__ == "__main__":
    example_usage()
